2021-12-27 16:51:39,154 |	  Reusing dataset opus_euconst (/home/li/.cache/huggingface/datasets/opus_euconst/en-fr/1.0.0/d1e611a011f28fdda67a97024820e0a3813b4e4decca194d9a20b3207a39b908)
2021-12-27 16:51:39,187 |	  DatasetDict({
    train: Dataset({
        features: ['translation'],
        num_rows: 10104
    })
})
2021-12-27 16:51:39,189 |	  {'translation': {'en': 'CONSIDERING that Article IV-437(2)(e) of the Constitution provides that the Treaty of 16 April 2003 concerning the accessions referred to above shall be repealed;  ', 'fr': "CONSIDÉRANT que l'article\xa0IV-437, paragraphe\xa02, point\xa0e), de la Constitution prévoit l'abrogation du traité du 16\xa0avril 2003 relatif aux adhésions visées ci-dessus;  "}}
2021-12-27 16:51:41,970 |	  Loading cached shuffled indices for dataset at /home/li/.cache/huggingface/datasets/opus_euconst/en-fr/1.0.0/d1e611a011f28fdda67a97024820e0a3813b4e4decca194d9a20b3207a39b908/cache-774986f0005795ce.arrow
2021-12-27 16:51:42,420 |	  train len: 7578
2021-12-27 16:51:42,422 |	  valid len: 1263
2021-12-27 16:51:42,423 |	  test len: 1263
2021-12-27 16:51:42,423 |	  {'en': 'translate English to French:, on the basis of Article\xa02, and shall report thereon at least once a year.  ', 'fr': "L'Agence européenne de défense contribue à l'évaluation régulière des contributions des États membres participants en matière de capacités, en particulier des contributions fournies suivant les critères qui seront établis, entre autres, sur la base de l'article\xa02, et en fait rapport au moins une fois par an.  "}
2021-12-27 16:52:02,738 |	  Step count: 0
2021-12-27 16:53:30,821 |	  loss_w (train):0.00025195657508447766
2021-12-27 16:53:53,260 |	  v_loss (train):333.8587341308594
2021-12-27 16:53:55,265 |	  model_w_in_main test loss : 0.837706
2021-12-27 16:53:55,822 |	  model_v_in_main test loss : 0.831462
2021-12-27 16:53:55,830 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.9999, -0.9999, -0.9999,  ..., -0.9999, -0.9999, -0.9999],
       device='cuda:0', requires_grad=True))
2021-12-27 16:53:55,833 |	  Step count: 1
2021-12-27 16:54:21,362 |	  loss_w (train):0.0003976798616349697
2021-12-27 16:54:30,183 |	  v_loss (train):111.9421157836914
2021-12-27 16:54:32,551 |	  model_w_in_main test loss : 0.837607
2021-12-27 16:54:32,693 |	  model_v_in_main test loss : 0.868355
2021-12-27 16:54:32,714 |	  ('Attention Weights A : ', Parameter containing:
tensor([-1.8547, -1.8547, -1.8547,  ..., -1.8547, -1.8547, -1.8547],
       device='cuda:0', requires_grad=True))
2021-12-27 16:54:32,717 |	  Step count: 2
2021-12-27 16:55:52,174 |	  loss_w (train):6.327614391921088e-05
2021-12-27 16:56:14,363 |	  v_loss (train):263.779052734375
2021-12-27 16:56:16,288 |	  model_w_in_main test loss : 0.837647
2021-12-27 16:56:16,820 |	  model_v_in_main test loss : 0.852040
2021-12-27 16:56:16,827 |	  ('Attention Weights A : ', Parameter containing:
tensor([-2.3137, -2.3137, -2.3137,  ..., -2.3137, -2.3137, -2.3137],
       device='cuda:0', requires_grad=True))
2021-12-27 16:56:16,829 |	  Step count: 3
2021-12-27 16:56:41,028 |	  loss_w (train):5.9986858104821295e-05
2021-12-27 16:56:44,327 |	  v_loss (train):90.01312255859375
2021-12-27 16:56:46,658 |	  model_w_in_main test loss : 0.837579
2021-12-27 16:56:47,232 |	  model_v_in_main test loss : 0.853961
2021-12-27 16:56:47,248 |	  ('Attention Weights A : ', Parameter containing:
tensor([-2.5981, -2.5981, -2.5981,  ..., -2.5981, -2.5981, -2.5981],
       device='cuda:0', requires_grad=True))
2021-12-27 16:56:47,251 |	  Step count: 4
2021-12-27 16:57:12,170 |	  loss_w (train):5.960127396065218e-07
2021-12-27 16:57:15,872 |	  v_loss (train):107.91200256347656
2021-12-27 16:57:18,289 |	  model_w_in_main test loss : 0.837582
2021-12-27 16:57:18,443 |	  model_v_in_main test loss : 0.878200
2021-12-27 16:57:18,464 |	  ('Attention Weights A : ', Parameter containing:
tensor([-2.4968, -2.4968, -2.4968,  ..., -2.4968, -2.4968, -2.4968],
       device='cuda:0', requires_grad=True))
2021-12-27 16:57:18,466 |	  Step count: 5
2021-12-27 16:57:54,298 |	  loss_w (train):0.0002165803307434544
2021-12-27 16:58:01,345 |	  v_loss (train):158.43104553222656
2021-12-27 16:58:03,329 |	  model_w_in_main test loss : 0.837634
2021-12-27 16:58:03,424 |	  model_v_in_main test loss : 0.876339
2021-12-27 16:58:03,430 |	  ('Attention Weights A : ', Parameter containing:
tensor([-2.5970, -2.5970, -2.5970,  ..., -2.5970, -2.5970, -2.5970],
       device='cuda:0', requires_grad=True))
2021-12-27 16:58:03,432 |	  Step count: 6
2021-12-27 16:58:29,260 |	  loss_w (train):0.00013173175102565438
2021-12-27 16:58:32,803 |	  v_loss (train):82.34506225585938
2021-12-27 16:58:34,949 |	  model_w_in_main test loss : 0.837749
2021-12-27 16:58:35,468 |	  model_v_in_main test loss : 0.880960
2021-12-27 16:58:35,473 |	  ('Attention Weights A : ', Parameter containing:
tensor([-2.6054, -2.6054, -2.6054,  ..., -2.6054, -2.6054, -2.6054],
       device='cuda:0', requires_grad=True))
2021-12-27 16:58:35,475 |	  Step count: 7
2021-12-27 16:59:06,613 |	  loss_w (train):1.6484449588460848e-05
2021-12-27 16:59:12,085 |	  v_loss (train):143.1834259033203
2021-12-27 16:59:14,193 |	  model_w_in_main test loss : 0.837744
2021-12-27 16:59:14,314 |	  model_v_in_main test loss : 0.887228
2021-12-27 16:59:14,318 |	  ('Attention Weights A : ', Parameter containing:
tensor([-2.6039, -2.6039, -2.6039,  ..., -2.6039, -2.6039, -2.6039],
       device='cuda:0', requires_grad=True))
2021-12-27 16:59:14,320 |	  Step count: 8
2021-12-27 16:59:39,495 |	  loss_w (train):1.7820023003878305e-06
2021-12-27 16:59:42,869 |	  v_loss (train):76.80359649658203
2021-12-27 16:59:44,813 |	  model_w_in_main test loss : 0.837731
2021-12-27 16:59:45,251 |	  model_v_in_main test loss : 0.871066
2021-12-27 16:59:45,256 |	  ('Attention Weights A : ', Parameter containing:
tensor([-1.3275, -1.3275, -1.3275,  ..., -1.3275, -1.3275, -1.3275],
       device='cuda:0', requires_grad=True))
2021-12-27 16:59:45,258 |	  Step count: 9
2021-12-27 17:01:16,801 |	  loss_w (train):8.972619411906635e-07
2021-12-27 17:01:38,388 |	  v_loss (train):198.57867431640625
2021-12-27 17:01:40,510 |	  model_w_in_main test loss : 0.837682
2021-12-27 17:01:40,974 |	  model_v_in_main test loss : 0.880966
2021-12-27 17:01:40,982 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.6427, -0.6427, -0.6427,  ..., -0.6427, -0.6427, -0.6427],
       device='cuda:0', requires_grad=True))
2021-12-27 17:01:40,984 |	  Step count: 10
2021-12-27 17:02:06,581 |	  loss_w (train):0.0001512727903900668
2021-12-27 17:02:09,754 |	  v_loss (train):103.07505798339844
2021-12-27 17:02:12,153 |	  model_w_in_main test loss : 0.837650
2021-12-27 17:02:12,288 |	  model_v_in_main test loss : 0.901313
2021-12-27 17:02:12,298 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.4332, -0.4332, -0.4332,  ..., -0.4332, -0.4332, -0.4332],
       device='cuda:0', requires_grad=True))
2021-12-27 17:02:12,301 |	  Step count: 11
2021-12-27 17:03:13,223 |	  loss_w (train):2.750521844063769e-06
2021-12-27 17:03:27,915 |	  v_loss (train):205.65298461914062
2021-12-27 17:03:30,235 |	  model_w_in_main test loss : 0.837762
2021-12-27 17:03:30,367 |	  model_v_in_main test loss : 0.910425
2021-12-27 17:03:30,372 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.2890, -0.2890, -0.2890,  ..., -0.2890, -0.2890, -0.2890],
       device='cuda:0', requires_grad=True))
2021-12-27 17:03:30,374 |	  Step count: 12
2021-12-27 17:04:08,453 |	  loss_w (train):5.800643702968955e-05
2021-12-27 17:04:19,081 |	  v_loss (train):153.5947265625
2021-12-27 17:04:21,411 |	  model_w_in_main test loss : 0.837674
2021-12-27 17:04:21,590 |	  model_v_in_main test loss : 0.903791
2021-12-27 17:04:21,598 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.2290, -0.2290, -0.2290,  ..., -0.2290, -0.2290, -0.2290],
       device='cuda:0', requires_grad=True))
2021-12-27 17:04:21,600 |	  Step count: 13
2021-12-27 17:05:45,527 |	  loss_w (train):0.0006980294128879905
2021-12-27 17:06:07,261 |	  v_loss (train):195.16326904296875
2021-12-27 17:06:09,461 |	  model_w_in_main test loss : 0.837486
2021-12-27 17:06:09,857 |	  model_v_in_main test loss : 0.895039
2021-12-27 17:06:09,911 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.2621, -0.2621, -0.2621,  ..., -0.2621, -0.2621, -0.2621],
       device='cuda:0', requires_grad=True))
2021-12-27 17:06:09,914 |	  Step count: 14
2021-12-27 17:06:37,889 |	  loss_w (train):2.9605021154566202e-06
2021-12-27 17:06:42,697 |	  v_loss (train):68.32789611816406
2021-12-27 17:06:44,446 |	  model_w_in_main test loss : 0.837580
2021-12-27 17:06:45,019 |	  model_v_in_main test loss : 0.912959
2021-12-27 17:06:45,025 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.2414, -0.2414, -0.2414,  ..., -0.2414, -0.2414, -0.2414],
       device='cuda:0', requires_grad=True))
2021-12-27 17:06:45,027 |	  Step count: 15
2021-12-27 17:07:16,403 |	  loss_w (train):3.3606484066694975e-05
2021-12-27 17:07:25,239 |	  v_loss (train):61.9101676940918
2021-12-27 17:07:27,618 |	  model_w_in_main test loss : 0.837541
2021-12-27 17:07:27,779 |	  model_v_in_main test loss : 0.950460
2021-12-27 17:07:27,787 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.2284, -0.2284, -0.2284,  ..., -0.2284, -0.2284, -0.2284],
       device='cuda:0', requires_grad=True))
2021-12-27 17:07:27,789 |	  Step count: 16
2021-12-27 17:08:00,493 |	  loss_w (train):0.00027505913749337196
2021-12-27 17:08:06,770 |	  v_loss (train):107.85946655273438
2021-12-27 17:08:08,806 |	  model_w_in_main test loss : 0.837662
2021-12-27 17:08:09,269 |	  model_v_in_main test loss : 0.944061
2021-12-27 17:08:09,274 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.2714, -0.2714, -0.2714,  ..., -0.2714, -0.2714, -0.2714],
       device='cuda:0', requires_grad=True))
2021-12-27 17:08:09,276 |	  Step count: 17
2021-12-27 17:09:00,377 |	  loss_w (train):6.159579584164021e-07
2021-12-27 17:09:11,925 |	  v_loss (train):180.8990478515625
2021-12-27 17:09:13,391 |	  model_w_in_main test loss : 0.837583
2021-12-27 17:09:13,850 |	  model_v_in_main test loss : 0.912931
2021-12-27 17:09:13,856 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.2895, -0.2895, -0.2895,  ..., -0.2895, -0.2895, -0.2895],
       device='cuda:0', requires_grad=True))
2021-12-27 17:09:13,858 |	  Step count: 18
2021-12-27 17:10:06,570 |	  loss_w (train):1.8573206034488976e-05
2021-12-27 17:10:17,692 |	  v_loss (train):92.52146911621094
2021-12-27 17:10:18,757 |	  model_w_in_main test loss : 0.837617
2021-12-27 17:10:19,199 |	  model_v_in_main test loss : 0.939659
2021-12-27 17:10:19,203 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.3259, -0.3259, -0.3259,  ..., -0.3259, -0.3259, -0.3259],
       device='cuda:0', requires_grad=True))
2021-12-27 17:10:19,205 |	  Step count: 19
2021-12-27 17:11:10,316 |	  loss_w (train):2.8868398658232763e-06
2021-12-27 17:11:24,044 |	  v_loss (train):142.01950073242188
2021-12-27 17:11:25,987 |	  model_w_in_main test loss : 0.837556
2021-12-27 17:11:26,519 |	  model_v_in_main test loss : 0.928027
2021-12-27 17:11:26,525 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.2282, -0.2282, -0.2282,  ..., -0.2282, -0.2282, -0.2282],
       device='cuda:0', requires_grad=True))
2021-12-27 17:11:26,527 |	  Step count: 20
2021-12-27 17:12:18,576 |	  loss_w (train):2.774096174107399e-06
2021-12-27 17:12:26,931 |	  v_loss (train):106.68106079101562
2021-12-27 17:12:28,805 |	  model_w_in_main test loss : 0.837550
2021-12-27 17:12:29,274 |	  model_v_in_main test loss : 0.932936
2021-12-27 17:12:29,278 |	  ('Attention Weights A : ', Parameter containing:
tensor([-0.0662, -0.0662, -0.0662,  ..., -0.0662, -0.0662, -0.0662],
       device='cuda:0', requires_grad=True))
2021-12-27 17:12:29,280 |	  Step count: 21
2021-12-27 17:12:56,629 |	  loss_w (train):6.372405186994001e-05
2021-12-27 17:13:03,728 |	  v_loss (train):38.077720642089844
2021-12-27 17:13:04,912 |	  model_w_in_main test loss : 0.837644
2021-12-27 17:13:05,089 |	  model_v_in_main test loss : 0.961371
2021-12-27 17:13:05,096 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.0208, 0.0208, 0.0208,  ..., 0.0208, 0.0208, 0.0208], device='cuda:0',
       requires_grad=True))
2021-12-27 17:13:05,098 |	  Step count: 22
2021-12-27 17:13:26,095 |	  loss_w (train):7.520250733250577e-08
2021-12-27 17:13:27,960 |	  v_loss (train):34.52643585205078
2021-12-27 17:13:29,270 |	  model_w_in_main test loss : 0.837660
2021-12-27 17:13:29,343 |	  model_v_in_main test loss : 0.984266
2021-12-27 17:13:29,352 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1220, 0.1220, 0.1220,  ..., 0.1220, 0.1220, 0.1220], device='cuda:0',
       requires_grad=True))
2021-12-27 17:13:29,354 |	  Step count: 23
2021-12-27 17:14:11,194 |	  loss_w (train):4.675753189076204e-06
2021-12-27 17:14:19,477 |	  v_loss (train):96.24021911621094
2021-12-27 17:14:20,778 |	  model_w_in_main test loss : 0.837572
2021-12-27 17:14:20,835 |	  model_v_in_main test loss : 0.949818
2021-12-27 17:14:20,838 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1763, 0.1763, 0.1763,  ..., 0.1763, 0.1763, 0.1763], device='cuda:0',
       requires_grad=True))
2021-12-27 17:14:20,840 |	  Step count: 24
2021-12-27 17:14:46,935 |	  loss_w (train):1.5952440662658773e-05
2021-12-27 17:14:50,785 |	  v_loss (train):54.09656524658203
2021-12-27 17:14:52,640 |	  model_w_in_main test loss : 0.837553
2021-12-27 17:14:52,751 |	  model_v_in_main test loss : 1.011402
2021-12-27 17:14:52,755 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1781, 0.1781, 0.1781,  ..., 0.1781, 0.1781, 0.1781], device='cuda:0',
       requires_grad=True))
2021-12-27 17:14:52,757 |	  Step count: 25
2021-12-27 17:15:26,610 |	  loss_w (train):0.0005616524140350521
2021-12-27 17:15:37,742 |	  v_loss (train):147.3315887451172
2021-12-27 17:15:39,734 |	  model_w_in_main test loss : 0.837511
2021-12-27 17:15:39,945 |	  model_v_in_main test loss : 0.998505
2021-12-27 17:15:40,021 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1980, 0.1980, 0.1980,  ..., 0.1980, 0.1980, 0.1980], device='cuda:0',
       requires_grad=True))
2021-12-27 17:15:40,023 |	  Step count: 26
2021-12-27 17:16:09,633 |	  loss_w (train):7.825201464584097e-08
2021-12-27 17:16:15,254 |	  v_loss (train):48.96347427368164
2021-12-27 17:16:17,246 |	  model_w_in_main test loss : 0.837355
2021-12-27 17:16:17,765 |	  model_v_in_main test loss : 0.935457
2021-12-27 17:16:17,769 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.2225, 0.2225, 0.2225,  ..., 0.2225, 0.2225, 0.2225], device='cuda:0',
       requires_grad=True))
2021-12-27 17:16:17,771 |	  Step count: 27
2021-12-27 17:16:41,426 |	  loss_w (train):0.001060048583894968
2021-12-27 17:16:45,070 |	  v_loss (train):50.80058288574219
2021-12-27 17:16:47,018 |	  model_w_in_main test loss : 0.837202
2021-12-27 17:16:47,588 |	  model_v_in_main test loss : 0.993098
2021-12-27 17:16:47,595 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1328, 0.1328, 0.1328,  ..., 0.1328, 0.1328, 0.1328], device='cuda:0',
       requires_grad=True))
2021-12-27 17:16:47,597 |	  Step count: 28
2021-12-27 17:17:41,593 |	  loss_w (train):1.0400046903669136e-06
2021-12-27 17:17:54,450 |	  v_loss (train):120.14204406738281
2021-12-27 17:17:56,493 |	  model_w_in_main test loss : 0.837243
2021-12-27 17:17:57,004 |	  model_v_in_main test loss : 1.006376
2021-12-27 17:17:57,009 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1721, 0.1721, 0.1721,  ..., 0.1721, 0.1721, 0.1721], device='cuda:0',
       requires_grad=True))
2021-12-27 17:17:57,011 |	  Step count: 29
2021-12-27 17:18:19,858 |	  loss_w (train):0.0018367728916928172
2021-12-27 17:18:23,615 |	  v_loss (train):27.229393005371094
2021-12-27 17:18:25,813 |	  model_w_in_main test loss : 0.838480
2021-12-27 17:18:26,179 |	  model_v_in_main test loss : 0.992586
2021-12-27 17:18:26,184 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1561, 0.1561, 0.1561,  ..., 0.1561, 0.1561, 0.1561], device='cuda:0',
       requires_grad=True))
2021-12-27 17:18:26,186 |	  Step count: 30
2021-12-27 17:19:08,025 |	  loss_w (train):1.0387811926193535e-06
2021-12-27 17:19:17,162 |	  v_loss (train):102.3975601196289
2021-12-27 17:19:19,294 |	  model_w_in_main test loss : 0.838527
2021-12-27 17:19:19,409 |	  model_v_in_main test loss : 0.956221
2021-12-27 17:19:19,417 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1575, 0.1575, 0.1575,  ..., 0.1575, 0.1575, 0.1575], device='cuda:0',
       requires_grad=True))
2021-12-27 17:19:19,420 |	  Step count: 31
2021-12-27 17:19:56,281 |	  loss_w (train):0.00036421374534256756
2021-12-27 17:20:04,523 |	  v_loss (train):21.30205535888672
2021-12-27 17:20:06,506 |	  model_w_in_main test loss : 0.838412
2021-12-27 17:20:06,620 |	  model_v_in_main test loss : 0.940064
2021-12-27 17:20:06,626 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1506, 0.1506, 0.1506,  ..., 0.1506, 0.1506, 0.1506], device='cuda:0',
       requires_grad=True))
2021-12-27 17:20:06,628 |	  Step count: 32
2021-12-27 17:20:52,404 |	  loss_w (train):8.594994937993761e-07
2021-12-27 17:21:03,728 |	  v_loss (train):99.95440673828125
2021-12-27 17:21:05,690 |	  model_w_in_main test loss : 0.838303
2021-12-27 17:21:06,092 |	  model_v_in_main test loss : 0.941002
2021-12-27 17:21:06,099 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.2497, 0.2497, 0.2497,  ..., 0.2497, 0.2497, 0.2497], device='cuda:0',
       requires_grad=True))
2021-12-27 17:21:06,102 |	  Step count: 33
2021-12-27 17:21:36,916 |	  loss_w (train):0.0006498167640529573
2021-12-27 17:21:43,147 |	  v_loss (train):72.98421478271484
2021-12-27 17:21:45,052 |	  model_w_in_main test loss : 0.838655
2021-12-27 17:21:45,198 |	  model_v_in_main test loss : 0.914372
2021-12-27 17:21:45,204 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.2642, 0.2642, 0.2642,  ..., 0.2642, 0.2642, 0.2642], device='cuda:0',
       requires_grad=True))
2021-12-27 17:21:45,207 |	  Step count: 34
2021-12-27 17:22:05,522 |	  loss_w (train):0.0027674445882439613
2021-12-27 17:22:08,181 |	  v_loss (train):17.469463348388672
2021-12-27 17:22:10,095 |	  model_w_in_main test loss : 0.838965
2021-12-27 17:22:10,561 |	  model_v_in_main test loss : 0.958918
2021-12-27 17:22:10,570 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.2159, 0.2159, 0.2159,  ..., 0.2159, 0.2159, 0.2159], device='cuda:0',
       requires_grad=True))
2021-12-27 17:22:10,572 |	  Step count: 35
2021-12-27 17:23:11,355 |	  loss_w (train):8.075183359324e-06
2021-12-27 17:23:25,530 |	  v_loss (train):61.100914001464844
2021-12-27 17:23:27,594 |	  model_w_in_main test loss : 0.838979
2021-12-27 17:23:28,142 |	  model_v_in_main test loss : 0.953142
2021-12-27 17:23:28,149 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.1682, 0.1682, 0.1682,  ..., 0.1682, 0.1682, 0.1682], device='cuda:0',
       requires_grad=True))
2021-12-27 17:23:28,151 |	  Step count: 36
2021-12-27 17:23:50,353 |	  loss_w (train):1.0555139624557341e-06
2021-12-27 17:23:54,043 |	  v_loss (train):21.782068252563477
2021-12-27 17:23:56,038 |	  model_w_in_main test loss : 0.838926
2021-12-27 17:23:56,595 |	  model_v_in_main test loss : 0.985562
2021-12-27 17:23:56,601 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.2457, 0.2457, 0.2457,  ..., 0.2457, 0.2457, 0.2457], device='cuda:0',
       requires_grad=True))
2021-12-27 17:23:56,603 |	  Step count: 37
2021-12-27 17:24:54,036 |	  loss_w (train):0.00016255310038104653
2021-12-27 17:25:09,785 |	  v_loss (train):100.96376037597656
2021-12-27 17:25:11,703 |	  model_w_in_main test loss : 0.838769
2021-12-27 17:25:12,254 |	  model_v_in_main test loss : 0.988368
2021-12-27 17:25:12,260 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.3634, 0.3634, 0.3634,  ..., 0.3634, 0.3634, 0.3634], device='cuda:0',
       requires_grad=True))
2021-12-27 17:25:12,262 |	  Step count: 38
2021-12-27 17:25:58,245 |	  loss_w (train):0.0006869379431009293
2021-12-27 17:26:04,069 |	  v_loss (train):26.849578857421875
2021-12-27 17:26:06,078 |	  model_w_in_main test loss : 0.838947
2021-12-27 17:26:06,587 |	  model_v_in_main test loss : 0.984602
2021-12-27 17:26:06,591 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.4047, 0.4047, 0.4047,  ..., 0.4047, 0.4047, 0.4047], device='cuda:0',
       requires_grad=True))
2021-12-27 17:26:06,594 |	  Step count: 39
2021-12-27 17:27:14,243 |	  loss_w (train):0.0003538759774528444
2021-12-27 17:27:30,724 |	  v_loss (train):157.7921905517578
2021-12-27 17:27:32,837 |	  model_w_in_main test loss : 0.838934
2021-12-27 17:27:33,266 |	  model_v_in_main test loss : 0.972445
2021-12-27 17:27:33,270 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.4164, 0.4164, 0.4164,  ..., 0.4164, 0.4164, 0.4164], device='cuda:0',
       requires_grad=True))
2021-12-27 17:27:33,272 |	  Step count: 40
2021-12-27 17:28:09,954 |	  loss_w (train):1.7024483440764016e-06
2021-12-27 17:28:18,318 |	  v_loss (train):39.9073600769043
2021-12-27 17:28:20,225 |	  model_w_in_main test loss : 0.838932
2021-12-27 17:28:20,331 |	  model_v_in_main test loss : 0.950191
2021-12-27 17:28:20,334 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.6392, 0.6392, 0.6392,  ..., 0.6392, 0.6392, 0.6392], device='cuda:0',
       requires_grad=True))
2021-12-27 17:28:20,336 |	  Step count: 41
2021-12-27 17:29:28,266 |	  loss_w (train):8.053646160988137e-05
2021-12-27 17:29:43,675 |	  v_loss (train):127.069580078125
2021-12-27 17:29:46,106 |	  model_w_in_main test loss : 0.838975
2021-12-27 17:29:46,236 |	  model_v_in_main test loss : 0.967132
2021-12-27 17:29:46,256 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.7582, 0.7582, 0.7582,  ..., 0.7582, 0.7582, 0.7582], device='cuda:0',
       requires_grad=True))
2021-12-27 17:29:46,258 |	  Step count: 42
2021-12-27 17:31:15,288 |	  loss_w (train):1.4998899132478982e-05
2021-12-27 17:31:39,489 |	  v_loss (train):247.21160888671875
2021-12-27 17:31:41,555 |	  model_w_in_main test loss : 0.838942
2021-12-27 17:31:42,048 |	  model_v_in_main test loss : 1.005385
2021-12-27 17:31:42,054 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8246, 0.8246, 0.8246,  ..., 0.8246, 0.8246, 0.8246], device='cuda:0',
       requires_grad=True))
2021-12-27 17:31:42,056 |	  Step count: 43
2021-12-27 17:32:40,574 |	  loss_w (train):4.852287460721527e-09
2021-12-27 17:32:53,932 |	  v_loss (train):73.9991226196289
2021-12-27 17:32:55,489 |	  model_w_in_main test loss : 0.838965
2021-12-27 17:32:55,924 |	  model_v_in_main test loss : 0.956513
2021-12-27 17:32:55,929 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8581, 0.8581, 0.8581,  ..., 0.8581, 0.8581, 0.8581], device='cuda:0',
       requires_grad=True))
2021-12-27 17:32:55,931 |	  Step count: 44
2021-12-27 17:33:53,820 |	  loss_w (train):2.4821787292239605e-08
2021-12-27 17:34:08,436 |	  v_loss (train):108.32884216308594
2021-12-27 17:34:10,408 |	  model_w_in_main test loss : 0.838944
2021-12-27 17:34:10,947 |	  model_v_in_main test loss : 0.914994
2021-12-27 17:34:10,953 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8751, 0.8751, 0.8751,  ..., 0.8751, 0.8751, 0.8751], device='cuda:0',
       requires_grad=True))
2021-12-27 17:34:10,956 |	  Step count: 45
2021-12-27 17:34:45,365 |	  loss_w (train):2.485677885744053e-09
2021-12-27 17:34:51,820 |	  v_loss (train):46.28276062011719
2021-12-27 17:34:53,902 |	  model_w_in_main test loss : 0.838950
2021-12-27 17:34:54,417 |	  model_v_in_main test loss : 0.928069
2021-12-27 17:34:54,422 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8837, 0.8837, 0.8837,  ..., 0.8837, 0.8837, 0.8837], device='cuda:0',
       requires_grad=True))
2021-12-27 17:34:54,424 |	  Step count: 46
2021-12-27 17:35:17,398 |	  loss_w (train):1.9616982172010466e-07
2021-12-27 17:35:20,573 |	  v_loss (train):14.526777267456055
2021-12-27 17:35:22,545 |	  model_w_in_main test loss : 0.838965
2021-12-27 17:35:23,086 |	  model_v_in_main test loss : 0.921564
2021-12-27 17:35:23,092 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8880, 0.8880, 0.8880,  ..., 0.8880, 0.8880, 0.8880], device='cuda:0',
       requires_grad=True))
2021-12-27 17:35:23,094 |	  Step count: 47
2021-12-27 17:36:30,018 |	  loss_w (train):2.244292716113705e-07
2021-12-27 17:36:49,029 |	  v_loss (train):122.65213012695312
2021-12-27 17:36:51,212 |	  model_w_in_main test loss : 0.838945
2021-12-27 17:36:51,571 |	  model_v_in_main test loss : 0.931222
2021-12-27 17:36:51,576 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8902, 0.8902, 0.8902,  ..., 0.8902, 0.8902, 0.8902], device='cuda:0',
       requires_grad=True))
2021-12-27 17:36:51,578 |	  Step count: 48
2021-12-27 17:37:44,068 |	  loss_w (train):1.3261730202884792e-07
2021-12-27 17:37:56,095 |	  v_loss (train):92.79684448242188
2021-12-27 17:37:57,518 |	  model_w_in_main test loss : 0.838937
2021-12-27 17:37:57,746 |	  model_v_in_main test loss : 0.922308
2021-12-27 17:37:57,750 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8913, 0.8913, 0.8913,  ..., 0.8913, 0.8913, 0.8913], device='cuda:0',
       requires_grad=True))
2021-12-27 17:37:57,752 |	  Step count: 49
2021-12-27 17:38:21,064 |	  loss_w (train):1.3289833233898207e-08
2021-12-27 17:38:29,547 |	  v_loss (train):3.427809476852417
2021-12-27 17:38:31,155 |	  model_w_in_main test loss : 0.838907
2021-12-27 17:38:31,377 |	  model_v_in_main test loss : 0.946978
2021-12-27 17:38:31,430 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8919, 0.8919, 0.8919,  ..., 0.8919, 0.8919, 0.8919], device='cuda:0',
       requires_grad=True))
2021-12-27 17:38:31,432 |	  Step count: 50
2021-12-27 17:39:00,425 |	  loss_w (train):3.873525145081658e-08
2021-12-27 17:39:06,725 |	  v_loss (train):10.461463928222656
2021-12-27 17:39:08,747 |	  model_w_in_main test loss : 0.838916
2021-12-27 17:39:08,903 |	  model_v_in_main test loss : 0.929040
2021-12-27 17:39:08,911 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8922, 0.8922, 0.8922,  ..., 0.8922, 0.8922, 0.8922], device='cuda:0',
       requires_grad=True))
2021-12-27 17:39:08,913 |	  Step count: 51
2021-12-27 17:40:44,608 |	  loss_w (train):2.6086163984473387e-07
2021-12-27 17:41:10,066 |	  v_loss (train):204.2079315185547
2021-12-27 17:41:12,429 |	  model_w_in_main test loss : 0.839041
2021-12-27 17:41:12,589 |	  model_v_in_main test loss : 0.919609
2021-12-27 17:41:12,593 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8923, 0.8923, 0.8923,  ..., 0.8923, 0.8923, 0.8923], device='cuda:0',
       requires_grad=True))
2021-12-27 17:41:12,596 |	  Step count: 52
2021-12-27 17:42:10,291 |	  loss_w (train):4.379125186915189e-07
2021-12-27 17:42:24,238 |	  v_loss (train):105.88472747802734
2021-12-27 17:42:26,314 |	  model_w_in_main test loss : 0.838893
2021-12-27 17:42:26,795 |	  model_v_in_main test loss : 0.949652
2021-12-27 17:42:26,801 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8924, 0.8924, 0.8924,  ..., 0.8924, 0.8924, 0.8924], device='cuda:0',
       requires_grad=True))
2021-12-27 17:42:26,803 |	  Step count: 53
2021-12-27 17:43:02,164 |	  loss_w (train):3.131002301870467e-08
2021-12-27 17:43:09,063 |	  v_loss (train):65.50611877441406
2021-12-27 17:43:10,992 |	  model_w_in_main test loss : 0.838866
2021-12-27 17:43:11,501 |	  model_v_in_main test loss : 0.897571
2021-12-27 17:43:11,527 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8924, 0.8924, 0.8924,  ..., 0.8924, 0.8924, 0.8924], device='cuda:0',
       requires_grad=True))
2021-12-27 17:43:11,529 |	  Step count: 54
2021-12-27 17:43:55,632 |	  loss_w (train):1.0703810282564064e-08
2021-12-27 17:44:04,155 |	  v_loss (train):34.96417236328125
2021-12-27 17:44:06,192 |	  model_w_in_main test loss : 0.838951
2021-12-27 17:44:06,686 |	  model_v_in_main test loss : 0.991922
2021-12-27 17:44:06,692 |	  ('Attention Weights A : ', Parameter containing:
tensor([0.8924, 0.1583, 0.8924,  ..., 0.8924, 0.8924, 0.8924], device='cuda:0',
       requires_grad=True))
2021-12-27 17:44:06,694 |	  Step count: 55
2021-12-27 17:44:39,706 |	  loss_w (train):2.6842443823227313e-09
2021-12-27 17:44:45,027 |	  v_loss (train):40.30362319946289
2021-12-27 17:44:46,578 |	  model_w_in_main test loss : 0.839014
2021-12-27 17:44:47,043 |	  model_v_in_main test loss : 0.917265
2021-12-27 17:44:47,048 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8924, -0.2122,  0.8924,  ...,  0.8924,  0.8924,  0.8924],
       device='cuda:0', requires_grad=True))
2021-12-27 17:44:47,050 |	  Step count: 56
2021-12-27 17:45:08,986 |	  loss_w (train):2.802102105903259e-09
2021-12-27 17:45:12,153 |	  v_loss (train):27.276830673217773
2021-12-27 17:45:14,134 |	  model_w_in_main test loss : 0.838965
2021-12-27 17:45:14,650 |	  model_v_in_main test loss : 0.897049
2021-12-27 17:45:14,656 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8924, -0.3992,  0.8924,  ...,  0.8924,  0.8924,  0.8924],
       device='cuda:0', requires_grad=True))
2021-12-27 17:45:14,658 |	  Step count: 57
2021-12-27 17:46:24,928 |	  loss_w (train):4.1532183558956604e-07
2021-12-27 17:46:43,968 |	  v_loss (train):111.80754852294922
2021-12-27 17:46:46,200 |	  model_w_in_main test loss : 0.838945
2021-12-27 17:46:46,322 |	  model_v_in_main test loss : 0.894778
2021-12-27 17:46:46,326 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8924, -0.4935,  0.8924,  ...,  0.8924,  0.8924,  0.8924],
       device='cuda:0', requires_grad=True))
2021-12-27 17:46:46,328 |	  Step count: 58
2021-12-27 17:47:31,469 |	  loss_w (train):9.432859826574713e-08
2021-12-27 17:47:38,710 |	  v_loss (train):47.77951431274414
2021-12-27 17:47:40,695 |	  model_w_in_main test loss : 0.838903
2021-12-27 17:47:41,264 |	  model_v_in_main test loss : 0.921254
2021-12-27 17:47:41,269 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8924, -0.5411,  0.8924,  ...,  0.8924,  0.8924,  0.8924],
       device='cuda:0', requires_grad=True))
2021-12-27 17:47:41,271 |	  Step count: 59
2021-12-27 17:48:49,936 |	  loss_w (train):1.1718761072643247e-08
2021-12-27 17:49:02,737 |	  v_loss (train):118.04074096679688
2021-12-27 17:49:04,586 |	  model_w_in_main test loss : 0.838903
2021-12-27 17:49:05,101 |	  model_v_in_main test loss : 0.974878
2021-12-27 17:49:05,105 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8924, -0.5651,  0.8924,  ...,  0.8924,  0.8924,  0.8924],
       device='cuda:0', requires_grad=True))
2021-12-27 17:49:05,107 |	  Step count: 60
2021-12-27 17:49:26,466 |	  loss_w (train):6.44852793385553e-09
2021-12-27 17:49:34,526 |	  v_loss (train):12.701045989990234
2021-12-27 17:49:36,653 |	  model_w_in_main test loss : 0.838925
2021-12-27 17:49:36,750 |	  model_v_in_main test loss : 0.985935
2021-12-27 17:49:36,754 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5772,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:49:36,756 |	  Step count: 61
2021-12-27 17:50:02,493 |	  loss_w (train):7.927132839036233e-10
2021-12-27 17:50:06,384 |	  v_loss (train):34.09624481201172
2021-12-27 17:50:08,336 |	  model_w_in_main test loss : 0.838864
2021-12-27 17:50:08,438 |	  model_v_in_main test loss : 0.973156
2021-12-27 17:50:08,441 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5833,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:50:08,442 |	  Step count: 62
2021-12-27 17:50:32,432 |	  loss_w (train):5.479829567889283e-08
2021-12-27 17:50:35,792 |	  v_loss (train):6.8729753494262695
2021-12-27 17:50:37,460 |	  model_w_in_main test loss : 0.838885
2021-12-27 17:50:37,514 |	  model_v_in_main test loss : 0.988089
2021-12-27 17:50:37,517 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5863,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:50:37,519 |	  Step count: 63
2021-12-27 17:51:19,539 |	  loss_w (train):7.87482292707864e-08
2021-12-27 17:51:28,380 |	  v_loss (train):66.13677978515625
2021-12-27 17:51:30,305 |	  model_w_in_main test loss : 0.838953
2021-12-27 17:51:30,436 |	  model_v_in_main test loss : 0.977801
2021-12-27 17:51:30,440 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5879,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:51:30,442 |	  Step count: 64
2021-12-27 17:51:57,887 |	  loss_w (train):6.997693091648216e-09
2021-12-27 17:52:00,358 |	  v_loss (train):5.6799421310424805
2021-12-27 17:52:01,291 |	  model_w_in_main test loss : 0.838873
2021-12-27 17:52:01,771 |	  model_v_in_main test loss : 0.977380
2021-12-27 17:52:01,777 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5887,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:52:01,779 |	  Step count: 65
2021-12-27 17:52:22,992 |	  loss_w (train):2.789387831825252e-09
2021-12-27 17:52:25,032 |	  v_loss (train):6.5657243728637695
2021-12-27 17:52:26,936 |	  model_w_in_main test loss : 0.838915
2021-12-27 17:52:27,476 |	  model_v_in_main test loss : 0.995233
2021-12-27 17:52:27,490 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5891,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:52:27,492 |	  Step count: 66
2021-12-27 17:53:27,450 |	  loss_w (train):2.133794474445949e-09
2021-12-27 17:53:42,329 |	  v_loss (train):74.54027557373047
2021-12-27 17:53:43,799 |	  model_w_in_main test loss : 0.838923
2021-12-27 17:53:43,904 |	  model_v_in_main test loss : 1.019497
2021-12-27 17:53:43,907 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5893,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:53:43,909 |	  Step count: 67
2021-12-27 17:54:05,934 |	  loss_w (train):5.019080617785221e-08
2021-12-27 17:54:08,555 |	  v_loss (train):2.191267251968384
2021-12-27 17:54:10,513 |	  model_w_in_main test loss : 0.838931
2021-12-27 17:54:10,621 |	  model_v_in_main test loss : 1.015532
2021-12-27 17:54:10,625 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5894,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:54:10,627 |	  Step count: 68
2021-12-27 17:54:45,302 |	  loss_w (train):9.774855591615506e-09
2021-12-27 17:54:54,082 |	  v_loss (train):48.50720977783203
2021-12-27 17:54:55,540 |	  model_w_in_main test loss : 0.838987
2021-12-27 17:54:56,035 |	  model_v_in_main test loss : 0.994622
2021-12-27 17:54:56,043 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5894,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:54:56,045 |	  Step count: 69
2021-12-27 17:55:16,625 |	  loss_w (train):1.7536009977447975e-08
2021-12-27 17:55:19,204 |	  v_loss (train):1.9673690795898438
2021-12-27 17:55:21,142 |	  model_w_in_main test loss : 0.839013
2021-12-27 17:55:21,676 |	  model_v_in_main test loss : 0.998744
2021-12-27 17:55:21,682 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5894,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:55:21,684 |	  Step count: 70
2021-12-27 17:55:58,302 |	  loss_w (train):7.115799860457628e-08
2021-12-27 17:56:04,685 |	  v_loss (train):44.74223709106445
2021-12-27 17:56:06,627 |	  model_w_in_main test loss : 0.838856
2021-12-27 17:56:06,742 |	  model_v_in_main test loss : 0.981612
2021-12-27 17:56:06,747 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5894,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:56:06,749 |	  Step count: 71
2021-12-27 17:56:57,274 |	  loss_w (train):5.621784371356853e-09
2021-12-27 17:57:10,178 |	  v_loss (train):98.8622817993164
2021-12-27 17:57:12,251 |	  model_w_in_main test loss : 0.838901
2021-12-27 17:57:12,767 |	  model_v_in_main test loss : 0.988347
2021-12-27 17:57:12,771 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5894,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:57:12,773 |	  Step count: 72
2021-12-27 17:57:58,126 |	  loss_w (train):4.3468325827689114e-08
2021-12-27 17:58:07,801 |	  v_loss (train):33.896244049072266
2021-12-27 17:58:09,780 |	  model_w_in_main test loss : 0.838888
2021-12-27 17:58:10,357 |	  model_v_in_main test loss : 0.958811
2021-12-27 17:58:10,362 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5894,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:58:10,364 |	  Step count: 73
2021-12-27 17:59:32,452 |	  loss_w (train):2.648699926055542e-09
2021-12-27 17:59:55,129 |	  v_loss (train):178.7995147705078
2021-12-27 17:59:57,540 |	  model_w_in_main test loss : 0.838981
2021-12-27 17:59:57,674 |	  model_v_in_main test loss : 0.984935
2021-12-27 17:59:57,679 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5894,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 17:59:57,681 |	  Step count: 74
2021-12-27 18:00:48,885 |	  loss_w (train):2.2884814043777624e-09
2021-12-27 18:01:00,710 |	  v_loss (train):68.71014404296875
2021-12-27 18:01:02,590 |	  model_w_in_main test loss : 0.838940
2021-12-27 18:01:02,736 |	  model_v_in_main test loss : 1.014520
2021-12-27 18:01:02,742 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5894,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:01:02,744 |	  Step count: 75
2021-12-27 18:02:01,233 |	  loss_w (train):7.878496077751151e-09
2021-12-27 18:02:11,468 |	  v_loss (train):86.4457778930664
2021-12-27 18:02:13,278 |	  model_w_in_main test loss : 0.838924
2021-12-27 18:02:13,420 |	  model_v_in_main test loss : 0.964424
2021-12-27 18:02:13,428 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:02:13,430 |	  Step count: 76
2021-12-27 18:02:51,318 |	  loss_w (train):1.5925637697478123e-08
2021-12-27 18:02:57,701 |	  v_loss (train):69.9246826171875
2021-12-27 18:02:59,630 |	  model_w_in_main test loss : 0.838914
2021-12-27 18:03:00,162 |	  model_v_in_main test loss : 0.963962
2021-12-27 18:03:00,168 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:03:00,170 |	  Step count: 77
2021-12-27 18:03:38,153 |	  loss_w (train):2.433091239595342e-08
2021-12-27 18:03:46,793 |	  v_loss (train):29.151548385620117
2021-12-27 18:03:48,745 |	  model_w_in_main test loss : 0.838924
2021-12-27 18:03:48,873 |	  model_v_in_main test loss : 1.035216
2021-12-27 18:03:48,891 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:03:48,894 |	  Step count: 78
2021-12-27 18:04:27,972 |	  loss_w (train):1.3365542450571866e-08
2021-12-27 18:04:31,487 |	  v_loss (train):8.990880012512207
2021-12-27 18:04:33,148 |	  model_w_in_main test loss : 0.838874
2021-12-27 18:04:33,676 |	  model_v_in_main test loss : 1.009763
2021-12-27 18:04:33,683 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:04:33,685 |	  Step count: 79
2021-12-27 18:05:04,450 |	  loss_w (train):3.602611897690622e-08
2021-12-27 18:05:12,005 |	  v_loss (train):3.522054433822632
2021-12-27 18:05:13,892 |	  model_w_in_main test loss : 0.838891
2021-12-27 18:05:14,433 |	  model_v_in_main test loss : 1.009210
2021-12-27 18:05:14,439 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:05:14,441 |	  Step count: 80
2021-12-27 18:05:40,930 |	  loss_w (train):3.817184079935032e-08
2021-12-27 18:05:45,971 |	  v_loss (train):46.724327087402344
2021-12-27 18:05:47,928 |	  model_w_in_main test loss : 0.838951
2021-12-27 18:05:48,477 |	  model_v_in_main test loss : 1.019090
2021-12-27 18:05:48,484 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:05:48,486 |	  Step count: 81
2021-12-27 18:07:12,059 |	  loss_w (train):1.134011284875669e-07
2021-12-27 18:07:37,044 |	  v_loss (train):132.5987548828125
2021-12-27 18:07:39,447 |	  model_w_in_main test loss : 0.838937
2021-12-27 18:07:39,620 |	  model_v_in_main test loss : 1.053783
2021-12-27 18:07:39,627 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:07:39,629 |	  Step count: 82
2021-12-27 18:08:26,029 |	  loss_w (train):5.848890261006545e-09
2021-12-27 18:08:38,082 |	  v_loss (train):109.18386840820312
2021-12-27 18:08:39,949 |	  model_w_in_main test loss : 0.838855
2021-12-27 18:08:40,452 |	  model_v_in_main test loss : 1.108693
2021-12-27 18:08:40,457 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:08:40,459 |	  Step count: 83
2021-12-27 18:09:10,149 |	  loss_w (train):8.654388317097528e-09
2021-12-27 18:09:19,562 |	  v_loss (train):22.839832305908203
2021-12-27 18:09:21,937 |	  model_w_in_main test loss : 0.838992
2021-12-27 18:09:22,073 |	  model_v_in_main test loss : 1.088382
2021-12-27 18:09:22,077 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:09:22,079 |	  Step count: 84
2021-12-27 18:10:06,207 |	  loss_w (train):2.0882968243540745e-08
2021-12-27 18:10:15,155 |	  v_loss (train):66.83231353759766
2021-12-27 18:10:17,072 |	  model_w_in_main test loss : 0.838962
2021-12-27 18:10:17,463 |	  model_v_in_main test loss : 1.077615
2021-12-27 18:10:17,517 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:10:17,519 |	  Step count: 85
2021-12-27 18:10:54,797 |	  loss_w (train):2.8139868213372665e-09
2021-12-27 18:11:02,408 |	  v_loss (train):61.28788757324219
2021-12-27 18:11:04,272 |	  model_w_in_main test loss : 0.838949
2021-12-27 18:11:04,825 |	  model_v_in_main test loss : 1.102234
2021-12-27 18:11:04,830 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:11:04,832 |	  Step count: 86
2021-12-27 18:12:29,828 |	  loss_w (train):1.0855035981194305e-08
2021-12-27 18:12:53,568 |	  v_loss (train):182.032958984375
2021-12-27 18:12:55,599 |	  model_w_in_main test loss : 0.838948
2021-12-27 18:12:56,076 |	  model_v_in_main test loss : 1.028277
2021-12-27 18:12:56,080 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:12:56,083 |	  Step count: 87
2021-12-27 18:13:51,011 |	  loss_w (train):4.046368218268981e-08
2021-12-27 18:14:04,131 |	  v_loss (train):86.62155151367188
2021-12-27 18:14:04,616 |	  model_w_in_main test loss : 0.839004
2021-12-27 18:14:04,768 |	  model_v_in_main test loss : 1.014059
2021-12-27 18:14:04,772 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:14:04,774 |	  Step count: 88
2021-12-27 18:14:58,325 |	  loss_w (train):3.265584691547474e-09
2021-12-27 18:15:10,487 |	  v_loss (train):99.88706970214844
2021-12-27 18:15:12,444 |	  model_w_in_main test loss : 0.838945
2021-12-27 18:15:13,009 |	  model_v_in_main test loss : 1.000311
2021-12-27 18:15:13,015 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:15:13,017 |	  Step count: 89
2021-12-27 18:15:33,017 |	  loss_w (train):6.230072457924507e-09
2021-12-27 18:15:38,015 |	  v_loss (train):0.7942318320274353
2021-12-27 18:15:39,803 |	  model_w_in_main test loss : 0.838872
2021-12-27 18:15:39,956 |	  model_v_in_main test loss : 1.027929
2021-12-27 18:15:39,960 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:15:39,962 |	  Step count: 90
2021-12-27 18:16:01,015 |	  loss_w (train):5.1771465336969413e-08
2021-12-27 18:16:07,406 |	  v_loss (train):0.7115892171859741
2021-12-27 18:16:09,290 |	  model_w_in_main test loss : 0.838897
2021-12-27 18:16:09,423 |	  model_v_in_main test loss : 1.025960
2021-12-27 18:16:09,427 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:16:09,429 |	  Step count: 91
2021-12-27 18:16:42,297 |	  loss_w (train):1.1937270727457872e-08
2021-12-27 18:16:49,376 |	  v_loss (train):5.961531639099121
2021-12-27 18:16:51,309 |	  model_w_in_main test loss : 0.838965
2021-12-27 18:16:51,894 |	  model_v_in_main test loss : 1.047708
2021-12-27 18:16:51,902 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:16:51,904 |	  Step count: 92
2021-12-27 18:18:06,966 |	  loss_w (train):1.5787129825639568e-07
2021-12-27 18:18:28,293 |	  v_loss (train):233.50250244140625
2021-12-27 18:18:30,181 |	  model_w_in_main test loss : 0.838918
2021-12-27 18:18:30,702 |	  model_v_in_main test loss : 1.057689
2021-12-27 18:18:30,705 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:18:30,707 |	  Step count: 93
2021-12-27 18:19:30,291 |	  loss_w (train):7.524417533488759e-09
2021-12-27 18:19:43,682 |	  v_loss (train):75.43803405761719
2021-12-27 18:19:44,972 |	  model_w_in_main test loss : 0.838962
2021-12-27 18:19:45,028 |	  model_v_in_main test loss : 1.039000
2021-12-27 18:19:45,031 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:19:45,033 |	  Step count: 94
2021-12-27 18:21:14,297 |	  loss_w (train):1.5779926343384432e-07
2021-12-27 18:21:39,184 |	  v_loss (train):124.9422607421875
2021-12-27 18:21:41,118 |	  model_w_in_main test loss : 0.838926
2021-12-27 18:21:41,561 |	  model_v_in_main test loss : 1.047554
2021-12-27 18:21:41,569 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:21:41,571 |	  Step count: 95
2021-12-27 18:22:54,488 |	  loss_w (train):3.212247889905484e-08
2021-12-27 18:23:08,838 |	  v_loss (train):222.57139587402344
2021-12-27 18:23:10,829 |	  model_w_in_main test loss : 0.838928
2021-12-27 18:23:11,423 |	  model_v_in_main test loss : 1.015112
2021-12-27 18:23:11,428 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:23:11,430 |	  Step count: 96
2021-12-27 18:23:52,304 |	  loss_w (train):2.5673841719253687e-08
2021-12-27 18:24:00,027 |	  v_loss (train):44.57276916503906
2021-12-27 18:24:01,917 |	  model_w_in_main test loss : 0.838939
2021-12-27 18:24:02,493 |	  model_v_in_main test loss : 1.075951
2021-12-27 18:24:02,499 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:24:02,501 |	  Step count: 97
2021-12-27 18:25:02,044 |	  loss_w (train):7.599267881630567e-09
2021-12-27 18:25:14,454 |	  v_loss (train):139.36509704589844
2021-12-27 18:25:16,403 |	  model_w_in_main test loss : 0.838995
2021-12-27 18:25:16,970 |	  model_v_in_main test loss : 1.030900
2021-12-27 18:25:16,976 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:25:16,978 |	  Step count: 98
2021-12-27 18:25:39,281 |	  loss_w (train):3.6497527222678627e-09
2021-12-27 18:25:42,490 |	  v_loss (train):13.190770149230957
2021-12-27 18:25:44,347 |	  model_w_in_main test loss : 0.838924
2021-12-27 18:25:44,561 |	  model_v_in_main test loss : 1.019192
2021-12-27 18:25:44,578 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:25:44,580 |	  Step count: 99
2021-12-27 18:26:33,384 |	  loss_w (train):9.371747822228826e-09
2021-12-27 18:26:45,102 |	  v_loss (train):43.61609649658203
2021-12-27 18:26:47,101 |	  model_w_in_main test loss : 0.838966
2021-12-27 18:26:47,207 |	  model_v_in_main test loss : 1.031671
2021-12-27 18:26:47,213 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:26:47,215 |	  Step count: 100
2021-12-27 18:27:31,528 |	  loss_w (train):3.727200326153479e-09
2021-12-27 18:27:40,940 |	  v_loss (train):52.7911376953125
2021-12-27 18:27:42,954 |	  model_w_in_main test loss : 0.838909
2021-12-27 18:27:43,436 |	  model_v_in_main test loss : 1.032547
2021-12-27 18:27:43,442 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:27:43,445 |	  Step count: 101
2021-12-27 18:28:14,430 |	  loss_w (train):4.1700850772485865e-08
2021-12-27 18:28:17,554 |	  v_loss (train):22.96752166748047
2021-12-27 18:28:19,557 |	  model_w_in_main test loss : 0.838941
2021-12-27 18:28:20,084 |	  model_v_in_main test loss : 1.045487
2021-12-27 18:28:20,088 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:28:20,090 |	  Step count: 102
2021-12-27 18:28:50,235 |	  loss_w (train):7.4108612579948385e-09
2021-12-27 18:28:56,181 |	  v_loss (train):30.82402801513672
2021-12-27 18:28:58,077 |	  model_w_in_main test loss : 0.838924
2021-12-27 18:28:58,581 |	  model_v_in_main test loss : 1.020759
2021-12-27 18:28:58,587 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:28:58,589 |	  Step count: 103
2021-12-27 18:30:08,178 |	  loss_w (train):8.84251782906631e-09
2021-12-27 18:30:24,125 |	  v_loss (train):121.802978515625
2021-12-27 18:30:25,556 |	  model_w_in_main test loss : 0.838976
2021-12-27 18:30:26,057 |	  model_v_in_main test loss : 1.005886
2021-12-27 18:30:26,061 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:30:26,063 |	  Step count: 104
2021-12-27 18:30:55,281 |	  loss_w (train):6.050932910284246e-08
2021-12-27 18:31:03,557 |	  v_loss (train):1.6887412071228027
2021-12-27 18:31:05,909 |	  model_w_in_main test loss : 0.838978
2021-12-27 18:31:06,046 |	  model_v_in_main test loss : 1.044280
2021-12-27 18:31:06,050 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:31:06,052 |	  Step count: 105
2021-12-27 18:32:10,146 |	  loss_w (train):2.1495997870601968e-08
2021-12-27 18:32:26,093 |	  v_loss (train):85.79460144042969
2021-12-27 18:32:27,943 |	  model_w_in_main test loss : 0.838934
2021-12-27 18:32:28,460 |	  model_v_in_main test loss : 1.089266
2021-12-27 18:32:28,466 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:32:28,468 |	  Step count: 106
2021-12-27 18:33:05,667 |	  loss_w (train):1.9498400671835725e-09
2021-12-27 18:33:13,811 |	  v_loss (train):20.72459602355957
2021-12-27 18:33:15,912 |	  model_w_in_main test loss : 0.838828
2021-12-27 18:33:16,407 |	  model_v_in_main test loss : 1.115725
2021-12-27 18:33:16,413 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:33:16,415 |	  Step count: 107
2021-12-27 18:33:44,798 |	  loss_w (train):3.407583903936029e-08
2021-12-27 18:33:49,979 |	  v_loss (train):48.78274154663086
2021-12-27 18:33:51,391 |	  model_w_in_main test loss : 0.838974
2021-12-27 18:33:51,539 |	  model_v_in_main test loss : 1.024150
2021-12-27 18:33:51,545 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:33:51,547 |	  Step count: 108
2021-12-27 18:34:48,430 |	  loss_w (train):5.6295654360383196e-08
2021-12-27 18:35:04,040 |	  v_loss (train):88.38186645507812
2021-12-27 18:35:05,625 |	  model_w_in_main test loss : 0.838899
2021-12-27 18:35:06,179 |	  model_v_in_main test loss : 1.029989
2021-12-27 18:35:06,186 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:35:06,188 |	  Step count: 109
2021-12-27 18:35:41,176 |	  loss_w (train):1.199807986296264e-08
2021-12-27 18:35:48,361 |	  v_loss (train):43.61334228515625
2021-12-27 18:35:50,793 |	  model_w_in_main test loss : 0.838834
2021-12-27 18:35:50,965 |	  model_v_in_main test loss : 1.033607
2021-12-27 18:35:50,981 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:35:50,983 |	  Step count: 110
2021-12-27 18:36:59,470 |	  loss_w (train):3.097805745255755e-08
2021-12-27 18:37:18,446 |	  v_loss (train):142.91285705566406
2021-12-27 18:37:19,890 |	  model_w_in_main test loss : 0.838952
2021-12-27 18:37:20,103 |	  model_v_in_main test loss : 1.011334
2021-12-27 18:37:20,107 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:37:20,109 |	  Step count: 111
2021-12-27 18:38:04,194 |	  loss_w (train):6.42129620587184e-08
2021-12-27 18:38:11,166 |	  v_loss (train):85.48204040527344
2021-12-27 18:38:13,177 |	  model_w_in_main test loss : 0.838948
2021-12-27 18:38:13,726 |	  model_v_in_main test loss : 1.001807
2021-12-27 18:38:13,733 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:38:13,735 |	  Step count: 112
2021-12-27 18:38:43,633 |	  loss_w (train):5.108096723382971e-10
2021-12-27 18:38:48,624 |	  v_loss (train):8.479679107666016
2021-12-27 18:38:50,642 |	  model_w_in_main test loss : 0.838978
2021-12-27 18:38:51,209 |	  model_v_in_main test loss : 0.990455
2021-12-27 18:38:51,215 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:38:51,217 |	  Step count: 113
2021-12-27 18:40:09,210 |	  loss_w (train):2.3886357780611434e-08
2021-12-27 18:40:21,414 |	  v_loss (train):132.14772033691406
2021-12-27 18:40:22,513 |	  model_w_in_main test loss : 0.838954
2021-12-27 18:40:22,974 |	  model_v_in_main test loss : 1.052691
2021-12-27 18:40:22,979 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:40:22,981 |	  Step count: 114
2021-12-27 18:41:01,190 |	  loss_w (train):1.5380189566371882e-08
2021-12-27 18:41:09,625 |	  v_loss (train):46.804752349853516
2021-12-27 18:41:11,707 |	  model_w_in_main test loss : 0.838876
2021-12-27 18:41:11,855 |	  model_v_in_main test loss : 1.111809
2021-12-27 18:41:11,860 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:41:11,862 |	  Step count: 115
2021-12-27 18:42:16,178 |	  loss_w (train):1.4346981380697343e-08
2021-12-27 18:42:35,546 |	  v_loss (train):110.66960906982422
2021-12-27 18:42:37,533 |	  model_w_in_main test loss : 0.838924
2021-12-27 18:42:38,091 |	  model_v_in_main test loss : 1.094283
2021-12-27 18:42:38,098 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:42:38,100 |	  Step count: 116
2021-12-27 18:43:09,634 |	  loss_w (train):4.106055495611827e-09
2021-12-27 18:43:15,806 |	  v_loss (train):15.908841133117676
2021-12-27 18:43:16,739 |	  model_w_in_main test loss : 0.838850
2021-12-27 18:43:17,165 |	  model_v_in_main test loss : 1.086581
2021-12-27 18:43:17,169 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:43:17,171 |	  Step count: 117
2021-12-27 18:43:42,011 |	  loss_w (train):3.071538046128808e-08
2021-12-27 18:43:46,053 |	  v_loss (train):13.840436935424805
2021-12-27 18:43:48,478 |	  model_w_in_main test loss : 0.838901
2021-12-27 18:43:48,595 |	  model_v_in_main test loss : 1.057685
2021-12-27 18:43:48,602 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:43:48,604 |	  Step count: 118
2021-12-27 18:44:32,727 |	  loss_w (train):1.20650156532065e-07
2021-12-27 18:44:38,547 |	  v_loss (train):32.89796829223633
2021-12-27 18:44:40,494 |	  model_w_in_main test loss : 0.838918
2021-12-27 18:44:40,734 |	  model_v_in_main test loss : 1.014149
2021-12-27 18:44:40,806 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:44:40,808 |	  Step count: 119
2021-12-27 18:45:05,762 |	  loss_w (train):1.6391730639497837e-08
2021-12-27 18:45:11,327 |	  v_loss (train):67.55229187011719
2021-12-27 18:45:13,275 |	  model_w_in_main test loss : 0.838996
2021-12-27 18:45:13,835 |	  model_v_in_main test loss : 1.004551
2021-12-27 18:45:13,841 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:45:13,844 |	  Step count: 120
2021-12-27 18:46:09,794 |	  loss_w (train):6.0157292480766955e-09
2021-12-27 18:46:20,728 |	  v_loss (train):95.88642883300781
2021-12-27 18:46:22,728 |	  model_w_in_main test loss : 0.838928
2021-12-27 18:46:23,299 |	  model_v_in_main test loss : 1.004988
2021-12-27 18:46:23,307 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:46:23,309 |	  Step count: 121
2021-12-27 18:47:18,015 |	  loss_w (train):7.235259058546717e-10
2021-12-27 18:47:31,882 |	  v_loss (train):48.57404327392578
2021-12-27 18:47:33,976 |	  model_w_in_main test loss : 0.838913
2021-12-27 18:47:34,530 |	  model_v_in_main test loss : 0.995715
2021-12-27 18:47:34,536 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:47:34,538 |	  Step count: 122
2021-12-27 18:48:29,542 |	  loss_w (train):5.29186863218456e-08
2021-12-27 18:48:42,314 |	  v_loss (train):92.45748901367188
2021-12-27 18:48:44,273 |	  model_w_in_main test loss : 0.838922
2021-12-27 18:48:44,841 |	  model_v_in_main test loss : 1.036791
2021-12-27 18:48:44,849 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:48:44,851 |	  Step count: 123
2021-12-27 18:49:06,079 |	  loss_w (train):4.472000725286307e-08
2021-12-27 18:49:07,442 |	  v_loss (train):2.322639226913452
2021-12-27 18:49:09,463 |	  model_w_in_main test loss : 0.838945
2021-12-27 18:49:09,893 |	  model_v_in_main test loss : 1.071794
2021-12-27 18:49:09,899 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:49:09,901 |	  Step count: 124
2021-12-27 18:49:38,861 |	  loss_w (train):4.5367002599050466e-08
2021-12-27 18:49:43,907 |	  v_loss (train):34.13425064086914
2021-12-27 18:49:45,897 |	  model_w_in_main test loss : 0.838925
2021-12-27 18:49:46,462 |	  model_v_in_main test loss : 1.066033
2021-12-27 18:49:46,469 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:49:46,471 |	  Step count: 125
2021-12-27 18:50:40,194 |	  loss_w (train):2.069664972736973e-08
2021-12-27 18:50:53,104 |	  v_loss (train):81.68092346191406
2021-12-27 18:50:55,521 |	  model_w_in_main test loss : 0.838920
2021-12-27 18:50:55,645 |	  model_v_in_main test loss : 1.070894
2021-12-27 18:50:55,650 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:50:55,652 |	  Step count: 126
2021-12-27 18:51:36,162 |	  loss_w (train):1.2625000067600922e-07
2021-12-27 18:51:43,958 |	  v_loss (train):36.678279876708984
2021-12-27 18:51:45,995 |	  model_w_in_main test loss : 0.838951
2021-12-27 18:51:46,070 |	  model_v_in_main test loss : 1.072377
2021-12-27 18:51:46,091 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:51:46,093 |	  Step count: 127
2021-12-27 18:52:26,510 |	  loss_w (train):1.8273093260745554e-08
2021-12-27 18:52:34,606 |	  v_loss (train):69.80736541748047
2021-12-27 18:52:35,887 |	  model_w_in_main test loss : 0.838911
2021-12-27 18:52:35,945 |	  model_v_in_main test loss : 1.077016
2021-12-27 18:52:35,949 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:52:35,950 |	  Step count: 128
2021-12-27 18:53:33,039 |	  loss_w (train):5.596999530510516e-10
2021-12-27 18:53:45,826 |	  v_loss (train):66.1054916381836
2021-12-27 18:53:47,839 |	  model_w_in_main test loss : 0.838989
2021-12-27 18:53:48,414 |	  model_v_in_main test loss : 1.082438
2021-12-27 18:53:48,421 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:53:48,423 |	  Step count: 129
2021-12-27 18:54:28,309 |	  loss_w (train):3.748975530015741e-08
2021-12-27 18:54:36,473 |	  v_loss (train):60.806488037109375
2021-12-27 18:54:38,617 |	  model_w_in_main test loss : 0.838939
2021-12-27 18:54:38,932 |	  model_v_in_main test loss : 1.074216
2021-12-27 18:54:38,937 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:54:38,939 |	  Step count: 130
2021-12-27 18:55:03,910 |	  loss_w (train):1.2685354988661857e-09
2021-12-27 18:55:06,983 |	  v_loss (train):33.29682540893555
2021-12-27 18:55:08,948 |	  model_w_in_main test loss : 0.838921
2021-12-27 18:55:09,072 |	  model_v_in_main test loss : 1.046622
2021-12-27 18:55:09,092 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:55:09,095 |	  Step count: 131
2021-12-27 18:55:53,085 |	  loss_w (train):3.161737893719874e-08
2021-12-27 18:56:02,519 |	  v_loss (train):14.98539924621582
2021-12-27 18:56:04,496 |	  model_w_in_main test loss : 0.838918
2021-12-27 18:56:05,065 |	  model_v_in_main test loss : 1.044181
2021-12-27 18:56:05,073 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:56:05,075 |	  Step count: 132
2021-12-27 18:56:28,690 |	  loss_w (train):7.607777519069714e-09
2021-12-27 18:56:31,532 |	  v_loss (train):19.735912322998047
2021-12-27 18:56:33,536 |	  model_w_in_main test loss : 0.838984
2021-12-27 18:56:34,064 |	  model_v_in_main test loss : 1.065610
2021-12-27 18:56:34,069 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:56:34,071 |	  Step count: 133
2021-12-27 18:57:00,934 |	  loss_w (train):9.595021666086723e-09
2021-12-27 18:57:05,445 |	  v_loss (train):21.867046356201172
2021-12-27 18:57:07,436 |	  model_w_in_main test loss : 0.838950
2021-12-27 18:57:07,993 |	  model_v_in_main test loss : 1.056712
2021-12-27 18:57:07,998 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:57:08,000 |	  Step count: 134
2021-12-27 18:57:51,350 |	  loss_w (train):8.959598618574205e-10
2021-12-27 18:57:55,359 |	  v_loss (train):57.785682678222656
2021-12-27 18:57:57,192 |	  model_w_in_main test loss : 0.838920
2021-12-27 18:57:57,732 |	  model_v_in_main test loss : 1.091879
2021-12-27 18:57:57,737 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:57:57,740 |	  Step count: 135
2021-12-27 18:58:25,690 |	  loss_w (train):4.670205555612483e-08
2021-12-27 18:58:33,935 |	  v_loss (train):8.264144897460938
2021-12-27 18:58:35,431 |	  model_w_in_main test loss : 0.838971
2021-12-27 18:58:36,009 |	  model_v_in_main test loss : 1.117391
2021-12-27 18:58:36,016 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:58:36,018 |	  Step count: 136
2021-12-27 18:59:36,659 |	  loss_w (train):2.0092107977376372e-09
2021-12-27 18:59:47,402 |	  v_loss (train):127.93993377685547
2021-12-27 18:59:49,448 |	  model_w_in_main test loss : 0.838961
2021-12-27 18:59:49,970 |	  model_v_in_main test loss : 1.088661
2021-12-27 18:59:49,975 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 18:59:49,977 |	  Step count: 137
2021-12-27 19:00:40,684 |	  loss_w (train):3.2698359575533686e-08
2021-12-27 19:00:52,048 |	  v_loss (train):48.00169372558594
2021-12-27 19:00:54,422 |	  model_w_in_main test loss : 0.838941
2021-12-27 19:00:54,472 |	  model_v_in_main test loss : 1.071478
2021-12-27 19:00:54,476 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:00:54,478 |	  Step count: 138
2021-12-27 19:01:42,681 |	  loss_w (train):3.4863707476517902e-09
2021-12-27 19:01:53,668 |	  v_loss (train):14.923391342163086
2021-12-27 19:01:56,060 |	  model_w_in_main test loss : 0.839053
2021-12-27 19:01:56,215 |	  model_v_in_main test loss : 1.049431
2021-12-27 19:01:56,220 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:01:56,222 |	  Step count: 139
2021-12-27 19:02:43,256 |	  loss_w (train):7.775314969649116e-08
2021-12-27 19:02:53,548 |	  v_loss (train):43.73383331298828
2021-12-27 19:02:55,541 |	  model_w_in_main test loss : 0.839078
2021-12-27 19:02:56,121 |	  model_v_in_main test loss : 1.043391
2021-12-27 19:02:56,125 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:02:56,127 |	  Step count: 140
2021-12-27 19:03:41,066 |	  loss_w (train):1.6238281830283086e-08
2021-12-27 19:03:48,332 |	  v_loss (train):55.415740966796875
2021-12-27 19:03:50,178 |	  model_w_in_main test loss : 0.838929
2021-12-27 19:03:50,746 |	  model_v_in_main test loss : 1.016491
2021-12-27 19:03:50,754 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:03:50,756 |	  Step count: 141
2021-12-27 19:05:19,679 |	  loss_w (train):8.104227011695997e-11
2021-12-27 19:05:44,697 |	  v_loss (train):131.117919921875
2021-12-27 19:05:46,673 |	  model_w_in_main test loss : 0.838918
2021-12-27 19:05:47,195 |	  model_v_in_main test loss : 1.026193
2021-12-27 19:05:47,200 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:05:47,202 |	  Step count: 142
2021-12-27 19:06:17,437 |	  loss_w (train):3.000311110668008e-08
2021-12-27 19:06:20,543 |	  v_loss (train):3.495511293411255
2021-12-27 19:06:22,241 |	  model_w_in_main test loss : 0.838955
2021-12-27 19:06:22,567 |	  model_v_in_main test loss : 1.026758
2021-12-27 19:06:22,571 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:06:22,573 |	  Step count: 143
2021-12-27 19:07:20,045 |	  loss_w (train):6.31778078741263e-08
2021-12-27 19:07:34,617 |	  v_loss (train):112.6567153930664
2021-12-27 19:07:36,579 |	  model_w_in_main test loss : 0.838871
2021-12-27 19:07:37,141 |	  model_v_in_main test loss : 0.983600
2021-12-27 19:07:37,147 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:07:37,149 |	  Step count: 144
2021-12-27 19:08:17,299 |	  loss_w (train):1.4054146291186953e-08
2021-12-27 19:08:26,153 |	  v_loss (train):45.90458679199219
2021-12-27 19:08:28,096 |	  model_w_in_main test loss : 0.838892
2021-12-27 19:08:28,206 |	  model_v_in_main test loss : 0.997295
2021-12-27 19:08:28,235 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:08:28,237 |	  Step count: 145
2021-12-27 19:08:51,051 |	  loss_w (train):1.867763010920953e-08
2021-12-27 19:08:53,959 |	  v_loss (train):0.8154922127723694
2021-12-27 19:08:55,622 |	  model_w_in_main test loss : 0.839003
2021-12-27 19:08:56,145 |	  model_v_in_main test loss : 1.053806
2021-12-27 19:08:56,151 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:08:56,153 |	  Step count: 146
2021-12-27 19:09:43,943 |	  loss_w (train):9.430747738292666e-09
2021-12-27 19:09:54,592 |	  v_loss (train):33.01981735229492
2021-12-27 19:09:56,564 |	  model_w_in_main test loss : 0.838836
2021-12-27 19:09:57,129 |	  model_v_in_main test loss : 1.034917
2021-12-27 19:09:57,134 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:09:57,136 |	  Step count: 147
2021-12-27 19:10:52,311 |	  loss_w (train):1.0388005122763388e-08
2021-12-27 19:11:07,436 |	  v_loss (train):59.57492446899414
2021-12-27 19:11:09,461 |	  model_w_in_main test loss : 0.838904
2021-12-27 19:11:10,032 |	  model_v_in_main test loss : 1.063577
2021-12-27 19:11:10,038 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:11:10,040 |	  Step count: 148
2021-12-27 19:12:40,903 |	  loss_w (train):7.849227046108354e-09
2021-12-27 19:13:04,311 |	  v_loss (train):183.4453582763672
2021-12-27 19:13:06,343 |	  model_w_in_main test loss : 0.838926
2021-12-27 19:13:06,458 |	  model_v_in_main test loss : 1.066805
2021-12-27 19:13:06,478 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:13:06,480 |	  Step count: 149
2021-12-27 19:13:39,588 |	  loss_w (train):1.0999969823899391e-08
2021-12-27 19:13:45,949 |	  v_loss (train):19.269641876220703
2021-12-27 19:13:48,336 |	  model_w_in_main test loss : 0.838989
2021-12-27 19:13:48,521 |	  model_v_in_main test loss : 1.056141
2021-12-27 19:13:48,539 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:13:48,541 |	  Step count: 150
2021-12-27 19:14:50,172 |	  loss_w (train):2.2021669821015166e-08
2021-12-27 19:15:04,851 |	  v_loss (train):63.38218688964844
2021-12-27 19:15:06,856 |	  model_w_in_main test loss : 0.838907
2021-12-27 19:15:07,438 |	  model_v_in_main test loss : 1.079915
2021-12-27 19:15:07,447 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:15:07,449 |	  Step count: 151
2021-12-27 19:15:45,545 |	  loss_w (train):1.0060949406920372e-08
2021-12-27 19:15:54,537 |	  v_loss (train):40.736328125
2021-12-27 19:15:56,651 |	  model_w_in_main test loss : 0.838982
2021-12-27 19:15:56,973 |	  model_v_in_main test loss : 1.077556
2021-12-27 19:15:56,978 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:15:56,980 |	  Step count: 152
2021-12-27 19:16:19,427 |	  loss_w (train):1.7431009968760236e-09
2021-12-27 19:16:22,102 |	  v_loss (train):3.771758556365967
2021-12-27 19:16:24,081 |	  model_w_in_main test loss : 0.838885
2021-12-27 19:16:24,648 |	  model_v_in_main test loss : 1.073189
2021-12-27 19:16:24,655 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:16:24,657 |	  Step count: 153
2021-12-27 19:16:53,677 |	  loss_w (train):3.174831508800935e-09
2021-12-27 19:16:58,803 |	  v_loss (train):7.405263900756836
2021-12-27 19:17:00,791 |	  model_w_in_main test loss : 0.838961
2021-12-27 19:17:00,949 |	  model_v_in_main test loss : 1.020980
2021-12-27 19:17:00,954 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:17:00,956 |	  Step count: 154
2021-12-27 19:17:37,569 |	  loss_w (train):5.3375821096324216e-08
2021-12-27 19:17:44,635 |	  v_loss (train):13.697701454162598
2021-12-27 19:17:46,656 |	  model_w_in_main test loss : 0.838924
2021-12-27 19:17:47,212 |	  model_v_in_main test loss : 0.995653
2021-12-27 19:17:47,217 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:17:47,220 |	  Step count: 155
2021-12-27 19:18:07,775 |	  loss_w (train):2.997237125157426e-09
2021-12-27 19:18:10,433 |	  v_loss (train):1.359514832496643
2021-12-27 19:18:12,440 |	  model_w_in_main test loss : 0.838941
2021-12-27 19:18:12,981 |	  model_v_in_main test loss : 1.005271
2021-12-27 19:18:12,988 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:18:12,990 |	  Step count: 156
2021-12-27 19:18:49,883 |	  loss_w (train):1.1474321048865477e-08
2021-12-27 19:18:59,282 |	  v_loss (train):18.17015266418457
2021-12-27 19:19:01,191 |	  model_w_in_main test loss : 0.838946
2021-12-27 19:19:01,332 |	  model_v_in_main test loss : 0.956715
2021-12-27 19:19:01,338 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:19:01,340 |	  Step count: 157
2021-12-27 19:20:22,147 |	  loss_w (train):9.294200076226389e-09
2021-12-27 19:20:41,510 |	  v_loss (train):118.39549255371094
2021-12-27 19:20:43,504 |	  model_w_in_main test loss : 0.838900
2021-12-27 19:20:44,076 |	  model_v_in_main test loss : 0.963356
2021-12-27 19:20:44,084 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:20:44,086 |	  Step count: 158
2021-12-27 19:21:18,466 |	  loss_w (train):1.1586264392349221e-08
2021-12-27 19:21:26,292 |	  v_loss (train):31.10801124572754
2021-12-27 19:21:28,270 |	  model_w_in_main test loss : 0.838920
2021-12-27 19:21:28,812 |	  model_v_in_main test loss : 0.965380
2021-12-27 19:21:28,819 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:21:28,821 |	  Step count: 159
2021-12-27 19:21:53,762 |	  loss_w (train):1.3497287731922825e-09
2021-12-27 19:21:57,498 |	  v_loss (train):2.204716444015503
2021-12-27 19:21:58,956 |	  model_w_in_main test loss : 0.838943
2021-12-27 19:21:59,485 |	  model_v_in_main test loss : 0.984614
2021-12-27 19:21:59,489 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:21:59,491 |	  Step count: 160
2021-12-27 19:22:58,826 |	  loss_w (train):3.460355202378196e-08
2021-12-27 19:23:12,407 |	  v_loss (train):35.39174270629883
2021-12-27 19:23:14,289 |	  model_w_in_main test loss : 0.838959
2021-12-27 19:23:14,434 |	  model_v_in_main test loss : 0.964289
2021-12-27 19:23:14,438 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:23:14,440 |	  Step count: 161
2021-12-27 19:24:18,503 |	  loss_w (train):8.96161012065022e-09
2021-12-27 19:24:21,075 |	  v_loss (train):303.2085266113281
2021-12-27 19:24:21,587 |	  model_w_in_main test loss : 0.838940
2021-12-27 19:24:21,708 |	  model_v_in_main test loss : 0.960792
2021-12-27 19:24:21,713 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:24:21,714 |	  Step count: 162
2021-12-27 19:24:51,052 |	  loss_w (train):9.414138357755064e-10
2021-12-27 19:24:59,291 |	  v_loss (train):15.199799537658691
2021-12-27 19:25:01,102 |	  model_w_in_main test loss : 0.838946
2021-12-27 19:25:01,234 |	  model_v_in_main test loss : 0.972972
2021-12-27 19:25:01,238 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:25:01,240 |	  Step count: 163
2021-12-27 19:26:10,967 |	  loss_w (train):7.106433219661312e-09
2021-12-27 19:26:27,788 |	  v_loss (train):88.45242309570312
2021-12-27 19:26:29,747 |	  model_w_in_main test loss : 0.838887
2021-12-27 19:26:30,341 |	  model_v_in_main test loss : 0.997346
2021-12-27 19:26:30,346 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:26:30,348 |	  Step count: 164
2021-12-27 19:27:07,935 |	  loss_w (train):4.385622176528159e-08
2021-12-27 19:27:15,586 |	  v_loss (train):6.865487098693848
2021-12-27 19:27:17,521 |	  model_w_in_main test loss : 0.838903
2021-12-27 19:27:18,089 |	  model_v_in_main test loss : 1.001896
2021-12-27 19:27:18,096 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:27:18,098 |	  Step count: 165
2021-12-27 19:28:15,036 |	  loss_w (train):3.76570064020143e-09
2021-12-27 19:28:28,010 |	  v_loss (train):67.91412353515625
2021-12-27 19:28:29,915 |	  model_w_in_main test loss : 0.838949
2021-12-27 19:28:30,471 |	  model_v_in_main test loss : 0.985731
2021-12-27 19:28:30,477 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:28:30,479 |	  Step count: 166
2021-12-27 19:29:08,364 |	  loss_w (train):1.2105815905272266e-08
2021-12-27 19:29:15,458 |	  v_loss (train):26.420629501342773
2021-12-27 19:29:17,285 |	  model_w_in_main test loss : 0.838912
2021-12-27 19:29:17,489 |	  model_v_in_main test loss : 0.978200
2021-12-27 19:29:17,493 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:29:17,495 |	  Step count: 167
2021-12-27 19:29:40,985 |	  loss_w (train):2.696249801203976e-08
2021-12-27 19:29:44,427 |	  v_loss (train):0.8410648703575134
2021-12-27 19:29:46,650 |	  model_w_in_main test loss : 0.838927
2021-12-27 19:29:46,831 |	  model_v_in_main test loss : 0.987580
2021-12-27 19:29:46,846 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:29:46,848 |	  Step count: 168
2021-12-27 19:30:35,531 |	  loss_w (train):3.236979573273402e-09
2021-12-27 19:30:45,108 |	  v_loss (train):79.61206817626953
2021-12-27 19:30:46,455 |	  model_w_in_main test loss : 0.838891
2021-12-27 19:30:46,824 |	  model_v_in_main test loss : 0.995928
2021-12-27 19:30:46,877 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:30:46,880 |	  Step count: 169
2021-12-27 19:31:34,304 |	  loss_w (train):7.832705595234302e-10
2021-12-27 19:31:46,895 |	  v_loss (train):84.30809783935547
2021-12-27 19:31:48,846 |	  model_w_in_main test loss : 0.838986
2021-12-27 19:31:48,983 |	  model_v_in_main test loss : 1.008988
2021-12-27 19:31:48,987 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:31:48,989 |	  Step count: 170
2021-12-27 19:32:17,524 |	  loss_w (train):2.6440902800572985e-08
2021-12-27 19:32:21,942 |	  v_loss (train):1.3767722845077515
2021-12-27 19:32:23,872 |	  model_w_in_main test loss : 0.839026
2021-12-27 19:32:24,392 |	  model_v_in_main test loss : 1.022490
2021-12-27 19:32:24,397 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:32:24,400 |	  Step count: 171
2021-12-27 19:33:37,373 |	  loss_w (train):1.2287307527003577e-07
2021-12-27 19:33:55,974 |	  v_loss (train):154.53436279296875
2021-12-27 19:33:57,973 |	  model_w_in_main test loss : 0.838921
2021-12-27 19:33:58,140 |	  model_v_in_main test loss : 0.955011
2021-12-27 19:33:58,157 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:33:58,159 |	  Step count: 172
2021-12-27 19:34:54,030 |	  loss_w (train):1.0624959578819926e-08
2021-12-27 19:35:04,879 |	  v_loss (train):39.14581298828125
2021-12-27 19:35:06,729 |	  model_w_in_main test loss : 0.839039
2021-12-27 19:35:06,861 |	  model_v_in_main test loss : 0.936858
2021-12-27 19:35:06,874 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:35:06,876 |	  Step count: 173
2021-12-27 19:35:33,019 |	  loss_w (train):2.1080428069808477e-08
2021-12-27 19:35:40,180 |	  v_loss (train):0.5949321985244751
2021-12-27 19:35:42,123 |	  model_w_in_main test loss : 0.838951
2021-12-27 19:35:42,670 |	  model_v_in_main test loss : 0.974584
2021-12-27 19:35:42,676 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:35:42,678 |	  Step count: 174
2021-12-27 19:36:06,399 |	  loss_w (train):1.6059262364365168e-08
2021-12-27 19:36:08,435 |	  v_loss (train):1.1176326274871826
2021-12-27 19:36:09,047 |	  model_w_in_main test loss : 0.839024
2021-12-27 19:36:09,132 |	  model_v_in_main test loss : 0.983444
2021-12-27 19:36:09,136 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:36:09,138 |	  Step count: 175
2021-12-27 19:36:30,737 |	  loss_w (train):7.811772895216507e-10
2021-12-27 19:36:37,757 |	  v_loss (train):8.065829277038574
2021-12-27 19:36:39,814 |	  model_w_in_main test loss : 0.838952
2021-12-27 19:36:40,285 |	  model_v_in_main test loss : 0.980610
2021-12-27 19:36:40,290 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:36:40,292 |	  Step count: 176
2021-12-27 19:37:01,436 |	  loss_w (train):3.1653843435286433e-10
2021-12-27 19:37:09,965 |	  v_loss (train):0.58794105052948
2021-12-27 19:37:11,739 |	  model_w_in_main test loss : 0.838997
2021-12-27 19:37:12,320 |	  model_v_in_main test loss : 1.008398
2021-12-27 19:37:12,325 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:37:12,327 |	  Step count: 177
2021-12-27 19:37:45,136 |	  loss_w (train):1.6174798167511995e-09
2021-12-27 19:37:51,437 |	  v_loss (train):14.481649398803711
2021-12-27 19:37:53,844 |	  model_w_in_main test loss : 0.839028
2021-12-27 19:37:53,976 |	  model_v_in_main test loss : 1.028069
2021-12-27 19:37:53,980 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:37:53,982 |	  Step count: 178
2021-12-27 19:38:17,373 |	  loss_w (train):1.2600939669482614e-07
2021-12-27 19:38:20,027 |	  v_loss (train):1.046012282371521
2021-12-27 19:38:22,010 |	  model_w_in_main test loss : 0.839010
2021-12-27 19:38:22,581 |	  model_v_in_main test loss : 1.021560
2021-12-27 19:38:22,587 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:38:22,589 |	  Step count: 179
2021-12-27 19:38:45,607 |	  loss_w (train):1.1778800512729504e-07
2021-12-27 19:38:48,757 |	  v_loss (train):26.390480041503906
2021-12-27 19:38:50,812 |	  model_w_in_main test loss : 0.838915
2021-12-27 19:38:51,362 |	  model_v_in_main test loss : 1.051537
2021-12-27 19:38:51,368 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:38:51,371 |	  Step count: 180
2021-12-27 19:39:26,576 |	  loss_w (train):7.557226666676797e-08
2021-12-27 19:39:32,882 |	  v_loss (train):15.304040908813477
2021-12-27 19:39:35,009 |	  model_w_in_main test loss : 0.838907
2021-12-27 19:39:35,479 |	  model_v_in_main test loss : 1.066272
2021-12-27 19:39:35,486 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:39:35,488 |	  Step count: 181
2021-12-27 19:40:33,326 |	  loss_w (train):1.8862998274471465e-07
2021-12-27 19:40:46,707 |	  v_loss (train):103.87409210205078
2021-12-27 19:40:49,040 |	  model_w_in_main test loss : 0.838893
2021-12-27 19:40:49,158 |	  model_v_in_main test loss : 1.063951
2021-12-27 19:40:49,162 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:40:49,164 |	  Step count: 182
2021-12-27 19:42:01,474 |	  loss_w (train):1.4653774194073321e-08
2021-12-27 19:42:19,290 |	  v_loss (train):111.85630798339844
2021-12-27 19:42:21,811 |	  model_w_in_main test loss : 0.838842
2021-12-27 19:42:22,356 |	  model_v_in_main test loss : 1.028957
2021-12-27 19:42:22,365 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:42:22,367 |	  Step count: 183
2021-12-27 19:42:56,765 |	  loss_w (train):2.679231281277339e-10
2021-12-27 19:43:02,548 |	  v_loss (train):57.61080551147461
2021-12-27 19:43:04,442 |	  model_w_in_main test loss : 0.838900
2021-12-27 19:43:04,643 |	  model_v_in_main test loss : 1.032732
2021-12-27 19:43:04,649 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:43:04,651 |	  Step count: 184
2021-12-27 19:43:57,588 |	  loss_w (train):8.503411308424802e-09
2021-12-27 19:44:09,415 |	  v_loss (train):66.78244018554688
2021-12-27 19:44:11,476 |	  model_w_in_main test loss : 0.838937
2021-12-27 19:44:12,034 |	  model_v_in_main test loss : 0.993216
2021-12-27 19:44:12,039 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:44:12,041 |	  Step count: 185
2021-12-27 19:44:36,041 |	  loss_w (train):1.255721393533804e-08
2021-12-27 19:44:39,344 |	  v_loss (train):0.5150930881500244
2021-12-27 19:44:41,143 |	  model_w_in_main test loss : 0.838881
2021-12-27 19:44:41,359 |	  model_v_in_main test loss : 1.022042
2021-12-27 19:44:41,410 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:44:41,413 |	  Step count: 186
2021-12-27 19:45:27,072 |	  loss_w (train):4.223209781883952e-09
2021-12-27 19:45:37,761 |	  v_loss (train):114.64323425292969
2021-12-27 19:45:39,751 |	  model_w_in_main test loss : 0.838919
2021-12-27 19:45:39,948 |	  model_v_in_main test loss : 1.025352
2021-12-27 19:45:39,962 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:45:39,965 |	  Step count: 187
2021-12-27 19:46:25,664 |	  loss_w (train):1.7471034396976393e-08
2021-12-27 19:46:35,227 |	  v_loss (train):32.47943115234375
2021-12-27 19:46:37,288 |	  model_w_in_main test loss : 0.838882
2021-12-27 19:46:37,748 |	  model_v_in_main test loss : 1.057975
2021-12-27 19:46:37,753 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:46:37,755 |	  Step count: 188
2021-12-27 19:47:13,433 |	  loss_w (train):3.8486787090619146e-09
2021-12-27 19:47:19,953 |	  v_loss (train):26.595016479492188
2021-12-27 19:47:21,930 |	  model_w_in_main test loss : 0.838924
2021-12-27 19:47:22,486 |	  model_v_in_main test loss : 1.017550
2021-12-27 19:47:22,491 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:47:22,494 |	  Step count: 189
2021-12-27 19:48:35,913 |	  loss_w (train):1.0474092704271243e-09
2021-12-27 19:48:52,671 |	  v_loss (train):66.81465911865234
2021-12-27 19:48:54,645 |	  model_w_in_main test loss : 0.838968
2021-12-27 19:48:54,858 |	  model_v_in_main test loss : 1.072636
2021-12-27 19:48:54,875 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:48:54,877 |	  Step count: 190
2021-12-27 19:49:29,616 |	  loss_w (train):5.165635030834892e-08
2021-12-27 19:49:36,278 |	  v_loss (train):67.207275390625
2021-12-27 19:49:38,246 |	  model_w_in_main test loss : 0.838967
2021-12-27 19:49:38,803 |	  model_v_in_main test loss : 1.069868
2021-12-27 19:49:38,809 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:49:38,811 |	  Step count: 191
2021-12-27 19:50:21,764 |	  loss_w (train):3.7786971773812184e-08
2021-12-27 19:50:31,250 |	  v_loss (train):31.988636016845703
2021-12-27 19:50:33,183 |	  model_w_in_main test loss : 0.838921
2021-12-27 19:50:33,624 |	  model_v_in_main test loss : 1.047542
2021-12-27 19:50:33,679 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:50:33,682 |	  Step count: 192
2021-12-27 19:51:57,179 |	  loss_w (train):2.470549542721301e-09
2021-12-27 19:52:21,829 |	  v_loss (train):226.72377014160156
2021-12-27 19:52:24,161 |	  model_w_in_main test loss : 0.838918
2021-12-27 19:52:24,564 |	  model_v_in_main test loss : 1.071059
2021-12-27 19:52:24,620 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:52:24,623 |	  Step count: 193
2021-12-27 19:53:24,730 |	  loss_w (train):1.0212742651560802e-08
2021-12-27 19:53:40,349 |	  v_loss (train):80.21385192871094
2021-12-27 19:53:40,913 |	  model_w_in_main test loss : 0.838944
2021-12-27 19:53:40,997 |	  model_v_in_main test loss : 1.052884
2021-12-27 19:53:41,000 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:53:41,002 |	  Step count: 194
2021-12-27 19:55:04,764 |	  loss_w (train):1.6094187316184616e-08
2021-12-27 19:55:29,449 |	  v_loss (train):239.90478515625
2021-12-27 19:55:31,456 |	  model_w_in_main test loss : 0.839011
2021-12-27 19:55:32,036 |	  model_v_in_main test loss : 1.068082
2021-12-27 19:55:32,042 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:55:32,044 |	  Step count: 195
2021-12-27 19:56:05,803 |	  loss_w (train):6.767781890459901e-09
2021-12-27 19:56:08,972 |	  v_loss (train):0.726908802986145
2021-12-27 19:56:10,850 |	  model_w_in_main test loss : 0.839067
2021-12-27 19:56:10,969 |	  model_v_in_main test loss : 1.091019
2021-12-27 19:56:10,974 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:56:10,976 |	  Step count: 196
2021-12-27 19:56:48,950 |	  loss_w (train):5.646432654771161e-08
2021-12-27 19:56:54,972 |	  v_loss (train):39.95419692993164
2021-12-27 19:56:56,446 |	  model_w_in_main test loss : 0.838861
2021-12-27 19:56:56,964 |	  model_v_in_main test loss : 1.066271
2021-12-27 19:56:56,969 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:56:56,971 |	  Step count: 197
2021-12-27 19:58:28,580 |	  loss_w (train):9.299225833814262e-10
2021-12-27 19:58:53,189 |	  v_loss (train):428.5019836425781
2021-12-27 19:58:55,046 |	  model_w_in_main test loss : 0.838954
2021-12-27 19:58:55,603 |	  model_v_in_main test loss : 1.105604
2021-12-27 19:58:55,608 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:58:55,611 |	  Step count: 198
2021-12-27 19:59:33,018 |	  loss_w (train):3.398653447561628e-08
2021-12-27 19:59:42,238 |	  v_loss (train):17.6685791015625
2021-12-27 19:59:44,161 |	  model_w_in_main test loss : 0.839009
2021-12-27 19:59:44,595 |	  model_v_in_main test loss : 1.045515
2021-12-27 19:59:44,600 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 19:59:44,602 |	  Step count: 199
2021-12-27 20:00:25,643 |	  loss_w (train):5.696625393625254e-09
2021-12-27 20:00:33,448 |	  v_loss (train):46.93559646606445
2021-12-27 20:00:35,390 |	  model_w_in_main test loss : 0.838933
2021-12-27 20:00:35,931 |	  model_v_in_main test loss : 1.013769
2021-12-27 20:00:35,939 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:00:35,941 |	  Step count: 200
2021-12-27 20:01:26,087 |	  loss_w (train):1.3052655845058325e-08
2021-12-27 20:01:37,395 |	  v_loss (train):30.737577438354492
2021-12-27 20:01:39,410 |	  model_w_in_main test loss : 0.838960
2021-12-27 20:01:39,937 |	  model_v_in_main test loss : 1.045821
2021-12-27 20:01:39,941 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:01:39,943 |	  Step count: 201
2021-12-27 20:02:11,645 |	  loss_w (train):6.589006318336033e-08
2021-12-27 20:02:16,909 |	  v_loss (train):16.760356903076172
2021-12-27 20:02:18,868 |	  model_w_in_main test loss : 0.838883
2021-12-27 20:02:18,994 |	  model_v_in_main test loss : 1.078700
2021-12-27 20:02:18,998 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:02:19,001 |	  Step count: 202
2021-12-27 20:03:10,365 |	  loss_w (train):5.181458595515664e-10
2021-12-27 20:03:23,559 |	  v_loss (train):55.44234848022461
2021-12-27 20:03:25,505 |	  model_w_in_main test loss : 0.838968
2021-12-27 20:03:25,635 |	  model_v_in_main test loss : 1.106091
2021-12-27 20:03:25,641 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:03:25,643 |	  Step count: 203
2021-12-27 20:04:30,706 |	  loss_w (train):2.76027822820879e-09
2021-12-27 20:04:44,902 |	  v_loss (train):101.16725158691406
2021-12-27 20:04:46,378 |	  model_w_in_main test loss : 0.838824
2021-12-27 20:04:46,945 |	  model_v_in_main test loss : 1.015852
2021-12-27 20:04:46,951 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:04:46,954 |	  Step count: 204
2021-12-27 20:05:18,408 |	  loss_w (train):1.517415455509763e-07
2021-12-27 20:05:21,003 |	  v_loss (train):1.3699073791503906
2021-12-27 20:05:23,364 |	  model_w_in_main test loss : 0.838875
2021-12-27 20:05:23,518 |	  model_v_in_main test loss : 1.010125
2021-12-27 20:05:23,522 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:05:23,524 |	  Step count: 205
2021-12-27 20:05:52,770 |	  loss_w (train):5.151939319603116e-09
2021-12-27 20:06:00,959 |	  v_loss (train):0.5549501180648804
2021-12-27 20:06:02,894 |	  model_w_in_main test loss : 0.838909
2021-12-27 20:06:03,399 |	  model_v_in_main test loss : 1.141781
2021-12-27 20:06:03,404 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:06:03,406 |	  Step count: 206
2021-12-27 20:06:54,229 |	  loss_w (train):7.77872131152435e-08
2021-12-27 20:07:05,619 |	  v_loss (train):49.74287414550781
2021-12-27 20:07:07,634 |	  model_w_in_main test loss : 0.838944
2021-12-27 20:07:08,195 |	  model_v_in_main test loss : 1.076052
2021-12-27 20:07:08,199 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:07:08,201 |	  Step count: 207
2021-12-27 20:08:02,099 |	  loss_w (train):8.424167141640737e-09
2021-12-27 20:08:15,519 |	  v_loss (train):72.35223388671875
2021-12-27 20:08:17,488 |	  model_w_in_main test loss : 0.838835
2021-12-27 20:08:18,062 |	  model_v_in_main test loss : 1.170608
2021-12-27 20:08:18,067 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:08:18,069 |	  Step count: 208
2021-12-27 20:08:40,058 |	  loss_w (train):1.4418631844037577e-09
2021-12-27 20:08:43,038 |	  v_loss (train):0.9782233238220215
2021-12-27 20:08:44,815 |	  model_w_in_main test loss : 0.838903
2021-12-27 20:08:45,212 |	  model_v_in_main test loss : 1.194424
2021-12-27 20:08:45,216 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:08:45,218 |	  Step count: 209
2021-12-27 20:09:12,751 |	  loss_w (train):5.166020389246739e-10
2021-12-27 20:09:16,583 |	  v_loss (train):24.558523178100586
2021-12-27 20:09:18,088 |	  model_w_in_main test loss : 0.838923
2021-12-27 20:09:18,257 |	  model_v_in_main test loss : 1.158461
2021-12-27 20:09:18,270 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:09:18,272 |	  Step count: 210
2021-12-27 20:09:37,972 |	  loss_w (train):2.9506068699447496e-09
2021-12-27 20:09:40,412 |	  v_loss (train):0.9297232627868652
2021-12-27 20:09:41,341 |	  model_w_in_main test loss : 0.838919
2021-12-27 20:09:41,794 |	  model_v_in_main test loss : 1.034800
2021-12-27 20:09:41,797 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:09:41,799 |	  Step count: 211
2021-12-27 20:10:01,167 |	  loss_w (train):3.249043345476821e-08
2021-12-27 20:10:03,763 |	  v_loss (train):10.628212928771973
2021-12-27 20:10:05,638 |	  model_w_in_main test loss : 0.838972
2021-12-27 20:10:05,763 |	  model_v_in_main test loss : 1.009131
2021-12-27 20:10:05,768 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:10:05,770 |	  Step count: 212
2021-12-27 20:10:34,448 |	  loss_w (train):2.011563182691134e-08
2021-12-27 20:10:38,961 |	  v_loss (train):11.8207368850708
2021-12-27 20:10:40,847 |	  model_w_in_main test loss : 0.838965
2021-12-27 20:10:40,996 |	  model_v_in_main test loss : 1.000922
2021-12-27 20:10:41,001 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:10:41,003 |	  Step count: 213
2021-12-27 20:11:00,971 |	  loss_w (train):8.551926944377897e-10
2021-12-27 20:11:03,657 |	  v_loss (train):0.1966402232646942
2021-12-27 20:11:05,592 |	  model_w_in_main test loss : 0.838939
2021-12-27 20:11:05,724 |	  model_v_in_main test loss : 1.031284
2021-12-27 20:11:05,729 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:11:05,731 |	  Step count: 214
2021-12-27 20:11:45,731 |	  loss_w (train):1.3629956718830272e-08
2021-12-27 20:11:56,973 |	  v_loss (train):57.43914794921875
2021-12-27 20:11:59,013 |	  model_w_in_main test loss : 0.838921
2021-12-27 20:11:59,562 |	  model_v_in_main test loss : 1.032362
2021-12-27 20:11:59,568 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:11:59,570 |	  Step count: 215
2021-12-27 20:12:20,935 |	  loss_w (train):6.473450220312316e-09
2021-12-27 20:12:29,907 |	  v_loss (train):18.159006118774414
2021-12-27 20:12:31,977 |	  model_w_in_main test loss : 0.838939
2021-12-27 20:12:32,550 |	  model_v_in_main test loss : 1.020387
2021-12-27 20:12:32,555 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:12:32,558 |	  Step count: 216
2021-12-27 20:13:37,113 |	  loss_w (train):2.2350620909605823e-08
2021-12-27 20:13:52,625 |	  v_loss (train):63.76896286010742
2021-12-27 20:13:54,994 |	  model_w_in_main test loss : 0.838883
2021-12-27 20:13:55,250 |	  model_v_in_main test loss : 0.991747
2021-12-27 20:13:55,254 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:13:55,257 |	  Step count: 217
2021-12-27 20:15:03,292 |	  loss_w (train):7.963639525598865e-09
2021-12-27 20:15:21,207 |	  v_loss (train):90.21118927001953
2021-12-27 20:15:23,200 |	  model_w_in_main test loss : 0.838970
2021-12-27 20:15:23,784 |	  model_v_in_main test loss : 0.996920
2021-12-27 20:15:23,790 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:15:23,792 |	  Step count: 218
2021-12-27 20:16:15,019 |	  loss_w (train):2.0410679368865203e-08
2021-12-27 20:16:25,251 |	  v_loss (train):72.65443420410156
2021-12-27 20:16:27,173 |	  model_w_in_main test loss : 0.838953
2021-12-27 20:16:27,727 |	  model_v_in_main test loss : 1.012614
2021-12-27 20:16:27,732 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:16:27,734 |	  Step count: 219
2021-12-27 20:17:06,408 |	  loss_w (train):1.471461263946594e-08
2021-12-27 20:17:15,258 |	  v_loss (train):36.51124954223633
2021-12-27 20:17:17,654 |	  model_w_in_main test loss : 0.838872
2021-12-27 20:17:17,796 |	  model_v_in_main test loss : 1.014851
2021-12-27 20:17:17,802 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:17:17,804 |	  Step count: 220
2021-12-27 20:18:15,150 |	  loss_w (train):4.0124464861790443e-10
2021-12-27 20:18:30,476 |	  v_loss (train):107.2010498046875
2021-12-27 20:18:32,719 |	  model_w_in_main test loss : 0.838896
2021-12-27 20:18:33,008 |	  model_v_in_main test loss : 0.992489
2021-12-27 20:18:33,013 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:18:33,015 |	  Step count: 221
2021-12-27 20:19:16,066 |	  loss_w (train):8.983187527178416e-09
2021-12-27 20:19:26,015 |	  v_loss (train):41.27922821044922
2021-12-27 20:19:27,987 |	  model_w_in_main test loss : 0.838957
2021-12-27 20:19:28,508 |	  model_v_in_main test loss : 0.988428
2021-12-27 20:19:28,513 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:19:28,516 |	  Step count: 222
2021-12-27 20:20:02,225 |	  loss_w (train):4.860353186586508e-08
2021-12-27 20:20:05,641 |	  v_loss (train):17.3150691986084
2021-12-27 20:20:07,443 |	  model_w_in_main test loss : 0.838897
2021-12-27 20:20:08,010 |	  model_v_in_main test loss : 1.012718
2021-12-27 20:20:08,017 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:20:08,019 |	  Step count: 223
2021-12-27 20:20:41,707 |	  loss_w (train):4.717313473179274e-08
2021-12-27 20:20:48,360 |	  v_loss (train):25.883527755737305
2021-12-27 20:20:50,508 |	  model_w_in_main test loss : 0.838884
2021-12-27 20:20:50,799 |	  model_v_in_main test loss : 1.017556
2021-12-27 20:20:50,845 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:20:50,847 |	  Step count: 224
2021-12-27 20:21:22,824 |	  loss_w (train):1.6620780307619043e-09
2021-12-27 20:21:32,259 |	  v_loss (train):20.73282814025879
2021-12-27 20:21:34,712 |	  model_w_in_main test loss : 0.838965
2021-12-27 20:21:34,878 |	  model_v_in_main test loss : 1.002956
2021-12-27 20:21:34,900 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:21:34,902 |	  Step count: 225
2021-12-27 20:23:03,339 |	  loss_w (train):1.7759824721963469e-09
2021-12-27 20:23:25,886 |	  v_loss (train):152.36309814453125
2021-12-27 20:23:27,330 |	  model_w_in_main test loss : 0.838955
2021-12-27 20:23:27,885 |	  model_v_in_main test loss : 1.004955
2021-12-27 20:23:27,889 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:23:27,891 |	  Step count: 226
2021-12-27 20:23:51,122 |	  loss_w (train):9.697883385229034e-09
2021-12-27 20:23:54,468 |	  v_loss (train):19.661527633666992
2021-12-27 20:23:56,354 |	  model_w_in_main test loss : 0.838992
2021-12-27 20:23:56,475 |	  model_v_in_main test loss : 1.023752
2021-12-27 20:23:56,482 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:23:56,484 |	  Step count: 227
2021-12-27 20:24:32,480 |	  loss_w (train):9.921879318142146e-09
2021-12-27 20:24:42,459 |	  v_loss (train):33.602630615234375
2021-12-27 20:24:44,451 |	  model_w_in_main test loss : 0.838934
2021-12-27 20:24:44,551 |	  model_v_in_main test loss : 1.014927
2021-12-27 20:24:44,554 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:24:44,556 |	  Step count: 228
2021-12-27 20:25:14,486 |	  loss_w (train):5.339400033221864e-10
2021-12-27 20:25:20,077 |	  v_loss (train):43.15784454345703
2021-12-27 20:25:22,185 |	  model_w_in_main test loss : 0.838950
2021-12-27 20:25:22,718 |	  model_v_in_main test loss : 1.020569
2021-12-27 20:25:22,722 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:25:22,725 |	  Step count: 229
2021-12-27 20:26:00,421 |	  loss_w (train):1.539121186056036e-08
2021-12-27 20:26:10,002 |	  v_loss (train):36.961219787597656
2021-12-27 20:26:12,437 |	  model_w_in_main test loss : 0.838882
2021-12-27 20:26:12,578 |	  model_v_in_main test loss : 1.023223
2021-12-27 20:26:12,592 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:26:12,595 |	  Step count: 230
2021-12-27 20:26:52,662 |	  loss_w (train):4.933768948944817e-09
2021-12-27 20:27:00,591 |	  v_loss (train):11.149904251098633
2021-12-27 20:27:02,526 |	  model_w_in_main test loss : 0.838892
2021-12-27 20:27:02,644 |	  model_v_in_main test loss : 1.022502
2021-12-27 20:27:02,649 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:27:02,651 |	  Step count: 231
2021-12-27 20:27:32,676 |	  loss_w (train):9.061197125959097e-09
2021-12-27 20:27:38,084 |	  v_loss (train):15.651875495910645
2021-12-27 20:27:39,904 |	  model_w_in_main test loss : 0.838928
2021-12-27 20:27:40,474 |	  model_v_in_main test loss : 0.996852
2021-12-27 20:27:40,479 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:27:40,481 |	  Step count: 232
2021-12-27 20:28:25,021 |	  loss_w (train):4.441631951124236e-09
2021-12-27 20:28:33,908 |	  v_loss (train):71.80509948730469
2021-12-27 20:28:35,886 |	  model_w_in_main test loss : 0.838850
2021-12-27 20:28:36,117 |	  model_v_in_main test loss : 0.979430
2021-12-27 20:28:36,171 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:28:36,173 |	  Step count: 233
2021-12-27 20:29:49,730 |	  loss_w (train):9.31839494455744e-09
2021-12-27 20:30:08,570 |	  v_loss (train):159.62423706054688
2021-12-27 20:30:10,056 |	  model_w_in_main test loss : 0.838923
2021-12-27 20:30:10,464 |	  model_v_in_main test loss : 0.993822
2021-12-27 20:30:10,518 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:30:10,521 |	  Step count: 234
2021-12-27 20:30:44,486 |	  loss_w (train):1.1930899823653363e-08
2021-12-27 20:30:51,429 |	  v_loss (train):21.72944450378418
2021-12-27 20:30:53,527 |	  model_w_in_main test loss : 0.838910
2021-12-27 20:30:53,989 |	  model_v_in_main test loss : 1.015637
2021-12-27 20:30:53,993 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:30:53,995 |	  Step count: 235
2021-12-27 20:31:35,759 |	  loss_w (train):3.17497104163067e-08
2021-12-27 20:31:45,938 |	  v_loss (train):58.803260803222656
2021-12-27 20:31:47,699 |	  model_w_in_main test loss : 0.838999
2021-12-27 20:31:47,883 |	  model_v_in_main test loss : 1.015438
2021-12-27 20:31:47,899 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:31:47,901 |	  Step count: 236
2021-12-27 20:32:41,815 |	  loss_w (train):5.4751474465319916e-08
2021-12-27 20:32:52,694 |	  v_loss (train):30.689735412597656
2021-12-27 20:32:54,676 |	  model_w_in_main test loss : 0.839000
2021-12-27 20:32:55,219 |	  model_v_in_main test loss : 1.026549
2021-12-27 20:32:55,226 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:32:55,228 |	  Step count: 237
2021-12-27 20:33:23,100 |	  loss_w (train):3.666563719306737e-09
2021-12-27 20:33:31,605 |	  v_loss (train):13.477591514587402
2021-12-27 20:33:33,574 |	  model_w_in_main test loss : 0.838902
2021-12-27 20:33:33,684 |	  model_v_in_main test loss : 0.989541
2021-12-27 20:33:33,690 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:33:33,692 |	  Step count: 238
2021-12-27 20:34:08,561 |	  loss_w (train):7.3529813349182405e-09
2021-12-27 20:34:13,906 |	  v_loss (train):33.90475845336914
2021-12-27 20:34:15,996 |	  model_w_in_main test loss : 0.838943
2021-12-27 20:34:16,130 |	  model_v_in_main test loss : 1.005915
2021-12-27 20:34:16,134 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:34:16,136 |	  Step count: 239
2021-12-27 20:35:03,277 |	  loss_w (train):3.3637061136460034e-08
2021-12-27 20:35:14,301 |	  v_loss (train):43.216041564941406
2021-12-27 20:35:16,264 |	  model_w_in_main test loss : 0.838901
2021-12-27 20:35:16,480 |	  model_v_in_main test loss : 1.012219
2021-12-27 20:35:16,553 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:35:16,555 |	  Step count: 240
2021-12-27 20:36:36,073 |	  loss_w (train):6.268167318523865e-09
2021-12-27 20:36:58,036 |	  v_loss (train):72.86683654785156
2021-12-27 20:36:59,755 |	  model_w_in_main test loss : 0.838901
2021-12-27 20:37:00,276 |	  model_v_in_main test loss : 1.019712
2021-12-27 20:37:00,280 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:37:00,283 |	  Step count: 241
2021-12-27 20:38:26,110 |	  loss_w (train):6.8254495388941905e-09
2021-12-27 20:38:50,206 |	  v_loss (train):133.54544067382812
2021-12-27 20:38:52,223 |	  model_w_in_main test loss : 0.838951
2021-12-27 20:38:52,792 |	  model_v_in_main test loss : 0.987914
2021-12-27 20:38:52,796 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:38:52,798 |	  Step count: 242
2021-12-27 20:40:10,157 |	  loss_w (train):2.4376230811640198e-08
2021-12-27 20:40:28,029 |	  v_loss (train):111.69819641113281
2021-12-27 20:40:30,329 |	  model_w_in_main test loss : 0.838982
2021-12-27 20:40:30,467 |	  model_v_in_main test loss : 0.977806
2021-12-27 20:40:30,472 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:40:30,475 |	  Step count: 243
2021-12-27 20:42:04,039 |	  loss_w (train):3.768572121032321e-09
2021-12-27 20:42:26,579 |	  v_loss (train):256.2816162109375
2021-12-27 20:42:28,465 |	  model_w_in_main test loss : 0.838936
2021-12-27 20:42:29,047 |	  model_v_in_main test loss : 0.947726
2021-12-27 20:42:29,053 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:42:29,055 |	  Step count: 244
2021-12-27 20:43:29,297 |	  loss_w (train):3.2215645262567705e-08
2021-12-27 20:43:49,609 |	  v_loss (train):60.22473907470703
2021-12-27 20:43:51,578 |	  model_w_in_main test loss : 0.838948
2021-12-27 20:43:51,698 |	  model_v_in_main test loss : 0.955402
2021-12-27 20:43:51,704 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:43:51,706 |	  Step count: 245
2021-12-27 20:44:12,662 |	  loss_w (train):3.4950647931353274e-10
2021-12-27 20:44:15,277 |	  v_loss (train):0.8426791429519653
2021-12-27 20:44:17,233 |	  model_w_in_main test loss : 0.838942
2021-12-27 20:44:17,754 |	  model_v_in_main test loss : 0.966345
2021-12-27 20:44:17,761 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:44:17,763 |	  Step count: 246
2021-12-27 20:44:42,052 |	  loss_w (train):1.0390230009704737e-08
2021-12-27 20:44:45,885 |	  v_loss (train):12.489211082458496
2021-12-27 20:44:47,802 |	  model_w_in_main test loss : 0.838867
2021-12-27 20:44:48,344 |	  model_v_in_main test loss : 1.000864
2021-12-27 20:44:48,350 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:44:48,352 |	  Step count: 247
2021-12-27 20:46:11,505 |	  loss_w (train):2.354910932922394e-09
2021-12-27 20:46:29,019 |	  v_loss (train):120.82142639160156
2021-12-27 20:46:31,029 |	  model_w_in_main test loss : 0.838953
2021-12-27 20:46:31,582 |	  model_v_in_main test loss : 0.980259
2021-12-27 20:46:31,588 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:46:31,590 |	  Step count: 248
2021-12-27 20:47:08,775 |	  loss_w (train):1.2504008495284324e-08
2021-12-27 20:47:15,394 |	  v_loss (train):38.63472366333008
2021-12-27 20:47:17,672 |	  model_w_in_main test loss : 0.838907
2021-12-27 20:47:17,933 |	  model_v_in_main test loss : 0.992185
2021-12-27 20:47:17,937 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:47:17,939 |	  Step count: 249
2021-12-27 20:48:30,516 |	  loss_w (train):1.1332650373674369e-09
2021-12-27 20:48:46,338 |	  v_loss (train):64.5751953125
2021-12-27 20:48:48,259 |	  model_w_in_main test loss : 0.838896
2021-12-27 20:48:48,827 |	  model_v_in_main test loss : 0.994113
2021-12-27 20:48:48,831 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:48:48,833 |	  Step count: 250
2021-12-27 20:49:42,768 |	  loss_w (train):8.041538990255503e-08
2021-12-27 20:49:55,409 |	  v_loss (train):52.78470230102539
2021-12-27 20:49:57,652 |	  model_w_in_main test loss : 0.838912
2021-12-27 20:49:57,931 |	  model_v_in_main test loss : 0.952749
2021-12-27 20:49:57,935 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:49:57,937 |	  Step count: 251
2021-12-27 20:50:28,508 |	  loss_w (train):8.72946515073636e-09
2021-12-27 20:50:33,044 |	  v_loss (train):8.473694801330566
2021-12-27 20:50:34,975 |	  model_w_in_main test loss : 0.838895
2021-12-27 20:50:35,526 |	  model_v_in_main test loss : 0.954025
2021-12-27 20:50:35,530 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:50:35,532 |	  Step count: 252
2021-12-27 20:50:59,007 |	  loss_w (train):8.253326910789838e-09
2021-12-27 20:51:02,761 |	  v_loss (train):0.7241509556770325
2021-12-27 20:51:04,698 |	  model_w_in_main test loss : 0.838965
2021-12-27 20:51:05,222 |	  model_v_in_main test loss : 0.997332
2021-12-27 20:51:05,228 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:51:05,230 |	  Step count: 253
2021-12-27 20:51:27,639 |	  loss_w (train):1.1008460809591725e-08
2021-12-27 20:51:35,967 |	  v_loss (train):0.1601540744304657
2021-12-27 20:51:37,888 |	  model_w_in_main test loss : 0.838989
2021-12-27 20:51:38,455 |	  model_v_in_main test loss : 0.984910
2021-12-27 20:51:38,460 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:51:38,462 |	  Step count: 254
2021-12-27 20:52:21,121 |	  loss_w (train):9.507800102781516e-10
2021-12-27 20:52:30,508 |	  v_loss (train):72.6136474609375
2021-12-27 20:52:32,967 |	  model_w_in_main test loss : 0.838995
2021-12-27 20:52:33,520 |	  model_v_in_main test loss : 0.985809
2021-12-27 20:52:33,527 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:52:33,529 |	  Step count: 255
2021-12-27 20:53:12,991 |	  loss_w (train):1.7638576821354945e-08
2021-12-27 20:53:21,762 |	  v_loss (train):37.75453567504883
2021-12-27 20:53:23,833 |	  model_w_in_main test loss : 0.838912
2021-12-27 20:53:24,283 |	  model_v_in_main test loss : 0.969085
2021-12-27 20:53:24,289 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:53:24,291 |	  Step count: 256
2021-12-27 20:53:54,749 |	  loss_w (train):1.6758786358650468e-08
2021-12-27 20:53:59,605 |	  v_loss (train):10.464988708496094
2021-12-27 20:54:01,366 |	  model_w_in_main test loss : 0.838951
2021-12-27 20:54:01,935 |	  model_v_in_main test loss : 0.958635
2021-12-27 20:54:01,942 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:54:01,944 |	  Step count: 257
2021-12-27 20:54:37,196 |	  loss_w (train):7.314550742876236e-09
2021-12-27 20:54:41,785 |	  v_loss (train):6.398649215698242
2021-12-27 20:54:44,187 |	  model_w_in_main test loss : 0.838875
2021-12-27 20:54:44,338 |	  model_v_in_main test loss : 0.977983
2021-12-27 20:54:44,345 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:54:44,347 |	  Step count: 258
2021-12-27 20:55:40,592 |	  loss_w (train):1.337802935097443e-08
2021-12-27 20:55:54,486 |	  v_loss (train):59.98789978027344
2021-12-27 20:55:55,919 |	  model_w_in_main test loss : 0.838956
2021-12-27 20:55:56,463 |	  model_v_in_main test loss : 0.991728
2021-12-27 20:55:56,469 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:55:56,471 |	  Step count: 259
2021-12-27 20:56:33,416 |	  loss_w (train):8.642019544424784e-09
2021-12-27 20:56:41,663 |	  v_loss (train):6.489960670471191
2021-12-27 20:56:43,655 |	  model_w_in_main test loss : 0.838955
2021-12-27 20:56:44,215 |	  model_v_in_main test loss : 1.016717
2021-12-27 20:56:44,221 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:56:44,223 |	  Step count: 260
2021-12-27 20:57:18,726 |	  loss_w (train):6.551533093812623e-09
2021-12-27 20:57:25,757 |	  v_loss (train):18.038772583007812
2021-12-27 20:57:27,770 |	  model_w_in_main test loss : 0.838967
2021-12-27 20:57:28,295 |	  model_v_in_main test loss : 1.028910
2021-12-27 20:57:28,299 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:57:28,302 |	  Step count: 261
2021-12-27 20:58:58,829 |	  loss_w (train):3.067491505248654e-08
2021-12-27 20:59:21,915 |	  v_loss (train):373.5535888671875
2021-12-27 20:59:23,834 |	  model_w_in_main test loss : 0.838938
2021-12-27 20:59:24,007 |	  model_v_in_main test loss : 0.986345
2021-12-27 20:59:24,023 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 20:59:24,025 |	  Step count: 262
2021-12-27 21:00:05,108 |	  loss_w (train):1.2280912287110368e-08
2021-12-27 21:00:13,911 |	  v_loss (train):24.38312530517578
2021-12-27 21:00:15,837 |	  model_w_in_main test loss : 0.838934
2021-12-27 21:00:16,027 |	  model_v_in_main test loss : 0.997108
2021-12-27 21:00:16,045 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:00:16,047 |	  Step count: 263
2021-12-27 21:01:10,424 |	  loss_w (train):5.318994578118463e-09
2021-12-27 21:01:23,890 |	  v_loss (train):95.79769134521484
2021-12-27 21:01:25,980 |	  model_w_in_main test loss : 0.838937
2021-12-27 21:01:26,444 |	  model_v_in_main test loss : 0.971558
2021-12-27 21:01:26,455 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:01:26,458 |	  Step count: 264
2021-12-27 21:02:23,605 |	  loss_w (train):2.173809043881647e-08
2021-12-27 21:02:37,217 |	  v_loss (train):104.07196807861328
2021-12-27 21:02:38,653 |	  model_w_in_main test loss : 0.838933
2021-12-27 21:02:39,202 |	  model_v_in_main test loss : 0.978531
2021-12-27 21:02:39,207 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:02:39,209 |	  Step count: 265
2021-12-27 21:03:00,374 |	  loss_w (train):1.3539345644630885e-08
2021-12-27 21:03:02,393 |	  v_loss (train):0.14055101573467255
2021-12-27 21:03:04,290 |	  model_w_in_main test loss : 0.838960
2021-12-27 21:03:04,843 |	  model_v_in_main test loss : 0.943608
2021-12-27 21:03:04,848 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:03:04,850 |	  Step count: 266
2021-12-27 21:03:59,203 |	  loss_w (train):2.3740964749663362e-09
2021-12-27 21:04:06,300 |	  v_loss (train):82.08982849121094
2021-12-27 21:04:08,247 |	  model_w_in_main test loss : 0.838888
2021-12-27 21:04:08,780 |	  model_v_in_main test loss : 0.957519
2021-12-27 21:04:08,787 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:04:08,789 |	  Step count: 267
2021-12-27 21:05:00,231 |	  loss_w (train):6.9284915582557005e-09
2021-12-27 21:05:10,423 |	  v_loss (train):12.647895812988281
2021-12-27 21:05:12,427 |	  model_w_in_main test loss : 0.839010
2021-12-27 21:05:12,985 |	  model_v_in_main test loss : 0.987671
2021-12-27 21:05:12,992 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:05:12,993 |	  Step count: 268
2021-12-27 21:05:56,335 |	  loss_w (train):1.8941039847675256e-09
2021-12-27 21:06:06,535 |	  v_loss (train):51.938690185546875
2021-12-27 21:06:08,483 |	  model_w_in_main test loss : 0.838926
2021-12-27 21:06:09,058 |	  model_v_in_main test loss : 0.999787
2021-12-27 21:06:09,065 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:06:09,067 |	  Step count: 269
2021-12-27 21:06:47,135 |	  loss_w (train):1.950049011156807e-09
2021-12-27 21:06:54,777 |	  v_loss (train):22.24334144592285
2021-12-27 21:06:56,611 |	  model_w_in_main test loss : 0.838937
2021-12-27 21:06:56,802 |	  model_v_in_main test loss : 1.013353
2021-12-27 21:06:56,806 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:06:56,808 |	  Step count: 270
2021-12-27 21:07:29,746 |	  loss_w (train):1.6433638894142177e-09
2021-12-27 21:07:38,536 |	  v_loss (train):16.848093032836914
2021-12-27 21:07:40,398 |	  model_w_in_main test loss : 0.838960
2021-12-27 21:07:40,520 |	  model_v_in_main test loss : 1.034149
2021-12-27 21:07:40,543 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:07:40,544 |	  Step count: 271
2021-12-27 21:08:15,418 |	  loss_w (train):2.0913851983550558e-08
2021-12-27 21:08:18,024 |	  v_loss (train):0.2981375455856323
2021-12-27 21:08:20,283 |	  model_w_in_main test loss : 0.838777
2021-12-27 21:08:20,500 |	  model_v_in_main test loss : 1.144229
2021-12-27 21:08:20,505 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:08:20,507 |	  Step count: 272
2021-12-27 21:09:16,481 |	  loss_w (train):1.2903420554266631e-08
2021-12-27 21:09:27,502 |	  v_loss (train):66.98893737792969
2021-12-27 21:09:29,460 |	  model_w_in_main test loss : 0.838911
2021-12-27 21:09:30,010 |	  model_v_in_main test loss : 1.026374
2021-12-27 21:09:30,017 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:09:30,019 |	  Step count: 273
2021-12-27 21:09:56,102 |	  loss_w (train):4.381663920582923e-09
2021-12-27 21:10:02,054 |	  v_loss (train):17.28439712524414
2021-12-27 21:10:03,621 |	  model_w_in_main test loss : 0.838909
2021-12-27 21:10:04,054 |	  model_v_in_main test loss : 0.999874
2021-12-27 21:10:04,058 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:10:04,060 |	  Step count: 274
2021-12-27 21:10:37,227 |	  loss_w (train):6.7501391143309775e-09
2021-12-27 21:10:44,096 |	  v_loss (train):42.26494598388672
2021-12-27 21:10:46,086 |	  model_w_in_main test loss : 0.838942
2021-12-27 21:10:46,419 |	  model_v_in_main test loss : 0.999751
2021-12-27 21:10:46,473 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:10:46,476 |	  Step count: 275
2021-12-27 21:12:01,635 |	  loss_w (train):4.8651855877324124e-08
2021-12-27 21:12:21,489 |	  v_loss (train):108.43135070800781
2021-12-27 21:12:23,751 |	  model_w_in_main test loss : 0.838914
2021-12-27 21:12:23,881 |	  model_v_in_main test loss : 0.982741
2021-12-27 21:12:23,885 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:12:23,887 |	  Step count: 276
2021-12-27 21:12:51,080 |	  loss_w (train):2.097882534357609e-09
2021-12-27 21:12:56,281 |	  v_loss (train):21.960161209106445
2021-12-27 21:12:57,841 |	  model_w_in_main test loss : 0.838879
2021-12-27 21:12:58,315 |	  model_v_in_main test loss : 0.988012
2021-12-27 21:12:58,321 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:12:58,323 |	  Step count: 277
2021-12-27 21:14:28,480 |	  loss_w (train):2.321870917754154e-09
2021-12-27 21:14:51,001 |	  v_loss (train):84.636474609375
2021-12-27 21:14:53,045 |	  model_w_in_main test loss : 0.838931
2021-12-27 21:14:53,612 |	  model_v_in_main test loss : 0.995453
2021-12-27 21:14:53,618 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:14:53,620 |	  Step count: 278
2021-12-27 21:15:42,515 |	  loss_w (train):7.224255416105052e-09
2021-12-27 21:15:51,946 |	  v_loss (train):160.6743621826172
2021-12-27 21:15:53,914 |	  model_w_in_main test loss : 0.838915
2021-12-27 21:15:54,454 |	  model_v_in_main test loss : 0.989293
2021-12-27 21:15:54,462 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:15:54,464 |	  Step count: 279
2021-12-27 21:16:49,435 |	  loss_w (train):2.8705549048879675e-10
2021-12-27 21:16:56,547 |	  v_loss (train):37.37981414794922
2021-12-27 21:16:57,921 |	  model_w_in_main test loss : 0.838931
2021-12-27 21:16:58,468 |	  model_v_in_main test loss : 0.958683
2021-12-27 21:16:58,476 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:16:58,478 |	  Step count: 280
2021-12-27 21:18:14,568 |	  loss_w (train):5.025367344480003e-10
2021-12-27 21:18:35,308 |	  v_loss (train):133.33177185058594
2021-12-27 21:18:36,493 |	  model_w_in_main test loss : 0.838921
2021-12-27 21:18:36,600 |	  model_v_in_main test loss : 0.942413
2021-12-27 21:18:36,605 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:18:36,607 |	  Step count: 281
2021-12-27 21:18:57,583 |	  loss_w (train):2.7982528294501208e-08
2021-12-27 21:19:04,740 |	  v_loss (train):0.08448071777820587
2021-12-27 21:19:06,437 |	  model_w_in_main test loss : 0.838934
2021-12-27 21:19:06,582 |	  model_v_in_main test loss : 0.936705
2021-12-27 21:19:06,589 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:19:06,591 |	  Step count: 282
2021-12-27 21:19:36,560 |	  loss_w (train):2.1960717688784825e-08
2021-12-27 21:19:44,803 |	  v_loss (train):10.659235954284668
2021-12-27 21:19:46,921 |	  model_w_in_main test loss : 0.838906
2021-12-27 21:19:47,386 |	  model_v_in_main test loss : 0.909883
2021-12-27 21:19:47,400 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:19:47,403 |	  Step count: 283
2021-12-27 21:20:47,641 |	  loss_w (train):2.892726058689732e-08
2021-12-27 21:21:03,237 |	  v_loss (train):84.51673889160156
2021-12-27 21:21:05,534 |	  model_w_in_main test loss : 0.838904
2021-12-27 21:21:05,775 |	  model_v_in_main test loss : 0.899426
2021-12-27 21:21:05,788 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:21:05,791 |	  Step count: 284
2021-12-27 21:22:12,204 |	  loss_w (train):4.243204188014715e-08
2021-12-27 21:22:30,995 |	  v_loss (train):96.95896911621094
2021-12-27 21:22:32,956 |	  model_w_in_main test loss : 0.838895
2021-12-27 21:22:33,155 |	  model_v_in_main test loss : 0.924252
2021-12-27 21:22:33,169 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:22:33,171 |	  Step count: 285
2021-12-27 21:23:50,260 |	  loss_w (train):1.8195482898164528e-09
2021-12-27 21:24:10,874 |	  v_loss (train):123.05390930175781
2021-12-27 21:24:13,004 |	  model_w_in_main test loss : 0.838931
2021-12-27 21:24:13,473 |	  model_v_in_main test loss : 0.957232
2021-12-27 21:24:13,477 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:24:13,480 |	  Step count: 286
2021-12-27 21:24:41,939 |	  loss_w (train):1.926315995604e-08
2021-12-27 21:24:46,487 |	  v_loss (train):46.73414611816406
2021-12-27 21:24:48,491 |	  model_w_in_main test loss : 0.838970
2021-12-27 21:24:49,024 |	  model_v_in_main test loss : 0.965194
2021-12-27 21:24:49,029 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:24:49,031 |	  Step count: 287
2021-12-27 21:25:53,366 |	  loss_w (train):1.3788561958882894e-10
2021-12-27 21:26:08,617 |	  v_loss (train):103.44998931884766
2021-12-27 21:26:10,597 |	  model_w_in_main test loss : 0.838827
2021-12-27 21:26:11,067 |	  model_v_in_main test loss : 0.948790
2021-12-27 21:26:11,073 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:26:11,075 |	  Step count: 288
2021-12-27 21:27:06,104 |	  loss_w (train):1.6005970993049345e-09
2021-12-27 21:27:19,145 |	  v_loss (train):43.398860931396484
2021-12-27 21:27:21,037 |	  model_w_in_main test loss : 0.838995
2021-12-27 21:27:21,238 |	  model_v_in_main test loss : 0.992002
2021-12-27 21:27:21,254 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:27:21,256 |	  Step count: 289
2021-12-27 21:27:45,272 |	  loss_w (train):7.451052219664689e-09
2021-12-27 21:27:48,881 |	  v_loss (train):6.128369331359863
2021-12-27 21:27:50,947 |	  model_w_in_main test loss : 0.838966
2021-12-27 21:27:51,277 |	  model_v_in_main test loss : 1.053161
2021-12-27 21:27:51,332 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:27:51,334 |	  Step count: 290
2021-12-27 21:28:34,314 |	  loss_w (train):2.2873461347217017e-08
2021-12-27 21:28:43,249 |	  v_loss (train):27.31548309326172
2021-12-27 21:28:45,297 |	  model_w_in_main test loss : 0.838861
2021-12-27 21:28:45,764 |	  model_v_in_main test loss : 1.073145
2021-12-27 21:28:45,770 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:28:45,772 |	  Step count: 291
2021-12-27 21:29:27,431 |	  loss_w (train):1.5286472532238804e-08
2021-12-27 21:29:37,452 |	  v_loss (train):33.693016052246094
2021-12-27 21:29:39,494 |	  model_w_in_main test loss : 0.838921
2021-12-27 21:29:40,064 |	  model_v_in_main test loss : 1.083166
2021-12-27 21:29:40,069 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:29:40,071 |	  Step count: 292
2021-12-27 21:30:18,896 |	  loss_w (train):1.6583429740535394e-08
2021-12-27 21:30:24,577 |	  v_loss (train):32.0223503112793
2021-12-27 21:30:25,238 |	  model_w_in_main test loss : 0.838935
2021-12-27 21:30:25,586 |	  model_v_in_main test loss : 1.085545
2021-12-27 21:30:25,591 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:30:25,593 |	  Step count: 293
2021-12-27 21:31:36,474 |	  loss_w (train):1.2114904635041057e-09
2021-12-27 21:31:53,413 |	  v_loss (train):168.66348266601562
2021-12-27 21:31:54,878 |	  model_w_in_main test loss : 0.838890
2021-12-27 21:31:55,387 |	  model_v_in_main test loss : 1.077032
2021-12-27 21:31:55,393 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:31:55,395 |	  Step count: 294
2021-12-27 21:33:09,092 |	  loss_w (train):2.677715271737213e-10
2021-12-27 21:33:27,945 |	  v_loss (train):74.43690490722656
2021-12-27 21:33:29,306 |	  model_w_in_main test loss : 0.838897
2021-12-27 21:33:29,392 |	  model_v_in_main test loss : 1.049820
2021-12-27 21:33:29,397 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:33:29,399 |	  Step count: 295
2021-12-27 21:34:15,448 |	  loss_w (train):5.068563790899816e-09
2021-12-27 21:34:24,314 |	  v_loss (train):49.35081481933594
2021-12-27 21:34:26,203 |	  model_w_in_main test loss : 0.838858
2021-12-27 21:34:26,774 |	  model_v_in_main test loss : 1.019570
2021-12-27 21:34:26,779 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:34:26,781 |	  Step count: 296
2021-12-27 21:34:59,140 |	  loss_w (train):1.8008117219636688e-09
2021-12-27 21:35:08,848 |	  v_loss (train):40.855289459228516
2021-12-27 21:35:11,189 |	  model_w_in_main test loss : 0.838964
2021-12-27 21:35:11,318 |	  model_v_in_main test loss : 1.018987
2021-12-27 21:35:11,339 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:35:11,341 |	  Step count: 297
2021-12-27 21:36:00,540 |	  loss_w (train):1.6780864475762769e-09
2021-12-27 21:36:09,601 |	  v_loss (train):63.838478088378906
2021-12-27 21:36:10,110 |	  model_w_in_main test loss : 0.838933
2021-12-27 21:36:10,270 |	  model_v_in_main test loss : 0.998400
2021-12-27 21:36:10,274 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:36:10,276 |	  Step count: 298
2021-12-27 21:37:01,806 |	  loss_w (train):2.8493057913081543e-10
2021-12-27 21:37:12,136 |	  v_loss (train):75.62469482421875
2021-12-27 21:37:14,470 |	  model_w_in_main test loss : 0.838897
2021-12-27 21:37:14,608 |	  model_v_in_main test loss : 0.972590
2021-12-27 21:37:14,612 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:37:14,614 |	  Step count: 299
2021-12-27 21:37:56,656 |	  loss_w (train):6.599356616732166e-10
2021-12-27 21:38:05,452 |	  v_loss (train):48.20039367675781
2021-12-27 21:38:07,445 |	  model_w_in_main test loss : 0.838951
2021-12-27 21:38:08,023 |	  model_v_in_main test loss : 0.963470
2021-12-27 21:38:08,031 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:38:08,034 |	  Step count: 300
2021-12-27 21:38:34,701 |	  loss_w (train):2.3246807145937964e-08
2021-12-27 21:38:37,491 |	  v_loss (train):3.8468356132507324
2021-12-27 21:38:39,433 |	  model_w_in_main test loss : 0.838958
2021-12-27 21:38:39,976 |	  model_v_in_main test loss : 0.973358
2021-12-27 21:38:39,981 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:38:39,983 |	  Step count: 301
2021-12-27 21:39:20,327 |	  loss_w (train):2.6437674272017375e-09
2021-12-27 21:39:29,393 |	  v_loss (train):36.209896087646484
2021-12-27 21:39:31,345 |	  model_w_in_main test loss : 0.838854
2021-12-27 21:39:31,738 |	  model_v_in_main test loss : 0.963638
2021-12-27 21:39:31,792 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:39:31,794 |	  Step count: 302
2021-12-27 21:40:03,152 |	  loss_w (train):5.347198239746831e-09
2021-12-27 21:40:08,870 |	  v_loss (train):12.276893615722656
2021-12-27 21:40:10,716 |	  model_w_in_main test loss : 0.838933
2021-12-27 21:40:10,903 |	  model_v_in_main test loss : 0.962989
2021-12-27 21:40:10,953 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:40:10,954 |	  Step count: 303
2021-12-27 21:40:31,777 |	  loss_w (train):1.0914406045614555e-09
2021-12-27 21:40:34,312 |	  v_loss (train):0.14531269669532776
2021-12-27 21:40:36,252 |	  model_w_in_main test loss : 0.838956
2021-12-27 21:40:36,589 |	  model_v_in_main test loss : 0.975140
2021-12-27 21:40:36,640 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:40:36,642 |	  Step count: 304
2021-12-27 21:41:22,972 |	  loss_w (train):8.603326051570548e-09
2021-12-27 21:41:34,374 |	  v_loss (train):51.37847900390625
2021-12-27 21:41:36,770 |	  model_w_in_main test loss : 0.838951
2021-12-27 21:41:36,966 |	  model_v_in_main test loss : 0.987609
2021-12-27 21:41:37,006 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:41:37,008 |	  Step count: 305
2021-12-27 21:42:26,923 |	  loss_w (train):1.127246296306339e-09
2021-12-27 21:42:37,258 |	  v_loss (train):25.89104461669922
2021-12-27 21:42:39,361 |	  model_w_in_main test loss : 0.839019
2021-12-27 21:42:39,849 |	  model_v_in_main test loss : 0.987020
2021-12-27 21:42:39,854 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:42:39,856 |	  Step count: 306
2021-12-27 21:43:22,784 |	  loss_w (train):8.25903878620693e-09
2021-12-27 21:43:31,109 |	  v_loss (train):38.60506820678711
2021-12-27 21:43:32,955 |	  model_w_in_main test loss : 0.838980
2021-12-27 21:43:33,075 |	  model_v_in_main test loss : 1.022036
2021-12-27 21:43:33,147 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:43:33,149 |	  Step count: 307
2021-12-27 21:44:04,275 |	  loss_w (train):7.154721259894359e-09
2021-12-27 21:44:12,068 |	  v_loss (train):0.04806426912546158
2021-12-27 21:44:13,917 |	  model_w_in_main test loss : 0.838942
2021-12-27 21:44:14,065 |	  model_v_in_main test loss : 1.046417
2021-12-27 21:44:14,070 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:44:14,072 |	  Step count: 308
2021-12-27 21:44:41,236 |	  loss_w (train):6.600201274409301e-09
2021-12-27 21:44:45,643 |	  v_loss (train):8.811762809753418
2021-12-27 21:44:47,544 |	  model_w_in_main test loss : 0.838928
2021-12-27 21:44:47,749 |	  model_v_in_main test loss : 1.035119
2021-12-27 21:44:47,825 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:44:47,827 |	  Step count: 309
2021-12-27 21:45:33,495 |	  loss_w (train):1.1120068421632823e-08
2021-12-27 21:45:44,541 |	  v_loss (train):48.7645149230957
2021-12-27 21:45:46,540 |	  model_w_in_main test loss : 0.838963
2021-12-27 21:45:46,886 |	  model_v_in_main test loss : 1.028268
2021-12-27 21:45:46,940 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:45:46,942 |	  Step count: 310
2021-12-27 21:46:39,313 |	  loss_w (train):3.3027394708007307e-10
2021-12-27 21:46:51,329 |	  v_loss (train):21.89719009399414
2021-12-27 21:46:53,336 |	  model_w_in_main test loss : 0.838900
2021-12-27 21:46:53,808 |	  model_v_in_main test loss : 1.031733
2021-12-27 21:46:53,865 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:46:53,868 |	  Step count: 311
2021-12-27 21:47:26,869 |	  loss_w (train):1.8372309895653416e-08
2021-12-27 21:47:32,833 |	  v_loss (train):34.55107116699219
2021-12-27 21:47:34,169 |	  model_w_in_main test loss : 0.838945
2021-12-27 21:47:34,604 |	  model_v_in_main test loss : 1.007214
2021-12-27 21:47:34,608 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:47:34,611 |	  Step count: 312
2021-12-27 21:48:44,245 |	  loss_w (train):2.9400064605056286e-08
2021-12-27 21:49:04,242 |	  v_loss (train):80.90149688720703
2021-12-27 21:49:06,328 |	  model_w_in_main test loss : 0.838950
2021-12-27 21:49:06,856 |	  model_v_in_main test loss : 0.984015
2021-12-27 21:49:06,861 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:49:06,863 |	  Step count: 313
2021-12-27 21:49:34,634 |	  loss_w (train):6.587983047978696e-09
2021-12-27 21:49:39,747 |	  v_loss (train):33.895442962646484
2021-12-27 21:49:41,798 |	  model_w_in_main test loss : 0.838915
2021-12-27 21:49:42,302 |	  model_v_in_main test loss : 0.969288
2021-12-27 21:49:42,306 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:49:42,308 |	  Step count: 314
2021-12-27 21:50:33,479 |	  loss_w (train):2.2271248734107019e-10
2021-12-27 21:50:45,320 |	  v_loss (train):23.059871673583984
2021-12-27 21:50:47,358 |	  model_w_in_main test loss : 0.838944
2021-12-27 21:50:47,922 |	  model_v_in_main test loss : 0.967594
2021-12-27 21:50:47,926 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:50:47,928 |	  Step count: 315
2021-12-27 21:51:34,137 |	  loss_w (train):3.861173158981046e-09
2021-12-27 21:51:45,376 |	  v_loss (train):42.797637939453125
2021-12-27 21:51:47,321 |	  model_w_in_main test loss : 0.838948
2021-12-27 21:51:47,895 |	  model_v_in_main test loss : 0.978622
2021-12-27 21:51:47,899 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:51:47,901 |	  Step count: 316
2021-12-27 21:52:48,685 |	  loss_w (train):3.05952663204323e-09
2021-12-27 21:53:08,757 |	  v_loss (train):118.05784606933594
2021-12-27 21:53:10,776 |	  model_w_in_main test loss : 0.838911
2021-12-27 21:53:11,340 |	  model_v_in_main test loss : 0.967702
2021-12-27 21:53:11,346 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:53:11,348 |	  Step count: 317
2021-12-27 21:54:34,220 |	  loss_w (train):1.7278870001469215e-10
2021-12-27 21:54:54,993 |	  v_loss (train):53.28486633300781
2021-12-27 21:54:57,392 |	  model_w_in_main test loss : 0.838903
2021-12-27 21:54:57,535 |	  model_v_in_main test loss : 0.978851
2021-12-27 21:54:57,539 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:54:57,541 |	  Step count: 318
2021-12-27 21:56:33,385 |	  loss_w (train):1.211477353990631e-07
2021-12-27 21:56:52,981 |	  v_loss (train):175.18052673339844
2021-12-27 21:56:54,986 |	  model_w_in_main test loss : 0.838932
2021-12-27 21:56:55,512 |	  model_v_in_main test loss : 0.965984
2021-12-27 21:56:55,518 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:56:55,520 |	  Step count: 319
2021-12-27 21:57:35,054 |	  loss_w (train):2.9071043350370473e-09
2021-12-27 21:57:43,365 |	  v_loss (train):36.65990447998047
2021-12-27 21:57:45,385 |	  model_w_in_main test loss : 0.838876
2021-12-27 21:57:45,951 |	  model_v_in_main test loss : 0.959401
2021-12-27 21:57:45,955 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:57:45,957 |	  Step count: 320
2021-12-27 21:58:18,537 |	  loss_w (train):1.2487367584412823e-08
2021-12-27 21:58:24,813 |	  v_loss (train):29.737016677856445
2021-12-27 21:58:26,794 |	  model_w_in_main test loss : 0.839002
2021-12-27 21:58:26,949 |	  model_v_in_main test loss : 0.970283
2021-12-27 21:58:26,962 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:58:26,964 |	  Step count: 321
2021-12-27 21:59:20,823 |	  loss_w (train):1.7886245373688325e-08
2021-12-27 21:59:33,224 |	  v_loss (train):74.58584594726562
2021-12-27 21:59:35,565 |	  model_w_in_main test loss : 0.838913
2021-12-27 21:59:35,757 |	  model_v_in_main test loss : 0.968375
2021-12-27 21:59:35,765 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 21:59:35,766 |	  Step count: 322
2021-12-27 22:00:05,403 |	  loss_w (train):5.762890165073031e-09
2021-12-27 22:00:10,136 |	  v_loss (train):36.096229553222656
2021-12-27 22:00:12,114 |	  model_w_in_main test loss : 0.838908
2021-12-27 22:00:12,664 |	  model_v_in_main test loss : 1.008239
2021-12-27 22:00:12,671 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:00:12,673 |	  Step count: 323
2021-12-27 22:00:34,345 |	  loss_w (train):1.1531275490028747e-08
2021-12-27 22:00:37,561 |	  v_loss (train):0.48830002546310425
2021-12-27 22:00:39,919 |	  model_w_in_main test loss : 0.838936
2021-12-27 22:00:40,137 |	  model_v_in_main test loss : 1.036436
2021-12-27 22:00:40,149 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:00:40,151 |	  Step count: 324
2021-12-27 22:01:17,593 |	  loss_w (train):7.530932322197259e-09
2021-12-27 22:01:25,443 |	  v_loss (train):0.2651599645614624
2021-12-27 22:01:27,407 |	  model_w_in_main test loss : 0.838945
2021-12-27 22:01:27,967 |	  model_v_in_main test loss : 1.064400
2021-12-27 22:01:27,973 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:01:27,975 |	  Step count: 325
2021-12-27 22:02:14,236 |	  loss_w (train):6.425202148108156e-09
2021-12-27 22:02:24,602 |	  v_loss (train):52.29175567626953
2021-12-27 22:02:26,605 |	  model_w_in_main test loss : 0.838942
2021-12-27 22:02:26,817 |	  model_v_in_main test loss : 1.039421
2021-12-27 22:02:26,826 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:02:26,828 |	  Step count: 326
2021-12-27 22:03:22,055 |	  loss_w (train):1.9326147793208293e-08
2021-12-27 22:03:29,707 |	  v_loss (train):60.15331268310547
2021-12-27 22:03:31,097 |	  model_w_in_main test loss : 0.838905
2021-12-27 22:03:31,523 |	  model_v_in_main test loss : 1.014401
2021-12-27 22:03:31,532 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:03:31,534 |	  Step count: 327
2021-12-27 22:04:03,265 |	  loss_w (train):2.8996101075762226e-09
2021-12-27 22:04:06,611 |	  v_loss (train):0.10900545865297318
2021-12-27 22:04:08,750 |	  model_w_in_main test loss : 0.839036
2021-12-27 22:04:09,087 |	  model_v_in_main test loss : 1.037746
2021-12-27 22:04:09,140 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:04:09,142 |	  Step count: 328
2021-12-27 22:04:54,520 |	  loss_w (train):2.9703098314293186e-10
2021-12-27 22:05:03,738 |	  v_loss (train):28.714649200439453
2021-12-27 22:05:05,727 |	  model_w_in_main test loss : 0.838901
2021-12-27 22:05:06,322 |	  model_v_in_main test loss : 1.032421
2021-12-27 22:05:06,327 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:05:06,329 |	  Step count: 329
2021-12-27 22:06:03,025 |	  loss_w (train):2.7815723058211006e-09
2021-12-27 22:06:15,252 |	  v_loss (train):116.68147277832031
2021-12-27 22:06:17,237 |	  model_w_in_main test loss : 0.838986
2021-12-27 22:06:17,795 |	  model_v_in_main test loss : 1.082964
2021-12-27 22:06:17,801 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:06:17,803 |	  Step count: 330
2021-12-27 22:06:49,481 |	  loss_w (train):2.2701154733795192e-08
2021-12-27 22:06:55,362 |	  v_loss (train):73.49646759033203
2021-12-27 22:06:57,299 |	  model_w_in_main test loss : 0.838920
2021-12-27 22:06:57,880 |	  model_v_in_main test loss : 1.030835
2021-12-27 22:06:57,885 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:06:57,887 |	  Step count: 331
2021-12-27 22:07:50,056 |	  loss_w (train):4.694623711998247e-08
2021-12-27 22:08:02,930 |	  v_loss (train):41.218135833740234
2021-12-27 22:08:05,246 |	  model_w_in_main test loss : 0.838970
2021-12-27 22:08:05,747 |	  model_v_in_main test loss : 0.981434
2021-12-27 22:08:05,782 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:08:05,784 |	  Step count: 332
2021-12-27 22:08:54,300 |	  loss_w (train):4.7893532695297836e-08
2021-12-27 22:09:05,068 |	  v_loss (train):116.65425109863281
2021-12-27 22:09:07,071 |	  model_w_in_main test loss : 0.838985
2021-12-27 22:09:07,635 |	  model_v_in_main test loss : 0.946425
2021-12-27 22:09:07,640 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:09:07,642 |	  Step count: 333
2021-12-27 22:09:35,287 |	  loss_w (train):5.993540330706537e-09
2021-12-27 22:09:44,793 |	  v_loss (train):18.564239501953125
2021-12-27 22:09:46,736 |	  model_w_in_main test loss : 0.838932
2021-12-27 22:09:46,835 |	  model_v_in_main test loss : 0.989623
2021-12-27 22:09:46,839 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:09:46,840 |	  Step count: 334
2021-12-27 22:10:40,493 |	  loss_w (train):1.856650122533665e-08
2021-12-27 22:10:52,766 |	  v_loss (train):114.5199203491211
2021-12-27 22:10:54,754 |	  model_w_in_main test loss : 0.838867
2021-12-27 22:10:55,285 |	  model_v_in_main test loss : 0.929125
2021-12-27 22:10:55,294 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:10:55,296 |	  Step count: 335
2021-12-27 22:11:54,594 |	  loss_w (train):7.165166238110032e-09
2021-12-27 22:12:07,989 |	  v_loss (train):36.81998062133789
2021-12-27 22:12:09,914 |	  model_w_in_main test loss : 0.838951
2021-12-27 22:12:10,425 |	  model_v_in_main test loss : 0.974014
2021-12-27 22:12:10,436 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:12:10,438 |	  Step count: 336
2021-12-27 22:12:44,530 |	  loss_w (train):1.9637319326193392e-08
2021-12-27 22:12:50,807 |	  v_loss (train):18.8756103515625
2021-12-27 22:12:52,598 |	  model_w_in_main test loss : 0.838928
2021-12-27 22:12:52,714 |	  model_v_in_main test loss : 0.975754
2021-12-27 22:12:52,722 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:12:52,724 |	  Step count: 337
2021-12-27 22:13:43,065 |	  loss_w (train):5.753620690995831e-09
2021-12-27 22:13:55,072 |	  v_loss (train):44.88846206665039
2021-12-27 22:13:56,995 |	  model_w_in_main test loss : 0.838868
2021-12-27 22:13:57,124 |	  model_v_in_main test loss : 0.941004
2021-12-27 22:13:57,129 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:13:57,131 |	  Step count: 338
2021-12-27 22:14:43,358 |	  loss_w (train):2.0585030569009177e-08
2021-12-27 22:14:56,005 |	  v_loss (train):76.91609191894531
2021-12-27 22:14:57,943 |	  model_w_in_main test loss : 0.838862
2021-12-27 22:14:58,136 |	  model_v_in_main test loss : 0.916999
2021-12-27 22:14:58,146 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:14:58,148 |	  Step count: 339
2021-12-27 22:15:21,378 |	  loss_w (train):1.7355665704599232e-07
2021-12-27 22:15:24,582 |	  v_loss (train):13.353262901306152
2021-12-27 22:15:26,363 |	  model_w_in_main test loss : 0.839024
2021-12-27 22:15:26,517 |	  model_v_in_main test loss : 0.892173
2021-12-27 22:15:26,521 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:15:26,524 |	  Step count: 340
2021-12-27 22:16:11,959 |	  loss_w (train):2.7501498855997397e-09
2021-12-27 22:16:21,460 |	  v_loss (train):44.137474060058594
2021-12-27 22:16:23,758 |	  model_w_in_main test loss : 0.838933
2021-12-27 22:16:23,927 |	  model_v_in_main test loss : 0.888202
2021-12-27 22:16:23,935 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:16:23,937 |	  Step count: 341
2021-12-27 22:17:26,795 |	  loss_w (train):6.816368625095492e-08
2021-12-27 22:17:39,399 |	  v_loss (train):29.041139602661133
2021-12-27 22:17:41,419 |	  model_w_in_main test loss : 0.838945
2021-12-27 22:17:41,951 |	  model_v_in_main test loss : 0.882490
2021-12-27 22:17:41,956 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:17:41,958 |	  Step count: 342
2021-12-27 22:18:24,219 |	  loss_w (train):3.031740969383634e-10
2021-12-27 22:18:33,716 |	  v_loss (train):32.3674201965332
2021-12-27 22:18:35,653 |	  model_w_in_main test loss : 0.838944
2021-12-27 22:18:36,175 |	  model_v_in_main test loss : 0.895056
2021-12-27 22:18:36,182 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:18:36,184 |	  Step count: 343
2021-12-27 22:19:03,586 |	  loss_w (train):2.978219448834807e-09
2021-12-27 22:19:08,091 |	  v_loss (train):12.01031494140625
2021-12-27 22:19:09,853 |	  model_w_in_main test loss : 0.839014
2021-12-27 22:19:10,024 |	  model_v_in_main test loss : 0.906986
2021-12-27 22:19:10,030 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:19:10,032 |	  Step count: 344
2021-12-27 22:19:48,827 |	  loss_w (train):2.7655431722450885e-08
2021-12-27 22:19:57,681 |	  v_loss (train):24.90420913696289
2021-12-27 22:19:58,945 |	  model_w_in_main test loss : 0.838927
2021-12-27 22:19:59,144 |	  model_v_in_main test loss : 0.901633
2021-12-27 22:19:59,157 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:19:59,159 |	  Step count: 345
2021-12-27 22:21:27,982 |	  loss_w (train):6.0557940884109485e-09
2021-12-27 22:21:52,606 |	  v_loss (train):443.86602783203125
2021-12-27 22:21:54,840 |	  model_w_in_main test loss : 0.838969
2021-12-27 22:21:55,120 |	  model_v_in_main test loss : 0.903394
2021-12-27 22:21:55,124 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:21:55,125 |	  Step count: 346
2021-12-27 22:22:38,837 |	  loss_w (train):1.1069718475198442e-08
2021-12-27 22:22:49,516 |	  v_loss (train):32.80699920654297
2021-12-27 22:22:51,945 |	  model_w_in_main test loss : 0.838959
2021-12-27 22:22:52,091 |	  model_v_in_main test loss : 0.938504
2021-12-27 22:22:52,095 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:22:52,097 |	  Step count: 347
2021-12-27 22:23:30,114 |	  loss_w (train):9.679741452828239e-09
2021-12-27 22:23:40,151 |	  v_loss (train):47.47825241088867
2021-12-27 22:23:41,742 |	  model_w_in_main test loss : 0.838950
2021-12-27 22:23:42,103 |	  model_v_in_main test loss : 0.972097
2021-12-27 22:23:42,109 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:23:42,111 |	  Step count: 348
2021-12-27 22:24:24,656 |	  loss_w (train):9.806864653683078e-09
2021-12-27 22:24:33,691 |	  v_loss (train):24.806312561035156
2021-12-27 22:24:35,179 |	  model_w_in_main test loss : 0.838890
2021-12-27 22:24:35,724 |	  model_v_in_main test loss : 1.009262
2021-12-27 22:24:35,731 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:24:35,733 |	  Step count: 349
2021-12-27 22:25:15,523 |	  loss_w (train):1.1263034949138273e-08
2021-12-27 22:25:24,951 |	  v_loss (train):49.927974700927734
2021-12-27 22:25:26,838 |	  model_w_in_main test loss : 0.838956
2021-12-27 22:25:27,394 |	  model_v_in_main test loss : 1.015143
2021-12-27 22:25:27,400 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:25:27,402 |	  Step count: 350
2021-12-27 22:25:59,272 |	  loss_w (train):2.734165671647304e-10
2021-12-27 22:26:07,536 |	  v_loss (train):7.680376052856445
2021-12-27 22:26:09,483 |	  model_w_in_main test loss : 0.838982
2021-12-27 22:26:09,687 |	  model_v_in_main test loss : 1.006527
2021-12-27 22:26:09,698 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:26:09,699 |	  Step count: 351
2021-12-27 22:26:51,587 |	  loss_w (train):3.143023619145424e-09
2021-12-27 22:27:01,096 |	  v_loss (train):41.67957305908203
2021-12-27 22:27:03,111 |	  model_w_in_main test loss : 0.838916
2021-12-27 22:27:03,676 |	  model_v_in_main test loss : 1.016096
2021-12-27 22:27:03,680 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:27:03,682 |	  Step count: 352
2021-12-27 22:27:53,415 |	  loss_w (train):1.7851162215087868e-10
2021-12-27 22:28:05,362 |	  v_loss (train):21.68903350830078
2021-12-27 22:28:07,320 |	  model_w_in_main test loss : 0.838888
2021-12-27 22:28:07,897 |	  model_v_in_main test loss : 1.015774
2021-12-27 22:28:07,905 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:28:07,907 |	  Step count: 353
2021-12-27 22:28:30,221 |	  loss_w (train):2.4272047483009374e-08
2021-12-27 22:28:33,293 |	  v_loss (train):1.67734956741333
2021-12-27 22:28:35,324 |	  model_w_in_main test loss : 0.838932
2021-12-27 22:28:35,894 |	  model_v_in_main test loss : 1.023984
2021-12-27 22:28:35,898 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:28:35,900 |	  Step count: 354
2021-12-27 22:29:02,771 |	  loss_w (train):1.3599436021749511e-09
2021-12-27 22:29:06,620 |	  v_loss (train):6.603561878204346
2021-12-27 22:29:07,997 |	  model_w_in_main test loss : 0.838838
2021-12-27 22:29:08,205 |	  model_v_in_main test loss : 1.021199
2021-12-27 22:29:08,209 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:29:08,211 |	  Step count: 355
2021-12-27 22:29:29,852 |	  loss_w (train):8.115796035212952e-09
2021-12-27 22:29:32,605 |	  v_loss (train):0.9957107305526733
2021-12-27 22:29:34,518 |	  model_w_in_main test loss : 0.838959
2021-12-27 22:29:35,070 |	  model_v_in_main test loss : 0.998784
2021-12-27 22:29:35,076 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:29:35,079 |	  Step count: 356
2021-12-27 22:30:18,803 |	  loss_w (train):8.058543166100662e-09
2021-12-27 22:30:27,937 |	  v_loss (train):22.749038696289062
2021-12-27 22:30:29,931 |	  model_w_in_main test loss : 0.838925
2021-12-27 22:30:30,016 |	  model_v_in_main test loss : 0.953661
2021-12-27 22:30:30,021 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:30:30,023 |	  Step count: 357
2021-12-27 22:30:54,922 |	  loss_w (train):7.378023081372476e-09
2021-12-27 22:30:58,266 |	  v_loss (train):0.5412641167640686
2021-12-27 22:31:00,252 |	  model_w_in_main test loss : 0.838928
2021-12-27 22:31:00,803 |	  model_v_in_main test loss : 0.965035
2021-12-27 22:31:00,808 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:31:00,810 |	  Step count: 358
2021-12-27 22:31:51,426 |	  loss_w (train):1.8172119808923526e-08
2021-12-27 22:32:00,286 |	  v_loss (train):85.935546875
2021-12-27 22:32:02,169 |	  model_w_in_main test loss : 0.838910
2021-12-27 22:32:02,328 |	  model_v_in_main test loss : 0.953680
2021-12-27 22:32:02,338 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:32:02,340 |	  Step count: 359
2021-12-27 22:32:49,813 |	  loss_w (train):5.751114695584647e-09
2021-12-27 22:32:59,844 |	  v_loss (train):5.993447780609131
2021-12-27 22:33:01,800 |	  model_w_in_main test loss : 0.838935
2021-12-27 22:33:02,392 |	  model_v_in_main test loss : 0.982308
2021-12-27 22:33:02,399 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:33:02,401 |	  Step count: 360
2021-12-27 22:33:44,204 |	  loss_w (train):1.3709022805841187e-09
2021-12-27 22:33:52,489 |	  v_loss (train):35.4727783203125
2021-12-27 22:33:54,437 |	  model_w_in_main test loss : 0.838967
2021-12-27 22:33:54,691 |	  model_v_in_main test loss : 0.982692
2021-12-27 22:33:54,762 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:33:54,765 |	  Step count: 361
2021-12-27 22:34:50,114 |	  loss_w (train):1.3034655577115473e-09
2021-12-27 22:35:04,539 |	  v_loss (train):99.07087707519531
2021-12-27 22:35:06,526 |	  model_w_in_main test loss : 0.838987
2021-12-27 22:35:07,087 |	  model_v_in_main test loss : 0.969630
2021-12-27 22:35:07,093 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:35:07,096 |	  Step count: 362
2021-12-27 22:35:50,105 |	  loss_w (train):4.472902048746619e-08
2021-12-27 22:35:59,359 |	  v_loss (train):53.02798080444336
2021-12-27 22:36:01,320 |	  model_w_in_main test loss : 0.838944
2021-12-27 22:36:01,453 |	  model_v_in_main test loss : 0.953206
2021-12-27 22:36:01,458 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:36:01,461 |	  Step count: 363
2021-12-27 22:36:37,376 |	  loss_w (train):6.964185339519702e-10
2021-12-27 22:36:45,991 |	  v_loss (train):9.453561782836914
2021-12-27 22:36:48,063 |	  model_w_in_main test loss : 0.838944
2021-12-27 22:36:48,635 |	  model_v_in_main test loss : 0.930426
2021-12-27 22:36:48,643 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:36:48,645 |	  Step count: 364
2021-12-27 22:37:19,268 |	  loss_w (train):1.506286295693826e-08
2021-12-27 22:37:24,643 |	  v_loss (train):46.39382553100586
2021-12-27 22:37:26,766 |	  model_w_in_main test loss : 0.838945
2021-12-27 22:37:26,935 |	  model_v_in_main test loss : 0.963331
2021-12-27 22:37:26,956 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:37:26,958 |	  Step count: 365
2021-12-27 22:38:38,351 |	  loss_w (train):1.8238972998574354e-08
2021-12-27 22:38:54,464 |	  v_loss (train):137.175048828125
2021-12-27 22:38:56,568 |	  model_w_in_main test loss : 0.838941
2021-12-27 22:38:56,940 |	  model_v_in_main test loss : 0.971250
2021-12-27 22:38:56,945 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:38:56,947 |	  Step count: 366
2021-12-27 22:40:35,232 |	  loss_w (train):4.090738769946256e-08
2021-12-27 22:40:53,879 |	  v_loss (train):327.16314697265625
2021-12-27 22:40:56,015 |	  model_w_in_main test loss : 0.838962
2021-12-27 22:40:56,303 |	  model_v_in_main test loss : 0.953361
2021-12-27 22:40:56,309 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:40:56,311 |	  Step count: 367
2021-12-27 22:41:34,602 |	  loss_w (train):2.2182092274114495e-10
2021-12-27 22:41:42,729 |	  v_loss (train):42.61613845825195
2021-12-27 22:41:44,767 |	  model_w_in_main test loss : 0.838975
2021-12-27 22:41:45,329 |	  model_v_in_main test loss : 0.927122
2021-12-27 22:41:45,335 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:41:45,337 |	  Step count: 368
2021-12-27 22:42:52,002 |	  loss_w (train):6.802778340642135e-09
2021-12-27 22:43:09,241 |	  v_loss (train):83.22602081298828
2021-12-27 22:43:10,821 |	  model_w_in_main test loss : 0.838906
2021-12-27 22:43:11,346 |	  model_v_in_main test loss : 0.930517
2021-12-27 22:43:11,351 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:43:11,353 |	  Step count: 369
2021-12-27 22:44:23,094 |	  loss_w (train):1.6935684854502142e-08
2021-12-27 22:44:39,284 |	  v_loss (train):80.35984802246094
2021-12-27 22:44:41,221 |	  model_w_in_main test loss : 0.838828
2021-12-27 22:44:41,799 |	  model_v_in_main test loss : 0.944182
2021-12-27 22:44:41,805 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:44:41,807 |	  Step count: 370
2021-12-27 22:45:08,749 |	  loss_w (train):2.970432788629296e-09
2021-12-27 22:45:12,554 |	  v_loss (train):23.15960121154785
2021-12-27 22:45:14,597 |	  model_w_in_main test loss : 0.838924
2021-12-27 22:45:15,076 |	  model_v_in_main test loss : 0.941249
2021-12-27 22:45:15,081 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:45:15,083 |	  Step count: 371
2021-12-27 22:45:37,505 |	  loss_w (train):4.734419078999963e-09
2021-12-27 22:45:40,163 |	  v_loss (train):0.0863637775182724
2021-12-27 22:45:42,122 |	  model_w_in_main test loss : 0.838925
2021-12-27 22:45:42,685 |	  model_v_in_main test loss : 0.915366
2021-12-27 22:45:42,690 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:45:42,692 |	  Step count: 372
2021-12-27 22:46:09,870 |	  loss_w (train):6.880966907374386e-09
2021-12-27 22:46:17,625 |	  v_loss (train):0.02783750370144844
2021-12-27 22:46:18,091 |	  model_w_in_main test loss : 0.838947
2021-12-27 22:46:18,283 |	  model_v_in_main test loss : 0.917124
2021-12-27 22:46:18,287 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:46:18,289 |	  Step count: 373
2021-12-27 22:47:50,453 |	  loss_w (train):7.805053270359963e-10
2021-12-27 22:48:16,448 |	  v_loss (train):129.10055541992188
2021-12-27 22:48:18,493 |	  model_w_in_main test loss : 0.838914
2021-12-27 22:48:18,985 |	  model_v_in_main test loss : 0.902157
2021-12-27 22:48:18,990 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:48:18,992 |	  Step count: 374
2021-12-27 22:48:47,106 |	  loss_w (train):4.5089332267878035e-10
2021-12-27 22:48:51,604 |	  v_loss (train):10.107620239257812
2021-12-27 22:48:53,083 |	  model_w_in_main test loss : 0.838924
2021-12-27 22:48:53,527 |	  model_v_in_main test loss : 0.903262
2021-12-27 22:48:53,533 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:48:53,535 |	  Step count: 375
2021-12-27 22:50:00,734 |	  loss_w (train):2.267670140554401e-08
2021-12-27 22:50:23,188 |	  v_loss (train):102.40299224853516
2021-12-27 22:50:25,180 |	  model_w_in_main test loss : 0.838890
2021-12-27 22:50:25,741 |	  model_v_in_main test loss : 0.918987
2021-12-27 22:50:25,749 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:50:25,751 |	  Step count: 376
2021-12-27 22:51:08,821 |	  loss_w (train):5.2523674298754486e-08
2021-12-27 22:51:20,886 |	  v_loss (train):28.171308517456055
2021-12-27 22:51:22,895 |	  model_w_in_main test loss : 0.838898
2021-12-27 22:51:23,476 |	  model_v_in_main test loss : 0.901504
2021-12-27 22:51:23,482 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:51:23,484 |	  Step count: 377
2021-12-27 22:52:56,225 |	  loss_w (train):4.787070295719786e-09
2021-12-27 22:53:21,524 |	  v_loss (train):123.8480453491211
2021-12-27 22:53:23,515 |	  model_w_in_main test loss : 0.838987
2021-12-27 22:53:24,024 |	  model_v_in_main test loss : 0.898796
2021-12-27 22:53:24,030 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:53:24,032 |	  Step count: 378
2021-12-27 22:53:51,371 |	  loss_w (train):8.937812268072776e-09
2021-12-27 22:53:55,227 |	  v_loss (train):10.085631370544434
2021-12-27 22:53:57,078 |	  model_w_in_main test loss : 0.838950
2021-12-27 22:53:57,305 |	  model_v_in_main test loss : 0.912280
2021-12-27 22:53:57,363 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:53:57,365 |	  Step count: 379
2021-12-27 22:54:18,820 |	  loss_w (train):4.840635448033481e-09
2021-12-27 22:54:21,536 |	  v_loss (train):0.09448545426130295
2021-12-27 22:54:23,332 |	  model_w_in_main test loss : 0.838924
2021-12-27 22:54:23,515 |	  model_v_in_main test loss : 0.921278
2021-12-27 22:54:23,520 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:54:23,522 |	  Step count: 380
2021-12-27 22:55:06,850 |	  loss_w (train):3.8189034157198876e-09
2021-12-27 22:55:15,642 |	  v_loss (train):58.9462890625
2021-12-27 22:55:17,626 |	  model_w_in_main test loss : 0.838910
2021-12-27 22:55:18,012 |	  model_v_in_main test loss : 0.922049
2021-12-27 22:55:18,017 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:55:18,018 |	  Step count: 381
2021-12-27 22:55:39,400 |	  loss_w (train):1.1789673681761315e-09
2021-12-27 22:55:42,083 |	  v_loss (train):0.10712296515703201
2021-12-27 22:55:44,051 |	  model_w_in_main test loss : 0.838942
2021-12-27 22:55:44,612 |	  model_v_in_main test loss : 0.921370
2021-12-27 22:55:44,619 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:55:44,621 |	  Step count: 382
2021-12-27 22:56:37,551 |	  loss_w (train):1.1547305334147495e-09
2021-12-27 22:56:49,107 |	  v_loss (train):80.68843078613281
2021-12-27 22:56:51,406 |	  model_w_in_main test loss : 0.838868
2021-12-27 22:56:51,541 |	  model_v_in_main test loss : 0.936790
2021-12-27 22:56:51,545 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:56:51,547 |	  Step count: 383
2021-12-27 22:57:13,531 |	  loss_w (train):1.3748867822016564e-08
2021-12-27 22:57:16,525 |	  v_loss (train):0.08512280136346817
2021-12-27 22:57:18,781 |	  model_w_in_main test loss : 0.838882
2021-12-27 22:57:19,090 |	  model_v_in_main test loss : 1.006549
2021-12-27 22:57:19,094 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:57:19,096 |	  Step count: 384
2021-12-27 22:58:18,982 |	  loss_w (train):2.3769986867705484e-08
2021-12-27 22:58:37,287 |	  v_loss (train):72.31190490722656
2021-12-27 22:58:39,266 |	  model_w_in_main test loss : 0.838912
2021-12-27 22:58:39,812 |	  model_v_in_main test loss : 1.030610
2021-12-27 22:58:39,818 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:58:39,820 |	  Step count: 385
2021-12-27 22:59:01,679 |	  loss_w (train):1.5429996835791826e-08
2021-12-27 22:59:04,445 |	  v_loss (train):5.232635974884033
2021-12-27 22:59:06,398 |	  model_w_in_main test loss : 0.838872
2021-12-27 22:59:06,551 |	  model_v_in_main test loss : 0.989895
2021-12-27 22:59:06,586 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:59:06,588 |	  Step count: 386
2021-12-27 22:59:46,246 |	  loss_w (train):3.8061565010849563e-10
2021-12-27 22:59:56,953 |	  v_loss (train):25.480979919433594
2021-12-27 22:59:59,158 |	  model_w_in_main test loss : 0.838916
2021-12-27 22:59:59,493 |	  model_v_in_main test loss : 0.970989
2021-12-27 22:59:59,497 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 22:59:59,499 |	  Step count: 387
2021-12-27 23:00:28,604 |	  loss_w (train):7.483307307154519e-09
2021-12-27 23:00:33,624 |	  v_loss (train):32.330535888671875
2021-12-27 23:00:35,713 |	  model_w_in_main test loss : 0.838951
2021-12-27 23:00:36,171 |	  model_v_in_main test loss : 0.964548
2021-12-27 23:00:36,176 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:00:36,179 |	  Step count: 388
2021-12-27 23:02:01,675 |	  loss_w (train):1.0666134642178804e-09
2021-12-27 23:02:24,451 |	  v_loss (train):131.81983947753906
2021-12-27 23:02:26,813 |	  model_w_in_main test loss : 0.838881
2021-12-27 23:02:26,990 |	  model_v_in_main test loss : 0.951370
2021-12-27 23:02:26,996 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:02:26,998 |	  Step count: 389
2021-12-27 23:02:53,126 |	  loss_w (train):3.8113894262892245e-09
2021-12-27 23:02:58,135 |	  v_loss (train):5.132236480712891
2021-12-27 23:03:00,120 |	  model_w_in_main test loss : 0.838826
2021-12-27 23:03:00,616 |	  model_v_in_main test loss : 0.930668
2021-12-27 23:03:00,620 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:03:00,622 |	  Step count: 390
2021-12-27 23:03:51,861 |	  loss_w (train):1.529096778085659e-07
2021-12-27 23:04:01,117 |	  v_loss (train):45.775447845458984
2021-12-27 23:04:02,567 |	  model_w_in_main test loss : 0.838856
2021-12-27 23:04:03,114 |	  model_v_in_main test loss : 0.931571
2021-12-27 23:04:03,119 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:04:03,121 |	  Step count: 391
2021-12-27 23:04:58,479 |	  loss_w (train):6.973530730647326e-08
2021-12-27 23:05:11,211 |	  v_loss (train):71.46593475341797
2021-12-27 23:05:13,013 |	  model_w_in_main test loss : 0.838974
2021-12-27 23:05:13,149 |	  model_v_in_main test loss : 0.943930
2021-12-27 23:05:13,165 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:05:13,167 |	  Step count: 392
2021-12-27 23:05:39,388 |	  loss_w (train):3.8304531768673655e-10
2021-12-27 23:05:47,909 |	  v_loss (train):0.036934852600097656
2021-12-27 23:05:50,069 |	  model_w_in_main test loss : 0.838920
2021-12-27 23:05:50,204 |	  model_v_in_main test loss : 0.948469
2021-12-27 23:05:50,209 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:05:50,211 |	  Step count: 393
2021-12-27 23:06:56,895 |	  loss_w (train):7.845047278465245e-09
2021-12-27 23:07:06,297 |	  v_loss (train):27.6212158203125
2021-12-27 23:07:08,702 |	  model_w_in_main test loss : 0.838879
2021-12-27 23:07:08,844 |	  model_v_in_main test loss : 0.992563
2021-12-27 23:07:08,848 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:07:08,850 |	  Step count: 394
2021-12-27 23:08:02,991 |	  loss_w (train):1.6895830512453358e-08
2021-12-27 23:08:14,410 |	  v_loss (train):73.4979248046875
2021-12-27 23:08:16,523 |	  model_w_in_main test loss : 0.838897
2021-12-27 23:08:16,971 |	  model_v_in_main test loss : 0.992118
2021-12-27 23:08:16,975 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:08:16,977 |	  Step count: 395
2021-12-27 23:09:26,752 |	  loss_w (train):2.1819530626743244e-09
2021-12-27 23:09:45,592 |	  v_loss (train):75.23149871826172
2021-12-27 23:09:47,592 |	  model_w_in_main test loss : 0.838804
2021-12-27 23:09:48,151 |	  model_v_in_main test loss : 0.949833
2021-12-27 23:09:48,157 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:09:48,160 |	  Step count: 396
2021-12-27 23:11:13,204 |	  loss_w (train):4.39589662448725e-08
2021-12-27 23:11:34,640 |	  v_loss (train):88.06364440917969
2021-12-27 23:11:36,677 |	  model_w_in_main test loss : 0.838929
2021-12-27 23:11:37,233 |	  model_v_in_main test loss : 0.934028
2021-12-27 23:11:37,238 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:11:37,241 |	  Step count: 397
2021-12-27 23:12:36,572 |	  loss_w (train):9.72919877995082e-09
2021-12-27 23:12:46,696 |	  v_loss (train):80.46907806396484
2021-12-27 23:12:48,797 |	  model_w_in_main test loss : 0.838964
2021-12-27 23:12:49,222 |	  model_v_in_main test loss : 0.962159
2021-12-27 23:12:49,228 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:12:49,230 |	  Step count: 398
2021-12-27 23:14:18,743 |	  loss_w (train):3.482803023757697e-08
2021-12-27 23:14:42,501 |	  v_loss (train):257.3810729980469
2021-12-27 23:14:44,660 |	  model_w_in_main test loss : 0.838952
2021-12-27 23:14:44,990 |	  model_v_in_main test loss : 0.965252
2021-12-27 23:14:45,000 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:14:45,002 |	  Step count: 399
2021-12-27 23:15:44,425 |	  loss_w (train):4.874046721781156e-10
2021-12-27 23:15:55,846 |	  v_loss (train):81.21491241455078
2021-12-27 23:15:58,164 |	  model_w_in_main test loss : 0.838953
2021-12-27 23:15:58,672 |	  model_v_in_main test loss : 0.955351
2021-12-27 23:15:58,704 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:15:58,706 |	  Step count: 400
2021-12-27 23:17:07,693 |	  loss_w (train):8.842835352851353e-10
2021-12-27 23:17:24,620 |	  v_loss (train):85.08114624023438
2021-12-27 23:17:26,636 |	  model_w_in_main test loss : 0.838852
2021-12-27 23:17:27,202 |	  model_v_in_main test loss : 0.958879
2021-12-27 23:17:27,209 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:17:27,211 |	  Step count: 401
2021-12-27 23:18:05,318 |	  loss_w (train):2.5774640755038547e-10
2021-12-27 23:18:13,614 |	  v_loss (train):0.02369987778365612
2021-12-27 23:18:15,493 |	  model_w_in_main test loss : 0.838891
2021-12-27 23:18:15,810 |	  model_v_in_main test loss : 0.968681
2021-12-27 23:18:15,837 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:18:15,839 |	  Step count: 402
2021-12-27 23:18:50,701 |	  loss_w (train):2.1157462448684328e-09
2021-12-27 23:18:57,356 |	  v_loss (train):54.80202865600586
2021-12-27 23:18:59,278 |	  model_w_in_main test loss : 0.838907
2021-12-27 23:18:59,854 |	  model_v_in_main test loss : 0.908193
2021-12-27 23:18:59,862 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:18:59,864 |	  Step count: 403
2021-12-27 23:19:48,173 |	  loss_w (train):2.3756557832044223e-10
2021-12-27 23:19:55,845 |	  v_loss (train):50.0504150390625
2021-12-27 23:19:57,758 |	  model_w_in_main test loss : 0.838850
2021-12-27 23:19:58,323 |	  model_v_in_main test loss : 0.870634
2021-12-27 23:19:58,329 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:19:58,331 |	  Step count: 404
2021-12-27 23:20:30,082 |	  loss_w (train):9.210195273112731e-09
2021-12-27 23:20:35,770 |	  v_loss (train):6.680319786071777
2021-12-27 23:20:38,219 |	  model_w_in_main test loss : 0.838914
2021-12-27 23:20:38,392 |	  model_v_in_main test loss : 0.862567
2021-12-27 23:20:38,408 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:20:38,411 |	  Step count: 405
2021-12-27 23:21:22,734 |	  loss_w (train):2.1061477895045755e-08
2021-12-27 23:21:27,831 |	  v_loss (train):19.928529739379883
2021-12-27 23:21:30,174 |	  model_w_in_main test loss : 0.838915
2021-12-27 23:21:30,650 |	  model_v_in_main test loss : 0.868841
2021-12-27 23:21:30,693 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:21:30,695 |	  Step count: 406
2021-12-27 23:22:27,602 |	  loss_w (train):2.788818562748929e-07
2021-12-27 23:22:40,765 |	  v_loss (train):51.87898635864258
2021-12-27 23:22:42,801 |	  model_w_in_main test loss : 0.838934
2021-12-27 23:22:43,271 |	  model_v_in_main test loss : 0.870533
2021-12-27 23:22:43,276 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:22:43,278 |	  Step count: 407
2021-12-27 23:23:13,879 |	  loss_w (train):1.760479761969691e-08
2021-12-27 23:23:23,478 |	  v_loss (train):13.892065048217773
2021-12-27 23:23:25,532 |	  model_w_in_main test loss : 0.838867
2021-12-27 23:23:25,868 |	  model_v_in_main test loss : 0.858130
2021-12-27 23:23:25,872 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:23:25,874 |	  Step count: 408
2021-12-27 23:24:30,284 |	  loss_w (train):1.4860082053758106e-08
2021-12-27 23:24:40,146 |	  v_loss (train):141.66311645507812
2021-12-27 23:24:42,367 |	  model_w_in_main test loss : 0.838933
2021-12-27 23:24:42,678 |	  model_v_in_main test loss : 0.844053
2021-12-27 23:24:42,683 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:24:42,685 |	  Step count: 409
2021-12-27 23:25:27,923 |	  loss_w (train):1.3734446913105103e-09
2021-12-27 23:25:36,999 |	  v_loss (train):31.12582778930664
2021-12-27 23:25:39,107 |	  model_w_in_main test loss : 0.838875
2021-12-27 23:25:39,549 |	  model_v_in_main test loss : 0.856659
2021-12-27 23:25:39,553 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:25:39,555 |	  Step count: 410
2021-12-27 23:26:22,047 |	  loss_w (train):1.393532622628868e-09
2021-12-27 23:26:30,806 |	  v_loss (train):112.10983276367188
2021-12-27 23:26:32,786 |	  model_w_in_main test loss : 0.838861
2021-12-27 23:26:33,332 |	  model_v_in_main test loss : 0.865061
2021-12-27 23:26:33,336 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:26:33,338 |	  Step count: 411
2021-12-27 23:27:10,223 |	  loss_w (train):8.135940254838658e-10
2021-12-27 23:27:18,634 |	  v_loss (train):0.09636835008859634
2021-12-27 23:27:20,473 |	  model_w_in_main test loss : 0.838876
2021-12-27 23:27:21,019 |	  model_v_in_main test loss : 0.868654
2021-12-27 23:27:21,025 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:27:21,027 |	  Step count: 412
2021-12-27 23:28:18,163 |	  loss_w (train):1.1017564638393651e-08
2021-12-27 23:28:32,335 |	  v_loss (train):47.510047912597656
2021-12-27 23:28:34,556 |	  model_w_in_main test loss : 0.838930
2021-12-27 23:28:34,761 |	  model_v_in_main test loss : 0.863573
2021-12-27 23:28:34,777 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:28:34,779 |	  Step count: 413
2021-12-27 23:29:46,506 |	  loss_w (train):2.2470484140058034e-08
2021-12-27 23:30:05,868 |	  v_loss (train):62.01960754394531
2021-12-27 23:30:08,188 |	  model_w_in_main test loss : 0.838986
2021-12-27 23:30:08,529 |	  model_v_in_main test loss : 0.878175
2021-12-27 23:30:08,536 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:30:08,538 |	  Step count: 414
2021-12-27 23:30:46,289 |	  loss_w (train):1.2456570175345405e-07
2021-12-27 23:30:52,803 |	  v_loss (train):19.811553955078125
2021-12-27 23:30:54,802 |	  model_w_in_main test loss : 0.838849
2021-12-27 23:30:55,390 |	  model_v_in_main test loss : 0.872576
2021-12-27 23:30:55,395 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:30:55,397 |	  Step count: 415
2021-12-27 23:31:56,889 |	  loss_w (train):2.1764197555285136e-08
2021-12-27 23:32:14,225 |	  v_loss (train):75.1591796875
2021-12-27 23:32:15,891 |	  model_w_in_main test loss : 0.838886
2021-12-27 23:32:16,452 |	  model_v_in_main test loss : 0.863314
2021-12-27 23:32:16,458 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:32:16,460 |	  Step count: 416
2021-12-27 23:33:44,781 |	  loss_w (train):7.098961418705585e-08
2021-12-27 23:34:09,152 |	  v_loss (train):143.44139099121094
2021-12-27 23:34:11,379 |	  model_w_in_main test loss : 0.838885
2021-12-27 23:34:11,900 |	  model_v_in_main test loss : 0.897971
2021-12-27 23:34:11,908 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:34:11,910 |	  Step count: 417
2021-12-27 23:34:57,438 |	  loss_w (train):6.0003690904864015e-09
2021-12-27 23:35:05,915 |	  v_loss (train):77.95248413085938
2021-12-27 23:35:07,856 |	  model_w_in_main test loss : 0.838862
2021-12-27 23:35:07,944 |	  model_v_in_main test loss : 0.877938
2021-12-27 23:35:07,950 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:35:07,952 |	  Step count: 418
2021-12-27 23:35:50,082 |	  loss_w (train):4.5067238829687994e-09
2021-12-27 23:35:58,942 |	  v_loss (train):27.716447830200195
2021-12-27 23:36:00,906 |	  model_w_in_main test loss : 0.838842
2021-12-27 23:36:01,436 |	  model_v_in_main test loss : 0.882897
2021-12-27 23:36:01,445 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:36:01,447 |	  Step count: 419
2021-12-27 23:37:06,925 |	  loss_w (train):9.744677953449354e-09
2021-12-27 23:37:22,996 |	  v_loss (train):114.25314331054688
2021-12-27 23:37:24,940 |	  model_w_in_main test loss : 0.838929
2021-12-27 23:37:25,237 |	  model_v_in_main test loss : 0.875475
2021-12-27 23:37:25,247 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:37:25,249 |	  Step count: 420
2021-12-27 23:38:05,865 |	  loss_w (train):2.646920549409515e-08
2021-12-27 23:38:15,240 |	  v_loss (train):0.04443071037530899
2021-12-27 23:38:17,243 |	  model_w_in_main test loss : 0.838959
2021-12-27 23:38:17,447 |	  model_v_in_main test loss : 0.878044
2021-12-27 23:38:17,513 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:38:17,515 |	  Step count: 421
2021-12-27 23:39:01,600 |	  loss_w (train):3.4416729022268555e-08
2021-12-27 23:39:13,717 |	  v_loss (train):46.55820083618164
2021-12-27 23:39:15,694 |	  model_w_in_main test loss : 0.838986
2021-12-27 23:39:16,261 |	  model_v_in_main test loss : 0.883356
2021-12-27 23:39:16,265 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:39:16,267 |	  Step count: 422
2021-12-27 23:39:48,478 |	  loss_w (train):5.109846323847478e-09
2021-12-27 23:39:54,127 |	  v_loss (train):39.76504898071289
2021-12-27 23:39:56,457 |	  model_w_in_main test loss : 0.838932
2021-12-27 23:39:56,692 |	  model_v_in_main test loss : 0.894726
2021-12-27 23:39:56,699 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:39:56,701 |	  Step count: 423
2021-12-27 23:40:26,878 |	  loss_w (train):2.1270674110951404e-08
2021-12-27 23:40:32,130 |	  v_loss (train):14.987483978271484
2021-12-27 23:40:34,140 |	  model_w_in_main test loss : 0.838867
2021-12-27 23:40:34,685 |	  model_v_in_main test loss : 0.891507
2021-12-27 23:40:34,691 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:40:34,694 |	  Step count: 424
2021-12-27 23:40:58,369 |	  loss_w (train):3.1890227347730615e-08
2021-12-27 23:41:01,896 |	  v_loss (train):0.042490940541028976
2021-12-27 23:41:03,979 |	  model_w_in_main test loss : 0.838901
2021-12-27 23:41:04,190 |	  model_v_in_main test loss : 0.884832
2021-12-27 23:41:04,201 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:41:04,203 |	  Step count: 425
2021-12-27 23:41:42,234 |	  loss_w (train):3.3460259007966897e-09
2021-12-27 23:41:48,528 |	  v_loss (train):24.31682777404785
2021-12-27 23:41:49,695 |	  model_w_in_main test loss : 0.838855
2021-12-27 23:41:49,757 |	  model_v_in_main test loss : 0.902001
2021-12-27 23:41:49,763 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:41:49,765 |	  Step count: 426
2021-12-27 23:43:00,677 |	  loss_w (train):2.7504103439213168e-09
2021-12-27 23:43:23,811 |	  v_loss (train):113.1124267578125
2021-12-27 23:43:25,173 |	  model_w_in_main test loss : 0.838893
2021-12-27 23:43:25,681 |	  model_v_in_main test loss : 0.918056
2021-12-27 23:43:25,689 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:43:25,691 |	  Step count: 427
2021-12-27 23:44:35,839 |	  loss_w (train):2.046438574154763e-10
2021-12-27 23:44:55,649 |	  v_loss (train):93.16578674316406
2021-12-27 23:44:57,537 |	  model_w_in_main test loss : 0.838915
2021-12-27 23:44:57,661 |	  model_v_in_main test loss : 0.932537
2021-12-27 23:44:57,678 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:44:57,679 |	  Step count: 428
2021-12-27 23:45:25,678 |	  loss_w (train):1.310556818623354e-08
2021-12-27 23:45:33,468 |	  v_loss (train):0.15005479753017426
2021-12-27 23:45:34,937 |	  model_w_in_main test loss : 0.838826
2021-12-27 23:45:35,497 |	  model_v_in_main test loss : 0.893023
2021-12-27 23:45:35,503 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:45:35,505 |	  Step count: 429
2021-12-27 23:46:44,951 |	  loss_w (train):3.976788232051831e-09
2021-12-27 23:46:59,549 |	  v_loss (train):33.9524040222168
2021-12-27 23:47:01,557 |	  model_w_in_main test loss : 0.838942
2021-12-27 23:47:02,078 |	  model_v_in_main test loss : 0.946673
2021-12-27 23:47:02,083 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:47:02,085 |	  Step count: 430
2021-12-27 23:47:53,150 |	  loss_w (train):8.223457470535322e-09
2021-12-27 23:48:08,170 |	  v_loss (train):112.06974792480469
2021-12-27 23:48:09,798 |	  model_w_in_main test loss : 0.838897
2021-12-27 23:48:10,340 |	  model_v_in_main test loss : 0.949520
2021-12-27 23:48:10,344 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:48:10,347 |	  Step count: 431
2021-12-27 23:49:36,972 |	  loss_w (train):3.79475153522435e-08
2021-12-27 23:50:00,600 |	  v_loss (train):122.8865737915039
2021-12-27 23:50:02,560 |	  model_w_in_main test loss : 0.838896
2021-12-27 23:50:02,924 |	  model_v_in_main test loss : 1.005868
2021-12-27 23:50:02,977 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:50:02,980 |	  Step count: 432
2021-12-27 23:50:25,347 |	  loss_w (train):1.7743428060157385e-08
2021-12-27 23:50:27,963 |	  v_loss (train):2.2105367183685303
2021-12-27 23:50:29,900 |	  model_w_in_main test loss : 0.838964
2021-12-27 23:50:30,444 |	  model_v_in_main test loss : 1.007997
2021-12-27 23:50:30,450 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:50:30,453 |	  Step count: 433
2021-12-27 23:51:01,702 |	  loss_w (train):5.402924774244866e-10
2021-12-27 23:51:06,034 |	  v_loss (train):9.80007553100586
2021-12-27 23:51:08,064 |	  model_w_in_main test loss : 0.838866
2021-12-27 23:51:08,635 |	  model_v_in_main test loss : 1.023571
2021-12-27 23:51:08,643 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:51:08,645 |	  Step count: 434
2021-12-27 23:52:02,180 |	  loss_w (train):1.4603731557372157e-09
2021-12-27 23:52:13,598 |	  v_loss (train):25.969205856323242
2021-12-27 23:52:16,080 |	  model_w_in_main test loss : 0.838920
2021-12-27 23:52:16,629 |	  model_v_in_main test loss : 0.983417
2021-12-27 23:52:16,636 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:52:16,639 |	  Step count: 435
2021-12-27 23:53:42,351 |	  loss_w (train):6.064137192396402e-09
2021-12-27 23:54:06,640 |	  v_loss (train):122.22586822509766
2021-12-27 23:54:08,641 |	  model_w_in_main test loss : 0.838897
2021-12-27 23:54:09,205 |	  model_v_in_main test loss : 0.968499
2021-12-27 23:54:09,213 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:54:09,215 |	  Step count: 436
2021-12-27 23:54:57,730 |	  loss_w (train):3.5161912270709195e-10
2021-12-27 23:55:06,851 |	  v_loss (train):18.85192108154297
2021-12-27 23:55:08,886 |	  model_w_in_main test loss : 0.838895
2021-12-27 23:55:09,432 |	  model_v_in_main test loss : 0.968074
2021-12-27 23:55:09,438 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:55:09,440 |	  Step count: 437
2021-12-27 23:55:36,709 |	  loss_w (train):5.117860024661525e-10
2021-12-27 23:55:41,177 |	  v_loss (train):8.54228401184082
2021-12-27 23:55:43,527 |	  model_w_in_main test loss : 0.838993
2021-12-27 23:55:43,665 |	  model_v_in_main test loss : 0.962835
2021-12-27 23:55:43,674 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:55:43,676 |	  Step count: 438
2021-12-27 23:56:17,690 |	  loss_w (train):1.9719342825297304e-10
2021-12-27 23:56:26,445 |	  v_loss (train):0.018044520169496536
2021-12-27 23:56:28,677 |	  model_w_in_main test loss : 0.838919
2021-12-27 23:56:28,985 |	  model_v_in_main test loss : 0.961801
2021-12-27 23:56:28,993 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:56:28,995 |	  Step count: 439
2021-12-27 23:57:03,415 |	  loss_w (train):9.439345305395364e-09
2021-12-27 23:57:11,686 |	  v_loss (train):30.739055633544922
2021-12-27 23:57:13,672 |	  model_w_in_main test loss : 0.838974
2021-12-27 23:57:13,778 |	  model_v_in_main test loss : 0.935278
2021-12-27 23:57:13,783 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:57:13,785 |	  Step count: 440
2021-12-27 23:57:52,520 |	  loss_w (train):1.4225696176595193e-08
2021-12-27 23:58:02,053 |	  v_loss (train):27.926448822021484
2021-12-27 23:58:04,428 |	  model_w_in_main test loss : 0.838941
2021-12-27 23:58:04,555 |	  model_v_in_main test loss : 0.941126
2021-12-27 23:58:04,560 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:58:04,562 |	  Step count: 441
2021-12-27 23:58:29,835 |	  loss_w (train):2.9314378480194137e-08
2021-12-27 23:58:33,550 |	  v_loss (train):5.760477066040039
2021-12-27 23:58:35,762 |	  model_w_in_main test loss : 0.839011
2021-12-27 23:58:36,151 |	  model_v_in_main test loss : 0.956522
2021-12-27 23:58:36,156 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:58:36,158 |	  Step count: 442
2021-12-27 23:59:06,081 |	  loss_w (train):1.2013384065312493e-08
2021-12-27 23:59:09,285 |	  v_loss (train):1.9962745904922485
2021-12-27 23:59:11,687 |	  model_w_in_main test loss : 0.838946
2021-12-27 23:59:11,826 |	  model_v_in_main test loss : 0.956108
2021-12-27 23:59:11,830 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-27 23:59:11,832 |	  Step count: 443
2021-12-28 00:00:04,405 |	  loss_w (train):5.06298380997805e-09
2021-12-28 00:00:17,231 |	  v_loss (train):57.7120361328125
2021-12-28 00:00:19,244 |	  model_w_in_main test loss : 0.838856
2021-12-28 00:00:19,797 |	  model_v_in_main test loss : 0.931527
2021-12-28 00:00:19,804 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:00:19,806 |	  Step count: 444
2021-12-28 00:01:02,575 |	  loss_w (train):4.627449534666539e-09
2021-12-28 00:01:11,508 |	  v_loss (train):14.374361038208008
2021-12-28 00:01:13,878 |	  model_w_in_main test loss : 0.838912
2021-12-28 00:01:14,011 |	  model_v_in_main test loss : 0.950737
2021-12-28 00:01:14,015 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:01:14,017 |	  Step count: 445
2021-12-28 00:01:35,057 |	  loss_w (train):2.9101471232806375e-10
2021-12-28 00:01:44,622 |	  v_loss (train):0.015545310452580452
2021-12-28 00:01:46,614 |	  model_w_in_main test loss : 0.838900
2021-12-28 00:01:46,951 |	  model_v_in_main test loss : 0.946262
2021-12-28 00:01:47,004 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:01:47,006 |	  Step count: 446
2021-12-28 00:02:30,757 |	  loss_w (train):2.0976548276152585e-10
2021-12-28 00:02:40,242 |	  v_loss (train):22.074932098388672
2021-12-28 00:02:42,108 |	  model_w_in_main test loss : 0.838907
2021-12-28 00:02:42,553 |	  model_v_in_main test loss : 0.953415
2021-12-28 00:02:42,608 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:02:42,611 |	  Step count: 447
2021-12-28 00:03:20,243 |	  loss_w (train):2.8919777683711345e-09
2021-12-28 00:03:29,007 |	  v_loss (train):0.006713380105793476
2021-12-28 00:03:31,008 |	  model_w_in_main test loss : 0.838852
2021-12-28 00:03:31,520 |	  model_v_in_main test loss : 0.953786
2021-12-28 00:03:31,526 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:03:31,528 |	  Step count: 448
2021-12-28 00:04:47,487 |	  loss_w (train):2.9044558758073435e-08
2021-12-28 00:05:07,106 |	  v_loss (train):146.65936279296875
2021-12-28 00:05:09,045 |	  model_w_in_main test loss : 0.838927
2021-12-28 00:05:09,605 |	  model_v_in_main test loss : 0.954084
2021-12-28 00:05:09,612 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:05:09,614 |	  Step count: 449
2021-12-28 00:06:34,622 |	  loss_w (train):1.4570751716291852e-08
2021-12-28 00:06:58,038 |	  v_loss (train):395.18389892578125
2021-12-28 00:06:59,967 |	  model_w_in_main test loss : 0.838899
2021-12-28 00:07:00,069 |	  model_v_in_main test loss : 0.970758
2021-12-28 00:07:00,073 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:07:00,074 |	  Step count: 450
2021-12-28 00:07:55,985 |	  loss_w (train):6.659599538494376e-09
2021-12-28 00:08:08,672 |	  v_loss (train):60.929412841796875
2021-12-28 00:08:10,793 |	  model_w_in_main test loss : 0.838935
2021-12-28 00:08:11,265 |	  model_v_in_main test loss : 0.964018
2021-12-28 00:08:11,269 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:08:11,270 |	  Step count: 451
2021-12-28 00:09:12,499 |	  loss_w (train):1.7682332043023052e-08
2021-12-28 00:09:24,174 |	  v_loss (train):62.69527053833008
2021-12-28 00:09:26,045 |	  model_w_in_main test loss : 0.838900
2021-12-28 00:09:26,149 |	  model_v_in_main test loss : 0.946364
2021-12-28 00:09:26,177 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:09:26,179 |	  Step count: 452
2021-12-28 00:10:40,180 |	  loss_w (train):9.153969249275917e-10
2021-12-28 00:10:58,427 |	  v_loss (train):165.60061645507812
2021-12-28 00:11:00,382 |	  model_w_in_main test loss : 0.838962
2021-12-28 00:11:00,894 |	  model_v_in_main test loss : 0.960995
2021-12-28 00:11:00,903 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:11:00,905 |	  Step count: 453
2021-12-28 00:12:08,993 |	  loss_w (train):3.241827639666184e-10
2021-12-28 00:12:24,228 |	  v_loss (train):86.9483413696289
2021-12-28 00:12:26,204 |	  model_w_in_main test loss : 0.838934
2021-12-28 00:12:26,762 |	  model_v_in_main test loss : 0.963765
2021-12-28 00:12:26,769 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:12:26,771 |	  Step count: 454
2021-12-28 00:12:50,201 |	  loss_w (train):1.1180842030000804e-08
2021-12-28 00:12:53,392 |	  v_loss (train):0.03118295967578888
2021-12-28 00:12:55,511 |	  model_w_in_main test loss : 0.838904
2021-12-28 00:12:55,955 |	  model_v_in_main test loss : 0.961137
2021-12-28 00:12:55,959 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:12:55,961 |	  Step count: 455
2021-12-28 00:13:38,293 |	  loss_w (train):3.069064558047785e-09
2021-12-28 00:13:46,813 |	  v_loss (train):10.124603271484375
2021-12-28 00:13:48,835 |	  model_w_in_main test loss : 0.838916
2021-12-28 00:13:49,331 |	  model_v_in_main test loss : 0.977902
2021-12-28 00:13:49,338 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:13:49,340 |	  Step count: 456
2021-12-28 00:14:52,894 |	  loss_w (train):1.267968574580891e-08
2021-12-28 00:15:07,644 |	  v_loss (train):76.32427215576172
2021-12-28 00:15:09,451 |	  model_w_in_main test loss : 0.838913
2021-12-28 00:15:09,997 |	  model_v_in_main test loss : 0.952480
2021-12-28 00:15:10,003 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:15:10,005 |	  Step count: 457
2021-12-28 00:15:58,409 |	  loss_w (train):2.4997759417999532e-09
2021-12-28 00:16:06,194 |	  v_loss (train):107.16461181640625
2021-12-28 00:16:08,075 |	  model_w_in_main test loss : 0.838921
2021-12-28 00:16:08,622 |	  model_v_in_main test loss : 0.954611
2021-12-28 00:16:08,629 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:16:08,631 |	  Step count: 458
2021-12-28 00:16:36,392 |	  loss_w (train):1.872419108650547e-09
2021-12-28 00:16:41,650 |	  v_loss (train):21.348690032958984
2021-12-28 00:16:43,496 |	  model_w_in_main test loss : 0.838849
2021-12-28 00:16:44,053 |	  model_v_in_main test loss : 0.979047
2021-12-28 00:16:44,060 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:16:44,062 |	  Step count: 459
2021-12-28 00:17:15,828 |	  loss_w (train):1.2200539245554864e-08
2021-12-28 00:17:22,235 |	  v_loss (train):0.014099400490522385
2021-12-28 00:17:24,192 |	  model_w_in_main test loss : 0.838902
2021-12-28 00:17:24,746 |	  model_v_in_main test loss : 0.981004
2021-12-28 00:17:24,751 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:17:24,752 |	  Step count: 460
2021-12-28 00:18:36,966 |	  loss_w (train):2.226325968024412e-08
2021-12-28 00:18:56,549 |	  v_loss (train):113.0304183959961
2021-12-28 00:18:58,446 |	  model_w_in_main test loss : 0.838912
2021-12-28 00:18:58,590 |	  model_v_in_main test loss : 0.995373
2021-12-28 00:18:58,604 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:18:58,606 |	  Step count: 461
2021-12-28 00:19:47,601 |	  loss_w (train):1.6092375432208428e-08
2021-12-28 00:19:58,007 |	  v_loss (train):41.46770477294922
2021-12-28 00:19:59,982 |	  model_w_in_main test loss : 0.838882
2021-12-28 00:20:00,539 |	  model_v_in_main test loss : 0.968836
2021-12-28 00:20:00,546 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:20:00,548 |	  Step count: 462
2021-12-28 00:21:00,145 |	  loss_w (train):3.5722838021001735e-09
2021-12-28 00:21:13,517 |	  v_loss (train):84.5342025756836
2021-12-28 00:21:15,484 |	  model_w_in_main test loss : 0.838944
2021-12-28 00:21:15,958 |	  model_v_in_main test loss : 0.945223
2021-12-28 00:21:15,962 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:21:15,964 |	  Step count: 463
2021-12-28 00:22:49,368 |	  loss_w (train):1.685723560740371e-08
2021-12-28 00:23:12,888 |	  v_loss (train):188.0609130859375
2021-12-28 00:23:14,916 |	  model_w_in_main test loss : 0.838922
2021-12-28 00:23:15,490 |	  model_v_in_main test loss : 0.952669
2021-12-28 00:23:15,495 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:23:15,497 |	  Step count: 464
2021-12-28 00:24:00,740 |	  loss_w (train):4.1429373709434e-08
2021-12-28 00:24:11,612 |	  v_loss (train):51.21377944946289
2021-12-28 00:24:13,551 |	  model_w_in_main test loss : 0.838910
2021-12-28 00:24:14,114 |	  model_v_in_main test loss : 0.931579
2021-12-28 00:24:14,118 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:24:14,120 |	  Step count: 465
2021-12-28 00:25:20,726 |	  loss_w (train):5.986905193822167e-09
2021-12-28 00:25:36,310 |	  v_loss (train):63.97401428222656
2021-12-28 00:25:38,665 |	  model_w_in_main test loss : 0.838878
2021-12-28 00:25:38,799 |	  model_v_in_main test loss : 0.954789
2021-12-28 00:25:38,805 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:25:38,807 |	  Step count: 466
2021-12-28 00:26:37,049 |	  loss_w (train):1.4100604017741603e-10
2021-12-28 00:26:50,903 |	  v_loss (train):55.70941162109375
2021-12-28 00:26:52,780 |	  model_w_in_main test loss : 0.838974
2021-12-28 00:26:52,899 |	  model_v_in_main test loss : 0.978556
2021-12-28 00:26:52,920 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:26:52,923 |	  Step count: 467
2021-12-28 00:27:56,020 |	  loss_w (train):1.2886355094110513e-08
2021-12-28 00:28:09,217 |	  v_loss (train):67.16219329833984
2021-12-28 00:28:11,333 |	  model_w_in_main test loss : 0.838895
2021-12-28 00:28:11,838 |	  model_v_in_main test loss : 0.973680
2021-12-28 00:28:11,843 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:28:11,845 |	  Step count: 468
2021-12-28 00:28:50,497 |	  loss_w (train):4.504215667111566e-09
2021-12-28 00:28:59,943 |	  v_loss (train):22.12656021118164
2021-12-28 00:29:02,372 |	  model_w_in_main test loss : 0.838905
2021-12-28 00:29:02,515 |	  model_v_in_main test loss : 1.020892
2021-12-28 00:29:02,521 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:29:02,523 |	  Step count: 469
2021-12-28 00:30:15,795 |	  loss_w (train):1.987457132202053e-08
2021-12-28 00:30:36,130 |	  v_loss (train):92.13068389892578
2021-12-28 00:30:38,487 |	  model_w_in_main test loss : 0.838931
2021-12-28 00:30:38,676 |	  model_v_in_main test loss : 1.033892
2021-12-28 00:30:38,693 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:30:38,695 |	  Step count: 470
2021-12-28 00:32:02,744 |	  loss_w (train):6.825546794431148e-10
2021-12-28 00:32:21,998 |	  v_loss (train):135.12261962890625
2021-12-28 00:32:23,917 |	  model_w_in_main test loss : 0.838935
2021-12-28 00:32:24,468 |	  model_v_in_main test loss : 0.985844
2021-12-28 00:32:24,475 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:32:24,477 |	  Step count: 471
2021-12-28 00:33:19,552 |	  loss_w (train):8.670122397802515e-09
2021-12-28 00:33:33,899 |	  v_loss (train):81.06423950195312
2021-12-28 00:33:35,934 |	  model_w_in_main test loss : 0.838926
2021-12-28 00:33:36,510 |	  model_v_in_main test loss : 0.977750
2021-12-28 00:33:36,516 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:33:36,518 |	  Step count: 472
2021-12-28 00:35:02,812 |	  loss_w (train):1.3187176683970847e-08
2021-12-28 00:35:28,662 |	  v_loss (train):121.82203674316406
2021-12-28 00:35:30,835 |	  model_w_in_main test loss : 0.838920
2021-12-28 00:35:30,962 |	  model_v_in_main test loss : 0.973852
2021-12-28 00:35:30,983 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:35:30,985 |	  Step count: 473
2021-12-28 00:36:26,670 |	  loss_w (train):1.5336737435589498e-09
2021-12-28 00:36:39,148 |	  v_loss (train):22.261140823364258
2021-12-28 00:36:41,415 |	  model_w_in_main test loss : 0.838931
2021-12-28 00:36:41,714 |	  model_v_in_main test loss : 0.982378
2021-12-28 00:36:41,722 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:36:41,724 |	  Step count: 474
2021-12-28 00:37:26,135 |	  loss_w (train):3.9701554044313525e-08
2021-12-28 00:37:36,830 |	  v_loss (train):40.17140197753906
2021-12-28 00:37:39,215 |	  model_w_in_main test loss : 0.838876
2021-12-28 00:37:39,338 |	  model_v_in_main test loss : 0.982039
2021-12-28 00:37:39,357 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:37:39,359 |	  Step count: 475
2021-12-28 00:38:20,858 |	  loss_w (train):2.417123390330289e-09
2021-12-28 00:38:28,422 |	  v_loss (train):26.972816467285156
2021-12-28 00:38:30,336 |	  model_w_in_main test loss : 0.838962
2021-12-28 00:38:30,548 |	  model_v_in_main test loss : 1.024442
2021-12-28 00:38:30,624 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:38:30,626 |	  Step count: 476
2021-12-28 00:39:14,711 |	  loss_w (train):4.9104386334875016e-08
2021-12-28 00:39:24,784 |	  v_loss (train):36.13969039916992
2021-12-28 00:39:27,185 |	  model_w_in_main test loss : 0.838932
2021-12-28 00:39:27,305 |	  model_v_in_main test loss : 1.023602
2021-12-28 00:39:27,310 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:39:27,312 |	  Step count: 477
2021-12-28 00:39:49,587 |	  loss_w (train):6.477430591900202e-09
2021-12-28 00:39:52,308 |	  v_loss (train):12.350627899169922
2021-12-28 00:39:54,066 |	  model_w_in_main test loss : 0.838968
2021-12-28 00:39:54,214 |	  model_v_in_main test loss : 1.018907
2021-12-28 00:39:54,225 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:39:54,227 |	  Step count: 478
2021-12-28 00:41:08,939 |	  loss_w (train):3.448679208872818e-08
2021-12-28 00:41:29,128 |	  v_loss (train):85.371337890625
2021-12-28 00:41:31,188 |	  model_w_in_main test loss : 0.838782
2021-12-28 00:41:31,712 |	  model_v_in_main test loss : 1.012742
2021-12-28 00:41:31,716 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:41:31,718 |	  Step count: 479
2021-12-28 00:42:00,514 |	  loss_w (train):5.896715116193718e-09
2021-12-28 00:42:05,641 |	  v_loss (train):10.544124603271484
2021-12-28 00:42:07,632 |	  model_w_in_main test loss : 0.838897
2021-12-28 00:42:07,744 |	  model_v_in_main test loss : 1.033935
2021-12-28 00:42:07,767 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:42:07,769 |	  Step count: 480
2021-12-28 00:42:42,046 |	  loss_w (train):1.7045227451717437e-08
2021-12-28 00:42:48,892 |	  v_loss (train):30.68259048461914
2021-12-28 00:42:50,494 |	  model_w_in_main test loss : 0.838908
2021-12-28 00:42:50,942 |	  model_v_in_main test loss : 1.020089
2021-12-28 00:42:50,947 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:42:50,949 |	  Step count: 481
2021-12-28 00:43:38,952 |	  loss_w (train):1.2539860816396242e-10
2021-12-28 00:43:50,412 |	  v_loss (train):20.82279396057129
2021-12-28 00:43:52,138 |	  model_w_in_main test loss : 0.838910
2021-12-28 00:43:52,700 |	  model_v_in_main test loss : 1.013307
2021-12-28 00:43:52,705 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:43:52,707 |	  Step count: 482
2021-12-28 00:44:41,101 |	  loss_w (train):1.2386303538391985e-08
2021-12-28 00:44:52,442 |	  v_loss (train):33.021156311035156
2021-12-28 00:44:54,529 |	  model_w_in_main test loss : 0.838863
2021-12-28 00:44:55,002 |	  model_v_in_main test loss : 1.023198
2021-12-28 00:44:55,006 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:44:55,008 |	  Step count: 483
2021-12-28 00:45:28,065 |	  loss_w (train):2.867032264930458e-07
2021-12-28 00:45:34,358 |	  v_loss (train):33.1276741027832
2021-12-28 00:45:36,341 |	  model_w_in_main test loss : 0.838894
2021-12-28 00:45:36,908 |	  model_v_in_main test loss : 1.030481
2021-12-28 00:45:36,914 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:45:36,916 |	  Step count: 484
2021-12-28 00:46:14,538 |	  loss_w (train):3.053006025766081e-08
2021-12-28 00:46:22,014 |	  v_loss (train):18.982229232788086
2021-12-28 00:46:24,102 |	  model_w_in_main test loss : 0.838807
2021-12-28 00:46:24,567 |	  model_v_in_main test loss : 0.999392
2021-12-28 00:46:24,572 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:46:24,574 |	  Step count: 485
2021-12-28 00:46:58,932 |	  loss_w (train):3.939095805094439e-08
2021-12-28 00:47:07,932 |	  v_loss (train):25.100120544433594
2021-12-28 00:47:09,305 |	  model_w_in_main test loss : 0.838859
2021-12-28 00:47:09,840 |	  model_v_in_main test loss : 1.023175
2021-12-28 00:47:09,846 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:47:09,848 |	  Step count: 486
2021-12-28 00:48:17,619 |	  loss_w (train):6.865225721242041e-09
2021-12-28 00:48:34,715 |	  v_loss (train):85.35519409179688
2021-12-28 00:48:36,696 |	  model_w_in_main test loss : 0.838887
2021-12-28 00:48:37,246 |	  model_v_in_main test loss : 1.019238
2021-12-28 00:48:37,250 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:48:37,252 |	  Step count: 487
2021-12-28 00:49:45,594 |	  loss_w (train):7.997173590013062e-09
2021-12-28 00:50:07,080 |	  v_loss (train):157.77511596679688
2021-12-28 00:50:09,028 |	  model_w_in_main test loss : 0.838896
2021-12-28 00:50:09,586 |	  model_v_in_main test loss : 0.988193
2021-12-28 00:50:09,592 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:50:09,594 |	  Step count: 488
2021-12-28 00:51:06,273 |	  loss_w (train):8.192279743468589e-09
2021-12-28 00:51:15,500 |	  v_loss (train):96.49429321289062
2021-12-28 00:51:17,481 |	  model_w_in_main test loss : 0.838941
2021-12-28 00:51:17,676 |	  model_v_in_main test loss : 0.971924
2021-12-28 00:51:17,689 |	  ('Attention Weights A : ', Parameter containing:
tensor([ 0.8925, -0.5895,  0.8925,  ...,  0.8925,  0.8925,  0.8925],
       device='cuda:0', requires_grad=True))
2021-12-28 00:51:17,691 |	  Step count: 489
