{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer\n",
    "from MT_hyperparams import *\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/25 05:15:37 PM |\t  Reusing dataset opus_euconst (/home/li/.cache/huggingface/datasets/opus_euconst/en-fr/1.0.0/d1e611a011f28fdda67a97024820e0a3813b4e4decca194d9a20b3207a39b908)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946756e7c6d94f6485681575c6d1d3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/25 05:15:37 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 10104\n",
      "    })\n",
      "})\n",
      "12/25 05:15:37 PM |\t  {'translation': {'en': 'CONSIDERING that Article IV-437(2)(e) of the Constitution provides that the Treaty of 16 April 2003 concerning the accessions referred to above shall be repealed;  ', 'fr': \"CONSIDÉRANT que l'article\\xa0IV-437, paragraphe\\xa02, point\\xa0e), de la Constitution prévoit l'abrogation du traité du 16\\xa0avril 2003 relatif aux adhésions visées ci-dessus;  \"}}\n"
     ]
    }
   ],
   "source": [
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('opus_euconst','en-fr')\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(0)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/25 05:15:39 PM |\t  Loading cached shuffled indices for dataset at /home/li/.cache/huggingface/datasets/opus_euconst/en-fr/1.0.0/d1e611a011f28fdda67a97024820e0a3813b4e4decca194d9a20b3207a39b908/cache-774986f0005795ce.arrow\n",
      "12/25 05:15:40 PM |\t  train len: 7578\n",
      "12/25 05:15:40 PM |\t  valid len: 1263\n",
      "12/25 05:15:40 PM |\t  test len: 1263\n",
      "12/25 05:15:40 PM |\t  {'en': 'translate English to French:, on the basis of Article\\xa02, and shall report thereon at least once a year.  ', 'fr': \"L'Agence européenne de défense contribue à l'évaluation régulière des contributions des États membres participants en matière de capacités, en particulier des contributions fournies suivant les critères qui seront établis, entre autres, sur la base de l'article\\xa02, et en fait rapport au moins une fois par an.  \"}\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer.\n",
    "import random\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id, reduction='none')\n",
    "L = len(dataset['train'])\n",
    "L_t = L//4*3\n",
    "L_v = L//8\n",
    "L_test = L//8\n",
    "dataset = dataset.shuffle(seed=seed_)\n",
    "\n",
    "\n",
    "train = dataset['train']['translation'][:L_t]\n",
    "valid = dataset['train']['translation'][L_t:L_t+L_v]\n",
    "test = dataset['train']['translation'][-L_test:]\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = 'translate English to French:' + t['en']\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), \n",
    "                        batch_size=2, pin_memory=True, num_workers=0)\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=RandomSampler(valid_data), \n",
    "                        batch_size=2, pin_memory=True, num_workers=0)\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, \n",
    "                        batch_size=5, pin_memory=True, num_workers=0)#, sampler=RandomSampler(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(len(train))\n",
    "A = A.cuda()\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.SGD(model_w.parameters(),w_lr,momentum=momentum,weight_decay=decay)\n",
    "scheduler_w  = torch.optim.lr_scheduler.CosineAnnealingLR(w_optimizer, float(epochs), eta_min=learning_rate_min)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion, tokenizer= tokenizer, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.SGD(model_v.parameters(),v_lr,momentum=momentum,weight_decay=decay)\n",
    "scheduler_v  = torch.optim.lr_scheduler.CosineAnnealingLR(v_optimizer, float(epochs), eta_min=learning_rate_min)\n",
    "\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> mon nom est kevin</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
       " \"<pad> c'est mon nomci est ma dénomination 321312</s>\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['my name is kevin','it is my nameit is my nameit is my name 321312']\n",
    "for index,i in enumerate(x) :\n",
    "    x[index] = 'translate English to French:' + x[index]\n",
    "y= tokenize(x, tokenizer, max_length = summary_length)\n",
    "input = y[0].cuda()\n",
    "output  = model_v.generate(input)\n",
    "tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_test(test_dataloader,model):\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        model.eval()\n",
    "        x = Variable(batch[0], requires_grad=False).cuda()\n",
    "        x_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        y = Variable(batch[2], requires_grad=False).cuda()\n",
    "        y_attn = Variable(batch[3], requires_grad=False).cuda()\n",
    "\n",
    "        ls = my_loss(x,x_attn,y,y_attn,model)\n",
    "        logging.info('%s test loss : %f',model.name,ls)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, train_dataloader, valid_dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, ):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        logging.info(\"Step count: %d\",step)\n",
    "        \n",
    "        batch_loss_w, batch_loss_v,  batch_count = 0, 0, 0\n",
    "        input_w = Variable(batch[0], requires_grad=False).cuda()\n",
    "        input_w_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        output_w = Variable(batch[2], requires_grad=False).cuda()\n",
    "        output_w_attn = Variable(batch[3], requires_grad=False).cuda()        \n",
    "        input_v = Variable(batch[4], requires_grad=False).cuda()\n",
    "        input_v_attn = Variable(batch[5], requires_grad=False).cuda()      \n",
    "        attn_idx = Variable(batch[6], requires_grad=False).cuda()\n",
    "        \n",
    "        valid_batch = next(iter(valid_dataloader))\n",
    "        valid_input_v      = Variable(valid_batch[0], requires_grad=False).cuda()\n",
    "        valid_input_v_attn = Variable(valid_batch[1], requires_grad=False).cuda()\n",
    "        valid_out_v      = Variable(valid_batch[2], requires_grad=False).cuda()\n",
    "        valid_out_v_attn = Variable(valid_batch[3], requires_grad=False).cuda()\n",
    "        \n",
    "\n",
    "        if epoch <= stop_epoch:\n",
    "            architect.step(input_w,  output_w,input_w_attn, output_w_attn, w_optimizer, input_v, input_v_attn,valid_input_v, valid_input_v_attn, valid_out_v, \n",
    "                valid_out_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\n",
    "\n",
    "        if epoch <=stop_epoch:\n",
    "            \n",
    "            w_optimizer.zero_grad()\n",
    "            loss_w = CTG_loss(input_w, input_w_attn, output_w, output_w_attn, attn_idx, A, w_model)\n",
    "            logging.info(f\"loss_w (train):{loss_w}\")\n",
    "            batch_loss_w += loss_w.item()\n",
    "            loss_w.backward()\n",
    "            nn.utils.clip_grad_norm(w_model.parameters(), grad_clip)\n",
    "            w_optimizer.step()\n",
    "\n",
    "\n",
    "            v_optimizer.zero_grad()\n",
    "            loss_aug = calc_loss_aug(input_v, input_v_attn, w_model, v_model)\n",
    "            v_loss =  (loss_aug)\n",
    "            logging.info(f\"v_loss (train):{v_loss}\")\n",
    "            batch_loss_v += v_loss.item()\n",
    "            v_loss.backward()\n",
    "            nn.utils.clip_grad_norm(v_model.parameters(), grad_clip)\n",
    "            v_optimizer.step()     \n",
    "            \n",
    "            my_test(test_dataloader,w_model) \n",
    "            my_test(test_dataloader,v_model)      \n",
    "        if step % 1  == 0:\n",
    "            logging.info(str((\"Attention Weights A : \", A.alpha)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/25 05:15:56 PM |\t  Step count: 0\n",
      "12/25 05:16:14 PM |\t  loss_w (train):3.4845939808292314e-05\n",
      "12/25 05:16:17 PM |\t  v_loss (train):333.8587341308594\n",
      "12/25 05:16:18 PM |\t  model_w_in_main test loss : 0.837824\n",
      "12/25 05:16:18 PM |\t  model_v_in_main test loss : 0.831462\n",
      "12/25 05:16:18 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0099, -0.0099, -0.0099,  ..., -0.0099, -0.0099, -0.0099],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:16:18 PM |\t  Step count: 1\n",
      "12/25 05:16:27 PM |\t  loss_w (train):6.766241131117567e-05\n",
      "12/25 05:16:29 PM |\t  v_loss (train):111.9421157836914\n",
      "12/25 05:16:29 PM |\t  model_w_in_main test loss : 0.837778\n",
      "12/25 05:16:29 PM |\t  model_v_in_main test loss : 0.868355\n",
      "12/25 05:16:29 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0182, -0.0182, -0.0182,  ..., -0.0182, -0.0182, -0.0182],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:16:29 PM |\t  Step count: 2\n",
      "12/25 05:16:46 PM |\t  loss_w (train):1.554307709739078e-05\n",
      "12/25 05:16:49 PM |\t  v_loss (train):263.779052734375\n",
      "12/25 05:16:49 PM |\t  model_w_in_main test loss : 0.837844\n",
      "12/25 05:16:49 PM |\t  model_v_in_main test loss : 0.852040\n",
      "12/25 05:16:49 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0227, -0.0227, -0.0227,  ..., -0.0227, -0.0227, -0.0227],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:16:49 PM |\t  Step count: 3\n",
      "12/25 05:16:59 PM |\t  loss_w (train):1.6379937733290717e-05\n",
      "12/25 05:17:00 PM |\t  v_loss (train):90.01312255859375\n",
      "12/25 05:17:00 PM |\t  model_w_in_main test loss : 0.837775\n",
      "12/25 05:17:00 PM |\t  model_v_in_main test loss : 0.853961\n",
      "12/25 05:17:00 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0257, -0.0257, -0.0257,  ..., -0.0257, -0.0257, -0.0257],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:17:00 PM |\t  Step count: 4\n",
      "12/25 05:17:11 PM |\t  loss_w (train):2.1330436084099347e-06\n",
      "12/25 05:17:11 PM |\t  v_loss (train):107.91200256347656\n",
      "12/25 05:17:11 PM |\t  model_w_in_main test loss : 0.837734\n",
      "12/25 05:17:12 PM |\t  model_v_in_main test loss : 0.878200\n",
      "12/25 05:17:12 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0247, -0.0247, -0.0247,  ..., -0.0247, -0.0247, -0.0247],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:17:12 PM |\t  Step count: 5\n",
      "12/25 05:17:23 PM |\t  loss_w (train):7.858308526920155e-05\n",
      "12/25 05:17:24 PM |\t  v_loss (train):158.43104553222656\n",
      "12/25 05:17:24 PM |\t  model_w_in_main test loss : 0.837713\n",
      "12/25 05:17:24 PM |\t  model_v_in_main test loss : 0.876339\n",
      "12/25 05:17:24 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0259, -0.0259, -0.0259,  ..., -0.0259, -0.0259, -0.0259],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:17:24 PM |\t  Step count: 6\n",
      "12/25 05:17:34 PM |\t  loss_w (train):8.64094981807284e-05\n",
      "12/25 05:17:34 PM |\t  v_loss (train):82.34506225585938\n",
      "12/25 05:17:34 PM |\t  model_w_in_main test loss : 0.837737\n",
      "12/25 05:17:34 PM |\t  model_v_in_main test loss : 0.880960\n",
      "12/25 05:17:34 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0262, -0.0262, -0.0262,  ..., -0.0262, -0.0262, -0.0262],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:17:34 PM |\t  Step count: 7\n",
      "12/25 05:17:45 PM |\t  loss_w (train):4.451858785614604e-06\n",
      "12/25 05:17:46 PM |\t  v_loss (train):143.1834259033203\n",
      "12/25 05:17:46 PM |\t  model_w_in_main test loss : 0.837820\n",
      "12/25 05:17:46 PM |\t  model_v_in_main test loss : 0.887228\n",
      "12/25 05:17:46 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0264, -0.0264, -0.0264,  ..., -0.0264, -0.0264, -0.0264],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:17:46 PM |\t  Step count: 8\n",
      "12/25 05:17:56 PM |\t  loss_w (train):2.421941280772444e-05\n",
      "12/25 05:17:56 PM |\t  v_loss (train):76.80359649658203\n",
      "12/25 05:17:57 PM |\t  model_w_in_main test loss : 0.837707\n",
      "12/25 05:17:57 PM |\t  model_v_in_main test loss : 0.871066\n",
      "12/25 05:17:57 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0135, -0.0135, -0.0135,  ..., -0.0135, -0.0135, -0.0135],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:17:57 PM |\t  Step count: 9\n",
      "12/25 05:18:14 PM |\t  loss_w (train):8.365855137526523e-06\n",
      "12/25 05:18:17 PM |\t  v_loss (train):198.57867431640625\n",
      "12/25 05:18:17 PM |\t  model_w_in_main test loss : 0.837758\n",
      "12/25 05:18:17 PM |\t  model_v_in_main test loss : 0.880966\n",
      "12/25 05:18:17 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0065, -0.0065, -0.0065,  ..., -0.0065, -0.0065, -0.0065],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:18:17 PM |\t  Step count: 10\n",
      "12/25 05:18:27 PM |\t  loss_w (train):3.635210305219516e-05\n",
      "12/25 05:18:27 PM |\t  v_loss (train):103.07505798339844\n",
      "12/25 05:18:28 PM |\t  model_w_in_main test loss : 0.837781\n",
      "12/25 05:18:28 PM |\t  model_v_in_main test loss : 0.901313\n",
      "12/25 05:18:28 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0039, -0.0039, -0.0039,  ..., -0.0039, -0.0039, -0.0039],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:18:28 PM |\t  Step count: 11\n",
      "12/25 05:18:41 PM |\t  loss_w (train):1.7604561435291544e-05\n",
      "12/25 05:18:43 PM |\t  v_loss (train):205.65298461914062\n",
      "12/25 05:18:43 PM |\t  model_w_in_main test loss : 0.837805\n",
      "12/25 05:18:43 PM |\t  model_v_in_main test loss : 0.910425\n",
      "12/25 05:18:43 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0022, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0022],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:18:43 PM |\t  Step count: 12\n",
      "12/25 05:18:55 PM |\t  loss_w (train):1.0456403288117144e-05\n",
      "12/25 05:18:57 PM |\t  v_loss (train):153.5947265625\n",
      "12/25 05:18:57 PM |\t  model_w_in_main test loss : 0.837647\n",
      "12/25 05:18:57 PM |\t  model_v_in_main test loss : 0.903791\n",
      "12/25 05:18:57 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:18:57 PM |\t  Step count: 13\n",
      "12/25 05:19:13 PM |\t  loss_w (train):0.00010887128883041441\n",
      "12/25 05:19:16 PM |\t  v_loss (train):195.16326904296875\n",
      "12/25 05:19:16 PM |\t  model_w_in_main test loss : 0.837806\n",
      "12/25 05:19:16 PM |\t  model_v_in_main test loss : 0.895039\n",
      "12/25 05:19:16 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:19:16 PM |\t  Step count: 14\n",
      "12/25 05:19:26 PM |\t  loss_w (train):1.320046249020379e-05\n",
      "12/25 05:19:27 PM |\t  v_loss (train):68.32789611816406\n",
      "12/25 05:19:27 PM |\t  model_w_in_main test loss : 0.837695\n",
      "12/25 05:19:27 PM |\t  model_v_in_main test loss : 0.912959\n",
      "12/25 05:19:27 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:19:27 PM |\t  Step count: 15\n",
      "12/25 05:19:38 PM |\t  loss_w (train):5.452481218526373e-06\n",
      "12/25 05:19:39 PM |\t  v_loss (train):61.9101676940918\n",
      "12/25 05:19:39 PM |\t  model_w_in_main test loss : 0.837778\n",
      "12/25 05:19:40 PM |\t  model_v_in_main test loss : 0.950460\n",
      "12/25 05:19:40 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:19:40 PM |\t  Step count: 16\n",
      "12/25 05:19:50 PM |\t  loss_w (train):3.573971116566099e-05\n",
      "12/25 05:19:51 PM |\t  v_loss (train):107.85946655273438\n",
      "12/25 05:19:51 PM |\t  model_w_in_main test loss : 0.837789\n",
      "12/25 05:19:51 PM |\t  model_v_in_main test loss : 0.944061\n",
      "12/25 05:19:51 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0017, -0.0017, -0.0017,  ..., -0.0017, -0.0017, -0.0017],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:19:51 PM |\t  Step count: 17\n",
      "12/25 05:20:05 PM |\t  loss_w (train):4.6973482312751e-06\n",
      "12/25 05:20:06 PM |\t  v_loss (train):180.8990478515625\n",
      "12/25 05:20:07 PM |\t  model_w_in_main test loss : 0.837776\n",
      "12/25 05:20:07 PM |\t  model_v_in_main test loss : 0.912931\n",
      "12/25 05:20:07 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:20:07 PM |\t  Step count: 18\n",
      "12/25 05:20:20 PM |\t  loss_w (train):2.2036351765564177e-06\n",
      "12/25 05:20:22 PM |\t  v_loss (train):92.52146911621094\n",
      "12/25 05:20:22 PM |\t  model_w_in_main test loss : 0.837776\n",
      "12/25 05:20:22 PM |\t  model_v_in_main test loss : 0.939659\n",
      "12/25 05:20:22 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([-0.0022, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0022],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "12/25 05:20:22 PM |\t  Step count: 19\n",
      "12/25 05:20:35 PM |\t  loss_w (train):1.5511142919422127e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_233129/143646209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_233129/181100835.py\u001b[0m in \u001b[0;36mmy_train\u001b[0;34m(epoch, train_dataloader, valid_dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mv_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_v_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mv_loss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mloss_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"v_loss (train):{v_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Tianyi/Self-teaching-for-machine-translation/1.0/losses.py\u001b[0m in \u001b[0;36mcalc_loss_aug\u001b[0;34m(input_ids, input_attn, w_model, v_model)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_loss_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mw_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mw_soft_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Tianyi/Self-teaching-for-machine-translation/1.0/T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# print(\"start of : generate\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_repeat_ngram_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m## sampling with top_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m             )\n\u001b[1;32m   1169\u001b[0m             \u001b[0;31m# 12. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1171\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1905\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1907\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   1908\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 )\n\u001b[1;32m   1008\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1010\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tianyi/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_train(begin_epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, w_lr,v_lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([0,  6206,  6667,    27,     1])\n",
    "tokenizer.decode([13959,  1566,    12,  2379,    10, 17608,   994,    27,     1,     0])\n",
    "logging.info(\"vocab size : %d\",model_v.vocab_size)\n",
    "logit = torch.load('logits.pt')\n",
    "target = torch.load('target_ids.pt')\n",
    "tokenizer.decode(target[0])\n",
    "logit.shape\n",
    "_,maxx = torch.max(logit,dim=-1,keepdim=True)\n",
    "maxx.shape\n",
    "tokenizer.decode(maxx[0].squeeze(-1))\n",
    "\n",
    "model_v.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
