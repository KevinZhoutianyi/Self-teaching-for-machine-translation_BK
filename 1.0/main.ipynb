{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reload each module run each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from T5 import *\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer\n",
    "from MT_hyperparams import *\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset opus_euconst (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\opus_euconst\\en-fr\\1.0.0\\d1e611a011f28fdda67a97024820e0a3813b4e4decca194d9a20b3207a39b908)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1003.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 10104\n",
      "    })\n",
      "})\n",
      "{'translation': {'en': 'CONSIDERING that Article IV-437(2)(e) of the Constitution provides that the Treaty of 16 April 2003 concerning the accessions referred to above shall be repealed;  ', 'fr': \"CONSIDÉRANT que l'article\\xa0IV-437, paragraphe\\xa02, point\\xa0e), de la Constitution prévoit l'abrogation du traité du 16\\xa0avril 2003 relatif aux adhésions visées ci-dessus;  \"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('opus_euconst','en-fr')\n",
    "print(dataset)\n",
    "print(dataset['train'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(0)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\opus_euconst\\en-fr\\1.0.0\\d1e611a011f28fdda67a97024820e0a3813b4e4decca194d9a20b3207a39b908\\cache-4efe7f3f95304f48.arrow\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer.\n",
    "import random\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id, reduction='none')\n",
    "L = len(dataset['train'])\n",
    "L_t = L//4*3\n",
    "L_v = L//8\n",
    "L_test = L//8\n",
    "dataset = dataset.shuffle(seed=seed_)\n",
    "\n",
    "\n",
    "\n",
    "train = dataset['train']['translation'][:L_t]\n",
    "valid = dataset['train']['translation'][L_t:L_t+L_v]\n",
    "test = dataset['train']['translation'][-L_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = 'translate English to French:' + t['en']\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 7578\n",
      "valid len: 1263\n",
      "test len: 1263\n",
      "{'en': 'translate English to French:, on the basis of Article\\xa02, and shall report thereon at least once a year.  ', 'fr': \"L'Agence européenne de défense contribue à l'évaluation régulière des contributions des États membres participants en matière de capacités, en particulier des contributions fournies suivant les critères qui seront établis, entre autres, sur la base de l'article\\xa02, et en fait rapport au moins une fois par an.  \"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"train len:\",len(train))\n",
    "print(\"valid len:\",len(valid))\n",
    "print(\"test len:\" ,len(test))\n",
    "print(train[5])\n",
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,    1,    2,  ..., 3786, 3787, 3788])\n",
      "Input shape: \n",
      "torch.Size([3789, 214]) torch.Size([3789, 214])\n",
      "Target shape: \n",
      "torch.Size([3789, 100]) torch.Size([3789, 100])\n",
      "Input shape: \n",
      "torch.Size([3789, 407]) torch.Size([3789, 407])\n"
     ]
    }
   ],
   "source": [
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), \n",
    "                        batch_size=2, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the attention parameters\n",
    "A = attention_params(len(train))\n",
    "# attention_weights.load_state_dict(torch.load(os.path.join(args.save, 'A.pt')))\n",
    "A = A.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: \n",
      "torch.Size([1263, 178]) torch.Size([1263, 178])\n",
      "Target shape: \n",
      "torch.Size([1263, 100]) torch.Size([1263, 100])\n"
     ]
    }
   ],
   "source": [
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=RandomSampler(valid_data), \n",
    "                        batch_size=2, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: \n",
      "torch.Size([1263, 232]) torch.Size([1263, 232])\n",
      "Target shape: \n",
      "torch.Size([1263, 100]) torch.Size([1263, 100])\n"
     ]
    }
   ],
   "source": [
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, \n",
    "                        batch_size=5, pin_memory=True, num_workers=0)#, sampler=RandomSampler(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from MT_hyperparams import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w = T5(criterion=criterion, tokenizer= tokenizer)\n",
    "# model.load_state_dict(torch.load(os.path.join(args.save, 'gpt_weights.pt')))\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.SGD(model_w.parameters(),lr,momentum=momentum,weight_decay=decay)\n",
    "scheduler_w  = torch.optim.lr_scheduler.CosineAnnealingLR(w_optimizer, float(epochs), eta_min=learning_rate_min)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v = T5(criterion=criterion, tokenizer= tokenizer)\n",
    "# model.load_state_dict(torch.load(os.path.join(args.save, 'gpt_weights.pt')))\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.SGD(model_v.parameters(),lr,momentum=momentum,weight_decay=decay)\n",
    "scheduler_v  = torch.optim.lr_scheduler.CosineAnnealingLR(v_optimizer, float(epochs), eta_min=learning_rate_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of : generate\n",
      "end of : generate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<pad> mon nom est kevin</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>',\n",
       " \"<pad> c'est mon nomci est ma dénomination 321312</s>\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['my name is kevin','it is my nameit is my nameit is my name 321312']\n",
    "for index,i in enumerate(x) :\n",
    "    x[index] = 'translate English to French:' + x[index]\n",
    "y= tokenize(x, tokenizer, max_length = summary_length)\n",
    "input = y[0].cuda()\n",
    "output  = model_v.generate(input)\n",
    "tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_test(test_dataloader,model):\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        x = Variable(batch[0], requires_grad=False).cuda()\n",
    "        x_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        y = Variable(batch[2], requires_grad=False).cuda()\n",
    "        y_attn = Variable(batch[3], requires_grad=False).cuda()\n",
    "\n",
    "        ls = my_loss(x,x_attn,y,y_attn,model)\n",
    "        print('\\n test loss :',ls)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, train_dataloader, valid_dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, ):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # for index,t in enumerate(batch):\n",
    "        #     print(\"Training data \",index,\"'s shape \",t.shape,end=' ')\n",
    "        batch_loss_w, batch_loss_v,  batch_count = 0, 0, 0\n",
    "        input_w = Variable(batch[0], requires_grad=False).cuda()\n",
    "        input_w_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        output_w = Variable(batch[2], requires_grad=False).cuda()\n",
    "        output_w_attn = Variable(batch[3], requires_grad=False).cuda()        \n",
    "        input_v = Variable(batch[4], requires_grad=False).cuda()\n",
    "        input_v_attn = Variable(batch[5], requires_grad=False).cuda()        \n",
    "        # attention indices for CTG loss\n",
    "        attn_idx = Variable(batch[6], requires_grad=False).cuda()\n",
    "        \n",
    "        #####################################################################################\n",
    "        # valid \n",
    "\n",
    "        # valid input_valid, target_valid, valid_attn_classifier\n",
    "        \n",
    "        # get a random minibatch from the search queue with replacement\n",
    "        valid_batch = next(iter(valid_dataloader))\n",
    "\n",
    "        valid_input_v      = Variable(valid_batch[0], requires_grad=False).cuda()\n",
    "        valid_input_v_attn = Variable(valid_batch[1], requires_grad=False).cuda()\n",
    "        valid_out_v      = Variable(valid_batch[2], requires_grad=False).cuda()\n",
    "        valid_out_v_attn = Variable(valid_batch[3], requires_grad=False).cuda()\n",
    "\n",
    "\n",
    "        if begin_epoch <= epoch <= stop_epoch:\n",
    "            \n",
    "            architect.step(input_w,  output_w,input_w_attn, output_w_attn, w_optimizer, input_v, input_v_attn,valid_input_v, valid_input_v_attn, valid_out_v, \n",
    "                valid_out_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\n",
    "        # end the framework training and just train on the classifier task after the stop epoch\n",
    "        if epoch <=stop_epoch:\n",
    "            ######################################################################\n",
    "            # Update the W model\n",
    "            w_optimizer.zero_grad()\n",
    "            \n",
    "\n",
    "            # W\n",
    "            loss_w = CTG_loss(input_w, input_w_attn, output_w, output_w_attn, attn_idx, A, w_model)\n",
    "            # store the batch loss\n",
    "            batch_loss_w += loss_w.item()\n",
    "\n",
    "            loss_w.backward()\n",
    "            \n",
    "            nn.utils.clip_grad_norm(w_model.parameters(), grad_clip)\n",
    "            \n",
    "            w_optimizer.step()\n",
    "            # print(w_optimizer)\n",
    "            \n",
    "            ######################################################################\n",
    "            # Update the V model\n",
    "            v_optimizer.zero_grad()\n",
    "        \n",
    "            # the training loss\n",
    "            # logits, loss_tr = w_model.loss(article_DS, article_DS_attn, summary_DS, summary_DS_attn)\n",
    "\n",
    "            # Loss on augmented dataset\n",
    "            \n",
    "            loss_aug = calc_loss_aug(input_v, input_v_attn, w_model, v_model)\n",
    "        \n",
    "            v_loss =  (loss_aug)\n",
    "            batch_loss_v += v_loss.item()\n",
    "            \n",
    "            v_loss.backward()\n",
    "            \n",
    "            nn.utils.clip_grad_norm(v_model.parameters(), grad_clip)\n",
    "            \n",
    "            # update the classifier model\n",
    "            v_optimizer.step()     \n",
    "            \n",
    "            my_test(test_dataloader,w_model) \n",
    "            my_test(test_dataloader,v_model)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "architect = Architect(model_w, model_v,  A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [[13959,  1566,    12,  2379,    10, 17608,   994,    27,     1,     0],[13959,  1566,    12,  2379,    10, 17608,   994,    27,     1,     0]]\n",
    "# aa = torch.LongTensor(a)\n",
    "# aa.long()\n",
    "# b=torch.zeros(aa.shape[0],aa.shape[1],32128)\n",
    "# c = b.scatter_(-1,aa.unsqueeze(-1), 1.).float().cuda()\n",
    "# model_v(c,torch.ones_like(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of : get_loss_vec\n",
      "start of forward\n",
      "T5 inputshape: torch.Size([2, 214, 768]) torch.Size([2, 214])\n",
      "end of forward\n",
      "end of : get_loss_vec\n",
      "input_ids torch.Size([2, 407])\n",
      "start of : generate\n",
      "end of : generate\n",
      "output_ids torch.Size([2, 110])\n",
      "start of forward\n",
      "T5 inputshape: torch.Size([2, 407, 768]) torch.Size([2, 407])\n",
      "end of forward\n",
      "w_logits torch.Size([2, 110, 32128])\n",
      "w_soft_idx torch.Size([2, 110, 1])\n",
      "one_hot torch.Size([2, 407, 32100])\n",
      "w_output_ids torch.Size([2, 407, 32100])\n",
      "start of forward\n",
      "embedding shape torch.Size([32100, 768])\n",
      "T5 inputshape: torch.Size([2, 407, 768]) torch.Size([2, 407])\n",
      "end of forward\n",
      "logits torch.Size([814, 32128]) tar torch.Size([814])\n",
      "T5 loss torch.Size([814])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 852.00 MiB (GPU 0; 12.00 GiB total capacity; 8.96 GiB already allocated; 0 bytes free; 10.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33508/2628594002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33508/2439249332.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, train_dataloader, valid_dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbegin_epoch\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mstop_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             architect.step(input_w,  output_w,input_w_attn, output_w_attn, w_optimizer, input_v, input_v_attn,valid_input_v, valid_input_v_attn, valid_out_v, \n\u001b[0m\u001b[0;32m     32\u001b[0m                 valid_out_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# end the framework training and just train on the classifier task after the stop epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\OneDrive\\桌面\\paper\\mycode\\1.0\\architect.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, w_input, w_target, w_input_attn, w_target_attn, w_optimizer, v_input, v_input_attn, valid_input_v, valid_input_v_attn, valid_out_v, valid_out_v_attn, v_optimizer, attn_idx, eta_w, eta_v)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# unrolled_bartrt_model.bart_model.train()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0munrolled_v_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_unrolled_v_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_input_attn\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0munrolled_w_model\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0meta_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munrolled_v_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munrolled_v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mvalid_input_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_input_v_attn\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mvalid_out_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_out_v_attn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\OneDrive\\桌面\\paper\\mycode\\1.0\\architect.py\u001b[0m in \u001b[0;36m_compute_unrolled_v_model\u001b[1;34m(self, input, input_attn, unrolled_w_model, eta_v, v_optimizer)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mdtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_decay\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 852.00 MiB (GPU 0; 12.00 GiB total capacity; 8.96 GiB already allocated; 0 bytes free; 10.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "my_train(begin_epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr,lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([0,  6206,  6667,    27,     1])\n",
    "tokenizer.decode([13959,  1566,    12,  2379,    10, 17608,   994,    27,     1,     0])\n",
    "print(model_v.vocab_size)\n",
    "logit = torch.load('logits.pt')\n",
    "target = torch.load('target_ids.pt')\n",
    "tokenizer.decode(target[0])\n",
    "logit.shape\n",
    "_,maxx = torch.max(logit,dim=-1,keepdim=True)\n",
    "maxx.shape\n",
    "tokenizer.decode(maxx[0].squeeze(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
